Topic_Number,Keywords,Abstract_1,Abstract_2,Abstract_3,Abstract_4,Abstract_5,Abstract_6,Abstract_7,Abstract_8,Abstract_9,Abstract_10,Perc_of_Corpus,Topic Cluster,Summary topic
1,score; student; test; exam; perform; school; anxieti; studi; medic; academ; signific; test_anxieti; level; colleg; year,"As adolescents spend the majority of their time focused on exams and assignments, they do not have sufficient time to engage in physical activity; this lack of physical activity is an important public health concern. This study aimed to investigate how school-based physical activity programs affect the health-related physical fitness of adolescents in the Republic of Korea. For this study, a total of 120 high school students participated in a school-based physical activity program that included badminton and table tennis for 15 weeks each (35 min/day, three times a week), with a total of 30 weeks for one academic year. The parameters for health-related physical fitness measured muscle strength (handgrip strength), power (standing long jump), cardiorespiratory fitness (shuttle run test), flexibility (sit and reach), body mass index (BMI), and the total score. The results revealed a statistically significant improvement in muscle strength (p < 0.001), power (p < 0.001), cardiorespiratory fitness (p < 0.001), flexibility (p = 0.005), and the overall health-related physical fitness score (p = 0.001). However, students’ BMI showed no significant difference before and after participation (p = 0.825). The results of this study indicated that school-based physical activity programs can have a positive effect on the health-related physical fitness of adolescents.","Introduction The purpose of this study was to determine the associations of the demographic variables of gender, state of legal residency, student age, and undergraduate major with scores on the Medical College Admissions Test (MCAT) and the United States Medical Licensing Exam (USMLE) Step 1 and Step 2 Clinical Knowledge. Methods The researchers collected and analyzed exam scores and demographic student data from participants of five graduating classes of students at the University of Minnesota Medical School (N = 1,067). Results Significant differences (p < 0.05) were found for traditional-aged (defined as < 25 years old at matriculation) versus nontraditional-aged students on USMLE Step 1 scores (t[1065] = 2.91, p = 0.004) and USMLE Step 2 scores (t[1061] = 4.39, p < 0.001), both in favor of traditional-aged students. Significant differences were found for males versus females on MCAT Composite scores (t[1063] = 6.53, p < 0.001) and USMLE Step 1 scores (t[1065] = 5.14, p < 0.001), both in favor of males. There were no significant differences between science and nonscience majors or between Minnesota legal residents and nonresidents. Conclusion Traditional age and male gender were associated with higher exam scores, although patterns differed between tests, whereas undergraduate major and state of legal residency were not associated with higher exam scores.","Background Medical students face greater academic stress and devote more time to their studies due to the tough nature of medical education, at the cost of sleep and physical activity. Good sleep quality and physical activity improve the mental ability and academic performance of the students. Objectives and rationale The study aims to assess sleep quality and physical activity levels among fourth-year MBBS students of Rawalpindi Medical University. We compare these levels with gender and boarding status and correlate them with the academic performance of the students. This may provide new target areas to improve the academics of students performing below average. Materials and methods It was a descriptive, cross-sectional study conducted in March 2019 on 344 medical students enrolled in the fourth-year MBBS class of Rawalpindi Medical University. Sleep quality was assessed by the Pittsburgh Sleep Quality Index (PSQI), physical activity levels by the Global Physical Activity Questionnaire (GPAQ), and academic performance by the marks attained in the most recent pathology class test. The students who could not prepare for the test in the usual manner were excluded from the study. Two-hundred nineteen (219) students were part of the final study sample. Data analysis was performed using SPSS v.22.0 (IBM Corp, Armonk, NY, US). A chi-squared test, independent samples t-test, Pearson’s correlation, and a multiple linear regression model were used to assess the variables. Results Sleep quality and physical activity were significantly correlated with academic performance (p-values of the chi-square and t-test were <0.000). Pearson’s correlation coefficient was -0.69 for PSQI (p<0.000) and 0.62 for GPAQ (p 0.003) with test scores. Gender showed significant association with sleep and physical activity levels (male students had better physical activity level and poorer sleep quality than female students) but no association with test scores. Boarding status was significantly associated with all three variables. Boarders had lower mean test scores and poorer sleep and physical activity indices as compared to non-boarders. The multiple linear regression model was valid (p-value of the F test was <0.000), with beta coefficients of -2.53 ( p=0.002) for sleep quality and 1.37 (p=0.01) for physical activity. The R2 value was 0.84 (84%). Conclusions Our study indicates an overall poor sleep quality and physical activity level among fourth-year medical students, particularly boarding students, who have lower test scores and worse sleep and physical activity levels. In general, male students have better GPAQ scores and female students have better PSQI scores. Both the PSQI and GPAQ scores are significantly correlated with test scores and provide potential target areas to improve the exam performance of the students.","Objectives To examine the predictive validity of pre-admission variables on students’ performance in a medical school in Saudi Arabia. Methods In this retrospective study, we collected admission and college performance data for 737 students in preclinical and clinical years. Data included high school scores and other standardized test scores, such as those of the National Achievement Test and the General Aptitude Test. Additionally, we included the scores of the Test of English as a Foreign Language (TOEFL) and the International English Language Testing System (IELTS) exams. Those datasets were then compared with college performance indicators, namely the cumulative Grade Point Average (cGPA) and progress test, using multivariate linear regression analysis. Results In preclinical years, both the National Achievement Test (p=0.04, B=0.08) and TOEFL (p=0.017, B=0.01) scores were positive predictors of cGPA, whereas the General Aptitude Test (p=0.048, B=-0.05) negatively predicted cGPA. Moreover, none of the pre-admission variables were predictive of progress test performance in the same group. On the other hand, none of the pre-admission variables were predictive of cGPA in clinical years. Overall, cGPA strongly predict-ed students’ progress test performance (p<0.001 and B=19.02). Conclusions Only the National Achievement Test and TOEFL significantly predicted performance in preclinical years. However, these variables do not predict progress test performance, meaning that they do not predict the functional knowledge reflected in the progress test. We report various strengths and deficiencies in the current medical college admission criteria, and call for employing more sensitive and valid ones that predict student performance and functional knowledge, especially in the clinical years.","A student's level of self-efficacy and test anxiety directly impacts their academic success (Abdi, Bageri, Shoghi, Goodarzi, & Hosseinzadeh, 2012; Hassanzadeh, Ebrahimi, & Mahdinejad, 2012). When a student doubts themself and their own ability to test well, the students' sole focus becomes worrying about poor grades and cannot focus on academics (Bandura, 1993). But, little is understood about how test-anxiety and self-efficacy affect short-term success in the classroom. Specifically, how test anxiety and level of self-efficacy directly preceding an exam will affect the exam score. Pre-and post-questionnaires assessing anxiety and self-efficacy immediately before and after a single college exam was completed by 110 college students and exam grades were obtained from the instructor. Results showed a strong relationship between both test anxiety and exam grades, and self-efficacy and exam grades. Further, multiple linear regression analyses showed that exam grade could be predicted by test anxiety and self-efficacy level, and that self-efficacy moderated the effects of anxiety.","Objective Test anxiety (TA) is a construct that has scarcely been studied based on Lang’s three-dimensional model of anxiety. The objective of this article is to investigate the repercussion of sociodemographic and academic variables on different responses for each component of anxiety and for the type of test in adolescent students. Method A total of 1181 students from 12 to 18 years old (M = 14.7 and SD = 1.8) participated, of whom 569 were boys (48.2%) and 612 girls (51.8%). A sociodemographic questionnaire and the Cuestionario de Ansiedad ante los examenes-Adaptado (CAEX-A) [Test Anxiety Questionnaire-Adapted] an adaptation for Spanish secondary school levels (ESO) and Bachillerato were administered. Results Girls scored higher on the cognitive and physiological components of TA than boys, the intensity of the physiological response increasing with age. Bachillerato level students reported more physiological anxiety than those of ESO level. Students with better marks in the previous year presented more anxiety in the cognitive component, while those who obtained the lower mark presented higher anxiety values in the behavioral component. Participants reported that the types of tests that cause them more anxiety were oral tests in front of the class, oral presentation in front of a panel, and mathematics tests. Conclusion Adolescents show a differential response of TA based on the physiological, cognitive and motor components, mediated by the variables of gender, age, grade, academic performance and type of exam. These results serve to design specific intervention programs to manage anxiety in situations of academic assessment.","Does school climate ameliorate or exacerbate the impact of neighborhood violent crime on test scores? Using administrative data from the New York City Department of Education and the New York City Police Department, we find that exposure to violence in the residential neighborhood and an unsafe climate at school lead to substantial test score losses in English language arts (ELA). Middle school students exposed to neighborhood violent crime before the ELA exam who attend schools perceived to be less safe or to have a weak sense of community score 0.06 and 0.03 standard deviations lower, respectively. We find the largest negative effects for boys and Hispanic students in the least safe schools, and no effect of neighborhood crime for students attending schools with better climates.","Objectives: To evaluate the correlation and concordance between the ‘Peruvian National Exam of Medicine’ (ENAM) and the Mean Grade Point Average (GPA) in recently graduated medical students in the period 2007 to 2009. Materials and Methods: We carried out a secondary data analysis, using the records of the physicians applying to the Rural and Urban Marginal Service in Health of Peru (SERUMS) processes for the years 2008 to 2010. We extracted from these registers, the grades obtained in the ENAM and GPA. We performed a descriptive analysis using medians and 1 st and 3 rd quartiles (q1/q3); we calculated the correlation between both scores using the Spearman correlation coefficient, additionally, we conducted a lineal regression analysis, and the concordance was measured using the Bland and Altman coefficient. Results: A total of 6 117 physicians were included, the overall median for the GPA was 13.4 (12.7/14.2) and for the ENAM was 11.6 (10.2/13.0).Of the total assessed, 36.8% failed the TEST. We observed an increase in annual median of ENAM scores, with the consequent decrease in the difference between both grades. The correlation between ENAM and PPU is direct and moderate (0.582), independent from the year, type of university management (Public or Private) and location. However, the concordance between both ratings is regular, with a global coefficient of 0.272 (CI 95%: 0.260 to 0.284). Conclusions: Independently of the year, location or type of university management, there is a moderate correlation between the ENAM and the PPU; however, there is only a regular concordance between both grades.","[Purpose] The purpose of this study was to identify the relationship between physical fitness level and academic achievement in middle school students. [Subjects and Methods] A total of 236 students aged 13–15 from three middle schools in D city, South Korea, were selected using a random sampling method. Academic achievement was measured by students’ 2014 fall-semester final exam scores and the level of physical fitness was determined according to the PAPS (Physical Activity Promotion System) score administrated by the Korean Ministry of Education. A Pearson correlation test with SPSS 20.0 was employed. [Results] The Pearson correlation test revealed a significant correlation between physical fitness and academic achievement. Specifically, students with higher levels of physical fitness tend to have higher academic performance. In addition, final exam scores of core subjects (e.g., English, mathematics, and science) were significantly related to the PAPS score. [Conclusion] Results of this study can be used to develop more effective physical education curricula. In addition, the data can also be applied to recreation and sport programs for other populations (e.g., children and adult) as well as existing national physical fitness data in various countries.","Using data from Indonesia, Newhouse and Beegle to evaluate the impact of school type on academic achievement of junior secondary school students (grades 7-9). Students that graduate from public junior secondary schools, controlling for a variety of other characteristics, score 0.15 to 0.3 standard deviations higher on the national exit exam than comparable privately schooled peers. This finding is robust to OLS, fixed-effects, and instrumental variable estimation strategies. Students attending Muslim private schools, including Madrassahs, fare no worse on average than students attending secular private schools. The results provide indirect evidence that higher quality inputs at public junior secondary schools promote higher test scores.",21.0341766121708,2,"year, test_anxieti, colleg"
2,student; learn; studi; use; exam; score; stress; result; test; academ; style; data; signific; academ_perform; final,"This study aims to determine whether there is a positive and significant relationship and there is an influence between learning interest on Integrated Science learning outcomes. The type of research used in this research is quantitative research with correlational methods. The population in this study were all 65 students of class VII at SMP Negeri 4 Maniamolo. The sampling technique uses a total sampling technique, meaning that the entire population is used as a sample. The instrument in this study used a closed questionnaire and students' science learning outcomes were in the form of odd semester final exam scores. Data analysis techniques were carried out by describing the data, correlational analysis, coefficient of determination and hypothesis testing. The test results in this study indicate that there is a positive and significant relationship between learning interest on science learning outcomes, and there is also an influence between learning interest on Integrated Science learning outcomes. So it was concluded that 1) because students have a sense of pleasure, interest, and a high desire for learning which is seen as giving them benefits and satisfaction, 2) students have a sense of comfort, are aware of the benefits of learning, and know the learning goals that make them interested so that learning occurs. improvement in learning outcomes.","This study aims to determine a positive and significant relationship as well as an influence between students' interest in learning and their mathematics learning outcomes. The research method used in this study is quantitative research with a correlational approach. The population in this study consists of all eighth-grade students at SMP Negeri 1 Toma, totaling 65 students. The sampling technique used is total sampling, meaning the entire population is used as the sample. The instruments in this study include closed-ended questionnaires and students' mathematics learning outcomes in the form of even semester final exam scores (UKK). Data analysis techniques involve describing the data, correlational analysis, coefficient of determination, and hypothesis testing. The results of this study show that there is a positive and significant relationship between students' interest in learning and their mathematics learning outcomes, and there is also an influence of students' interest in learning on their mathematics learning outcomes. It can be concluded that 1) because students have a sense of enjoyment, interest, and a high desire to learn that they perceive as beneficial and satisfying, and 2) students feel comfortable, are aware of the benefits of learning, and understand the learning objectives, which makes them interested and leads to an improvement in learning outcomes.","Abstract Self-assessment is vital for online learning since it is one of the most essential skills of distance learners. In this respect, the purpose of this study was to understand learners’ self-assessment quiz taking behaviours in an undergraduate level online course. We tried to figure out whether there is a relation between self-assessment quiz taking behaviours and final exam scores or not. In addition, we investigated how self-assessment quiz taking behaviour differs with respect to learner profile. In line with this purpose, 677 students’ 6092 test events across Project Culture course on Sakai CLE LMS were analyzed. For the analysis of the quantitative data, one-way ANOVA, Chi-Square test of independence, independent-samples t-test and descriptive statistics were utilized. The results revealed that learners who attended self-assessment quizzes regularly had higher final exam scores than others who did not attend those quizzes. Also, they were more satisfied with the course than others study field. In addition, learners who attended selfassessment quizzes regularly had a higher degree of perceived learning. However, number of attempts to those quizzes does not have an effect on final exam scores. On the other hand, a statistically significant relationship was found between attempt number and gender in favour of female learners.","Purpose: The present study was conducted to find the preferred mode of learning among first-year preclinical students and compare the preferred mode of learning with sex, faculty of students, and academic performance of the students using the VARK questionnaire. Methods: A cross-sectional study was done among 142 first-year Bachelor of Medicine–Bachelor of Surgery and Bachelor of Dental Surgery students from February to May 2018. Demographic data and various academic performance marks were recorded for each individual. VARK (visual, aural, read/write and kinesthetic) questionnaire version 7.8 was administered to calculate the score of each component. Mean VARK scores were calculated and each student classified by their preferred mode of learning. The preferred mode of learning was compared with sex, nationality, faculty of students, and academic performance using χ2, unpaired t-tests, and the Mann–Whitney U test. P<0.05 was taken as statistically significant for comparison. Results: A majority of the students (53.52%) were multimodal. The most common multimodal mode of preference was bimodal (26.06%), while the most common unimodal preference was kinesthetic (29.06%). Total V score, K score, and VARK score were higher among males, while A and R scores were higher among females. The K score (7.96±2.35 in males and 6.96±2.43 in females) differed significantly (P=0.019) between male and female subjects. More subjects with higher scores in the theory exam of anatomy were unimodal learners (53.8%) compared to multimodal learners (46.2%). Conclusion: From this study, it can be concluded that undergraduate students were diverse in their learning styles, but most were multimodal. Though learning styles were found to vary by sex, nationality, and academic performance, differences were not statistically significant.","OBJECTIVE: Stress is a condition caused by various factors and characterized by imbalance in body functioning, impair in nervous system, and tension. The purpose of this study was to examine the effects of cortisol level, which increases in healthy young individuals due to stress, on dynamic and static balance scores as well as to present the results caused by high levels of stress. METHODS: In this study, 107 healthy medicine faculty students in their second year (who will take the same committee exam) aged between 19 and 23 years were included. The first balance measurements and saliva samples were taken 40 days before the committee exam, and this period was acknowledged as the relaxed period. The same students were considered for balance measurements again on the day of committee exam; saliva samples were collected, and cortisol concentration was determined. This period was acknowledged as the stressful period. The State-Trait Anxiety Inventory (STAI) was given to the participants in their relaxed and stressful periods. Dynamic balance scores were measured with Star Excursion Balance Test (SEBT). Static balance scores were measured with One Leg Standing Balance Test (OLSBT). RESULTS: The mean cortisol level was found to increase approximately 9 times in stressful periods compared with that in relaxed periods. STAI, which shows state anxiety, showed an increase supporting this increase. In stressful periods, dynamic balance scores showed obvious decrease in all directions. In addition, in stressful periods, an obvious decrease was observed in static balance scores compared with those in relaxed periods. CONCLUSION: This study showed that stress negatively affected dynamic and static balance, even for short periods of time. We believe that our study will form a positive source and basis when correlated with long terms stress and balance measurements.","Background Digital learning environments have become very common in the training of medical professionals, and students often use such platforms for exam preparation. Multiple choice questions (MCQs) are a common format in medical exams and are used by students to prepare for said exams. Objective We aimed to examine whether particular learning activities contributed more strongly than others to users’ exam performance. Methods We analyzed data from users of an online platform that provides learning materials for medical students in preparation for their final exams. We analyzed whether the number of learning cards viewed and the number of MCQs taken were positively related to learning outcomes. We also examined whether viewing learning cards or answering MCQs was more effective. Finally, we tested whether taking individual notes predicted learning outcomes, and whether taking notes had an effect after controlling for the effects of learning cards and MCQs. Our analyses from the online platform Amboss are based on user activity data, which supplied the number of learning cards studied and test questions answered. We also included the number of notes from each of those 23,633 users who had studied at least 200 learning cards and had answered at least 1000 test exam questions in the 180 days before their state exam. The activity data for this analysis was collected retrospectively, using Amboss archival usage data from April 2014 to April 2017. Learning outcomes were measured using the final state exam scores that were calculated by using the answers voluntarily entered by the participants. Results We found correlations between the number of cards studied (r=.22; P<.001) and the number of test questions that had been answered (r=.23; P<.001) with the percentage of correct answers in the learners’ medical exams. The number of test questions answered still yielded a significant effect, even after controlling for the number of learning cards studied using a hierarchical regression analysis (β=.14; P<.001; ΔR2=.017; P<.001). We found a negative interaction between the number of learning cards and MCQs, indicating that users with high scores for learning cards and MCQs had the highest exam scores. Those 8040 participants who had taken at least one note had a higher percentage of correct answers (80.94%; SD=7.44) than those who had not taken any notes (78.73%; SD=7.80; t23631=20.95; P<.001). In a stepwise regression, the number of notes the participants had taken predicted the percentage of correct answers over and above the effect of the number of learning cards studied and of the number of test questions entered in step one (β=.06; P<.001; ΔR2=.004; P<.001). Conclusions These results show that online learning platforms are particularly helpful whenever learners engage in active elaboration in learning material, such as by answering MCQs or taking notes.","This  article  reports  on  the  reliability,  internal  validity,  external  validity,  gender  differences,  and  norms  of  a Spanish  version  of  the  Achievement  Emotions  Questionnaire  (Pekrun  et  al.,  2011)  adapted  for  Argentinean  university students (namely  AEQ-AR).  The  AEQ-AR  contains  24  scales  measuring  enjoyment,  hope,  pride, relief,  anger,  anxiety, shame,  hopelessness,  and  boredom  during  class,  while  studying,  and  when  taking  tests  and  exams.   Argentinean undergraduates studying at the National University of Cordoba participated in the study.  An estimation sample (N = 400) and a validation sample (N = 266) were formed to examine internal validity and reliability. The total sample (N = 666) was used to analyze external validity, gender differences and to obtain norms for the scales.  Results indicate that the scales are reliable,  internally valid as demonstrated by exploratory and confirmatory factor analysis, and externally valid in terms of relationships with  task value, social academic self-efficacy, achievement goals, avoidance of help seeking, and  academic performance. In addition,  partial support for the gender differences hypothesis of prospective and retrospective emotions related to  negative  results  was  found.  The  obtained  norms  for  male and  female  students  will  allow  interpret  the  scores obtained for practical purposes. Finally, instructions and scales of the AEQ-AR are presented in the appendix.","This study aims to determine the achievement level in each competency given to students and to know the average percentage of post-e-learning student scores. The research method used is quantitative with descriptive statistical techniques. This research population is sports education students 2017, 2018, and 2019 active students, with a sample of 10% of the population. The determination of this sample is based on purposive sampling. Data collection techniques using test instruments, in the form of questions and semester exam results. The research data analysis technique uses descriptive statistical methods obtained during the 2019-2020 semester, namely the Final Semester Examination value. After feeling that it is sufficient to obtain data and process, it will get the research results after feeling that it is enough to get the data and processed to get the research results. The results of the study found that effective learning was seen from 83% of students getting course scores with an average of above 75 at the time of the final even semester examinations in 2019-2020, and it can be concluded that the effectiveness of e-learning in Sports Education students at the Indonesian Technocrat University was successful. With a student passing rate above 80%. It is hoped that this e-learning process will be further developed with a better platform for facing future generations where the role of technology is a significant thing in meeting the changing times.","The aim of this study is to determine the effect of Learning Modeling System (LMS) Moodle in learning. The population is taken from all students of Mathematics Education, University of PGRI Semarang. The sample was randomly selected from five different course groups. The initial score is taken from the semester test, and the final score is taken through the semester test after the five groups are taught using Moodle. The results of both test results are compared to find out the increase in learning outcomes. Meanwhile, the student's attitude toward learning is taken through his mathematical disposition through questionnaire. The results show that there was a significant increase in exam results on the final exam of the semester. This result is supported by student learning interest which increases on average after using LMS Moodle taken from disposition data.","Information about score obtained from a test is often interpreted as an indicator of the student's ability level. This is one of the weaknesses of classical analysis that are unable to provide meaningful and fair information. The acquisition of the same score if it comes from a test item with a different level of difficulty, must show different abilities. Analysis of the Rasch model will overcome this weakness. The purpose of this study was to analyze the quality of the items by validating the national chemistry exam instrument using the Rasch model. The research sample was 212 new students of the Department of Chemistry at the State University of Medan. The data collected was in the form of respondent's answer data to the 2013 chemistry UN questions, which amounted to 40 items multiple choice and uses the documentation method. Data analysis technique used the Rasch Model with Ministep software. The results of the analysis show the quality of the Chemistry National Exam (UN) questions is categorized as very good based on the following aspects: unidimension, item fit test, person map item, difficulty test level, person and item reliability. There is one item found to be gender bias, in which men benefit more than women. The average chemistry ability of respondents is above the average level of difficulty of the test items",15.3473354028472,0,"academ_perform, final, data"
3,student; perform; cours; exam; score; test; examin; assess; differ; use; onlin; studi; result; signific; osc,"The “ gender gap ” on various physics conceptual evaluations has been extensively studied. Men ’ s average pretest scores on the Force Concept Inventory and Force and Motion Conceptual Evaluation are 13% higher than women ’ s, and post-test scores are on average 12% higher than women ’ s. This study analyzed the gender differences within the Conceptual Survey of Electricity and Magnetism (CSEM) in which the gender gap has been less well studied and is less consistent. In the current study, data collected from 1407 students (77% men, 23% women) in a calculus-based physics course over ten semesters showed that male students outperformed female students on the CSEM pretest (5%) and post-test (6%). Separate analyses were conducted for qualitative and quantitative problems on lab quizzes and course exams and showed that male students outperformed female students by 3% on qualitative quiz and exam problems. Male and female students performed equally on the quantitative course exam problems. The gender gaps within CSEM post-test scores, qualitative lab quiz scores, and qualitative exam scores were insignificant for students with a CSEM pretest score of 25% or less but grew as pretest scores increased. Structural equation modeling demonstrated that a latent variable, called Conceptual Physics Performance/Non-Quantitative (CPP/NonQnt), orthogonal to quantitative test performance was useful in explaining the differences observed in qualitative performance; this variable was most strongly related to CSEM post-test scores. The CPP/NonQnt of male students was 0.44 standard deviations higher than female students. The CSEM pretest measured CPP/NonQnt much less accurately for women ( R 2 ¼ 4% ) than for men ( R 2 ¼ 17% ). The failure to detect a gender gap for students scoring 25% or less on the pretest suggests that the CSEM instrument itself is not gender biased. The failure to find a performance difference in quantitative test performance while detecting a gap in qualitative performance suggests the qualitative differences do not result from psychological factors such as science anxiety or stereotype threat. DOI: 10.1103/PhysRevPhysEducRes.13.020114","Our previous research Kost et al., Phys. Rev. ST Phys. Educ. Res. 5, 010101 2009 examined gender differences in the first-semester, introductory physics class at the University of Colorado at Boulder. We found that: 1 there were gender differences in several aspects of the course, including conceptual survey performance, 2 these differences persisted despite the use of interactive engagement techniques, and 3 the post-test gender differences could largely be attributed to differences in males’ and females’ prior physics and math performance and their incoming attitudes and beliefs. In the current study, we continue to characterize gender differences in our physics courses by examining the second-semester, electricity and magnetism course. We analyze three factors: student retention from Physics 1 to Physics 2, student performance, and students’ attitudes and beliefs about physics, and find gender differences in all three of these areas. Specifically, females are less likely to stay in the physics major than males. Despite males and females performing about equally on the conceptual pretest, we find that females score about 6 percentage points lower than males on the conceptual post-test. In most semesters, females outperform males on homework and participation, and males outperform females on exams, resulting in course grades of males and females that are not significantly different. In terms of students’ attitudes and beliefs, we find that both males and females shift toward less expertlike beliefs over the course of Physics 2. Shifts are statistically equal for all categories except for the Personal Interest category, where females have more negative shifts than males. A large fraction of the conceptual post-test gender gap up to 60% can be accounted for by differences in males’ and females’ prior physics and math performance and their pre-Physics 2 attitudes and beliefs. Taken together, the results of this study suggest that it is an accumulation of small gender differences over time that may be responsible for the large differences that we observe in physics participation of males and females.","In this paper we compare and contrast student's pretest/post-test performance on the Halloun-Hestenes force concept inventory (FCI) to the Thornton-Sokoloff force and motion conceptual evaluation (FMCE). Both tests are multiple-choice assessment instruments whose results are used to characterize how well a first term, introductory physics course promotes conceptual understanding. However, the two exams have slightly different content domains, as well as different representational formats; hence, one exam or the other might better fit the interests of a given instructor or researcher. To begin the comparison, we outline how to determine a single-number score for the FMCE and present ranges of normalized gains on this exam. We then compare scores on the FCI and the FMCE for approximately 2000 students enrolled in the Studio Physics course at Rensselaer Polytechnic Institute over a period of eight years (1998--2006) that encompassed significant evolution of the course and many different instructors. We found that the mean score on the FCI is significantly higher than the mean score on the FMCE, however there is a very strong relationship between scores on the two exams. The slope of a best fit line drawn through FCI versus FMCE data is approximately 0.54, and the correlation coefficient is approximately $r=0.78$, for preinstructional and postinstructional testings combined. In spite of this strong relationship, the assessments measure different normalized gains under identical circumstances. Additionally, students who scored well on one exam did not necessarily score well on the other. We use this discrepancy to uncover some subtle, but important, differences between the exams. We also present ranges of normalized gains for the FMCE in a variety of instructional settings.","Submissions to an online homework tutor were analyzed to determine whether they were copied. The fraction of copied submissions increased rapidly over the semester, as each weekly deadline approached and for problems later in each assignment. The majority of students, who copied less than 10% of their problems, worked steadily over the three days prior to the deadline, whereas repetitive copiers those who copied 30% of their submitted problems exerted little effort early. Importantly, copying homework problems that require an analytic answer correlates with a 2 decline over the semester in relative score for similar problems on exams but does not significantly correlate with the amount of conceptual learning as measured by pretesting and post-testing. An anonymous survey containing questions used in many previous studies of self-reported academic dishonesty showed 1 /3 less copying than actually was detected. The observed patterns of copying, free response questions on the survey, and interview data suggest that time pressure on students who do not start their homework in a timely fashion is the proximate cause of copying. Several measures of initial ability in math or physics correlated with copying weakly or not at all. Changes in course format and instructional practices that previous self-reported academic dishonesty surveys and/or the observed copying patterns suggested would reduce copying have been accompanied by more than a factor of 4 reduction of copying from 11% of all electronic problems to less than 3%. As expected since repetitive copiers have approximately three times the chance of failing, this was accompanied by a reduction in the overall course failure rate. Survey results indicate that students copy almost twice as much written homework as online homework and show that students nationally admit to more academic dishonesty than MIT students.","Traditional and online university courses share expectations for quality content and rigor. Student and faculty concerns about compromised academic integrity and actual instances of academic dishonesty in assessments, especially with online testing, are increasingly troublesome. Recent research suggests that in the absence of proctoring, the time taken to complete an exam increases significantly and online test results are inflated. This study uses a randomized design in seven sections of an online course to examine test scores from 97 students and time taken to complete online tests with and without proctoring software, controlling for exam difficulty, course design, instructor effects, and student majors. Results from fixed effects estimated from a fitted statistical model showed a significant advantage in quiz performance (7-9 points on a 100 point quiz) when students were not proctored, with all other variables statistically accounted for. Larger grade disparities and longer testing times were observed on the most difficult quizzes, and with factors that reflected the perception of high stakes of the quiz grades. Overall, use of proctoring software resulted in lower quiz scores, shorter quiz taking times, and less variation in quiz performance across exams, implying greater compliance with academic integrity compared with when quizzes were taken without proctoring software.","Online education continues to grow, bringing opportunities and challenges for students and instructors. One challenge is the perception that academic integrity associated with online tests is compromised due to undetected cheating that yields artificially higher grades. To address these concerns, proctoring software has been developed to address and prevent academic dishonesty. The purpose of this study was to compare online test results from proctored versus unproctored online tests. Test performance of 147 students enrolled in multiple sections of an online course were compared using linear mixed effects models with nearly half the students having no proctoring and the remainder required to use online proctoring software. Students scored, on average, 17 points lower [95% CI: 14, 20] and used significantly less time in online tests that used proctoring software versus unproctored tests. Significant grade disparity and different time usage occurred on different exams, both across and within sections of the same course where some students used test proctoring software and others did not. Implications and suggestions for incorporating strategic interventions to address integrity, addressing disparate test scores, and validating student knowledge in online classes are discussed.","We identify the student characteristics most associated with success in an introductory business statistics class, placing special focus on the relationship between student math skills and course performance, as measured by student grade in the course. To determine which math skills are important for student success, we examine (1) whether the student has taken calculus or business calculus, (2) whether the student has been required to take remedial mathematics, (3) the student's score on a test of very basic mathematical concepts, (4) student scores on the mathematics portion of the ACT exam, and (5) science/reasoning portion of the ACT exam. The score on the science portion of the ACT exam and the math-quiz score are significantly related to performance in an introductory statistics course, as are student GPA and gender. This result is robust across course formats and instructors. These results have implications for curriculum development, course content, and course prerequisites.","Sir, Assessment of learning has always been a difficult, yet an essential component of an educational program. In the undergraduate medical education system in India, curricular guidelines of Medical Council of India lay emphasis on methods of assessment of knowledge and skills in pharmacology.[1] Although continuous formative assessment constitutes an integral part in the curriculum, the ‘pass’ and the ‘fail’ certificates are based to a great extent on students’ performance in the final summative examination. The final examination consists of written papers, viva-voce sessions and practical exercises. Written examination consists of two papers. Each paper has the maximum marks of 40 and contains structured essay type questions and short notes. In viva-voce examination, each student is assessed by five examiners; two of them external examiners and the others internal examiners. In order to pass, a candidate must obtain 50% marks in aggregate with a minimum of 50% marks in written and viva together and a minimum of 50% marks in practical examination.[1] The written examination is a useful evaluation format that not only tests students’ ability to recall facts, but also can assess higher-order cognitive functions, such as interpretation of data and problem solving skills. The viva-voce examination on the other hand is a general encounter between a candidate and one or more examiners.[2] Viva-voce examinations are less reliable as they are essentially subjective in nature, afflicted with ‘halo effects’, errors of central tendency, a general tendency toward leniency, and errors of contrast.[2] Examiners mostly indulge in over-marking in viva-voce examinations in order to make an otherwise undeserving candidate ‘pass’. We explored this recently in a small questionnaire-based interview among examiners of pharmacology in one university and the examiners admitted showing such ‘leniency’. Against this backdrop, we planned the present study to compare students’ performance in written and viva-voce components of the final summative pharmacology examination in MBBS curriculum in order to have a critical insight into the two modes of evaluation, the way they are practiced. This was a record-based observational study done in a medical college in India that also served as an examination centre for second professional MBBS examination in pharmacology for four consecutive years, from 2008 to 2011. The performance of students was assessed. Permission for access to the students’ score sheets was obtained from appropriate authority and confidentiality of individual student’s score was maintained. Percentage of marks obtained by four batches of students (n=589), in consecutive years (2008-11), in written and viva-voce components of the final summative examination in pharmacology were reviewed: Batch 1 (Jan 2011 Exam, n=159), Batch 2 (Jan 2010 Exam, n=139), Batch 3 (Jan 2009 Exam, n=148), Batch 4 (Jan 2008 Exam, n=143). Based on their performance in terms of percentage of marks in aggregate, all students in a batch were classified into four categories viz., ‘failed’(F) – <50%, ‘borderline passed’ (BP) – 50-57%, ‘passed’ (P) – >57% to <75% and ‘passed with distinction’ (PD) – ≥75%. Correlation was assessed between the percentage of marks obtained by students in these categories in written vis-a-vis viva-voce examination. Highly significant association was observed in marks obtained by students in P and PD categories in all four batches in viva-voce and written examination (P<0.001). However, no significant association was observed in marks obtained by students in F and BP categories in all four batches in viva-voce and written examination (P>0.05). The results are shown in Table 1. Interestingly, no student in F category got 50% marks in written examination, but most of them scored satisfactorily in the viva-voce. Among all the students in F category, three students in 2008, five in 2009, four in 2010 and none in 2011 failed in practical examination. The number of students in each category (e.g., F, BP, P and PD) when compared among the 4 years (2008-11) did not show any significant difference [Figure 1]. Our study showed that there was highly significant association between written and viva-voce marks of students in the PD and P categories (P<0.001). We interpret this as the ‘true’ reflection of knowledge and competence of the students in this category. Our study also revealed that there was a lack of significant association in performance in written and viva-voce examination among students in F and BP categories (P>0.05). Marks obtained by students in viva-voce were higher with respect to those in written examination in these two categories. Rather, the poorer the performance in written examination, the higher the marks obtained in the viva-voce. Such trend is most prominent in the F category of students Access this article online","Many prior studies have investigated female and male students’ self-efficacy (SE) in physics courses. However, test anxiety (TA) is rarely studied in the physics context, despite prior work suggesting it may play a detrimental role in the development of SE. In this study, we explore the relationships between SE, TA, and gender differences in introductory calculus-based physics performance. Although there has been research that uses TA and SE to predict student grades, no study to our knowledge has investigated this in the context of low- (e.g., homework and quizzes) and high-stakes (e.g., traditional exams) physics assessments. Using validated survey data and grade information, we compared the predictive power of SE and TA on student performance on a variety of assessment types. We found that there are gender differences in both SE and TA, as well as in high-stakes assessment outcomes. There were no gender differences in low-stakes assessment scores. Further, we found that models that control for SE and/or TA eliminate the predictive power of gender for high-stakes assessment outcomes. Finally, we found that SE partially mediates the effect of TA on high-stakes assessment outcomes. From these results, we make several suggestions for instructors that may alleviate the adverse effects of TA and make physics assessments more equitable and inclusive.","Prior research has established that students often underprepare for midterm examinations yet remain overconfident in their proficiency. Research concerning the testing effect has demonstrated that utilizing testing as a study strategy leads to higher performance and more accurate confidence compared to more common study strategies such as rereading or reviewing homework problems. We report on three experiments that explore the viability of using computer adaptive testing (CAT) for assessing students’ physics proficiency, for preparing students for midterm exams by diagnosing their weaknesses, and for predicting scores in midterm exams in an introductory calculus-based mechanics course for science and engineering majors. The first two experiments evaluated the reliability and validity of the CAT algorithm. In addition, we investigated the ability of the CAT test to predict performance on the midterm exam. The third experiment explored whether completing two CAT tests in the days before a midterm exam would facilitate performance on the midterm exam. Scores on the CAT tests and the midterm exams were significantly correlated and, on average, were not statistically different from each other. This provides evidence for moderate parallel-forms reliability and criterion-related validity of the CAT algorithm. In addition, when used as a diagnostic tool, CAT showed promise in helping students perform better on midterm exams. Finally, we found that the CAT tests predicted the average performance on the midterm exams reasonably well, however, the CAT tests were not as accurate as desired at predicting the performance of individual students. While CAT shows promise for practice testing, more research is needed to refine testing algorithms to increase reliability before implementing CAT for summative evaluations. In light of these findings, we believe that more research is needed comparing CAT to traditional paper-and-pencil practice tests in order to determine whether the effort needed to create a CAT system is worthwhile.",17.3639939222881,4,"osc, onlin, examin"
4,group; student; score; learn; cours; studi; signific; method; test; medic; differ; exam; control; two; effect,"Introduction Collaborative testing is a learning strategy that provides students with the opportunity to learn and practice collaboration. This study aimed to determine the effect of collaborative testing on test performance and retention of course content in nursing students of Shiraz University of Medical Sciences, Shiraz, Iran. Methods This quasi-experimental study was carried out on 84 students enrolled in the course of Medical-Surgical 2 in Spring 2013 and Fall 2013 semesters. The control group consisting of 39 students participated in the first mid-term exam in an individual format. The intervention group, on the other hand, consisted of 45 students who took the test in a two-stage process. The first stage included an individual testing, while the second stage was a collaborative one given in groups of five individuals chosen randomly. Four weeks later, in order to investigate retention of the course content, both groups took part in the second mid-term exam held individually. Results The study findings showed significant difference between the mean scores in the intervention group in the Fall 2013 semester (p=0.001). Besides, a statistically significant difference was found between the two groups regarding the tests mean scores (p=0.001). Moreover, retention of course content improved in the collaborative group (p=0.001). Conclusion The results indicated an increase in test performance and a long-term learning enhancement in collaborative testing compared with the traditional method. Collaborative testing, as an active learning technique and a valuable assessment method, can help nursing instructors provide the alumni with strong problem-solving and critical thinking abilities at healthcare environments.","Students’ achievement in Biology is often looked up as a benchmark to evaluate the mode of teaching and learning in higher education. Problem-based learning (PBL) is an approach that focuses on students’ solving a problem through collaborative groups. There were eighty samples involved in this study. The samples were divided into three groups: ICT integrated with PBL group: a PBL group, and a lecture group. The PBL with Information and Communication Technology (ICT) group used a PBL module integrated with the following ICT elements: Microsoft Word template; Microsoft PowerPoint; electronic discussion group, and blog. Meanwhile the PBL group used the PBL module alongside log books and posters. The control group utilized the lecture method. All these groups went through four sessions of Biology. Before the beginning of session one and after the fourth session, an achievement test was given to all the students. Based on the analysis for MANOVA with repeated measure 3x2x2, the main effect for type of treatment, exam time and subscale was found significantly different. Additionally, the type of treatment interacts with exam time and subscale in contributing towards the achievement test scores. Overall, the findings suggested that the ICT integrated with PBL group was significant compared to the PBL group and control group. The ICT integrated with PBL group also performed significantly higher for the subjective scale.","The flipped classroom (FC) teaching has been increasingly employed in medical education. Many studies have shown this “student-centered” pedagogical model improves students' overall achievement in the course, with students showing more motivation and better self-directed learning skills when compared to the traditional classroom teaching. However, most of the previous studies have been evaluating the short-term effects of FC teaching conducted upon completion of the course. The retention of the promotion and the long-term effects on learning of students' subsequent courses deserve further attention and evaluation. By adopting and running FC teaching in the whole course of physiology, this study aimed to determine the short-term impact of FC teaching on students' learning of physiology course and also the long-term influences in students' learning of follow-up medical curriculums within 18 months after the completion of physiology course. 119 sophomore students majoring in clinical medicine from Central South University were recruited and they were assigned randomly into two groups: the control group (n =61) who received the traditional lecture (TL) teaching, and the experimental group (n =58), who received the FC teaching. In this study, students' final exam scores were used to assess their learning effectiveness and an independent samples t-test was conducted to compare scores between the two groups. Our study showed that FC teaching significantly improved the learning outcome of physiology in the experimental group compared with the control group (P = 0.0001) without obvious impact on the learning of other subjects conducted in the same period of time. Moreover, our results also demonstrated the long-term benefit of FC teaching, with students from the experimental group scoring higher in pathophysiology (P = 0.006), pathology (P = 0.029), pharmacology (P = 0.0089), diagnostics (P = 0.01) and internal medicine (P = 0.0004) than those from the control group. The study results indicate that FC is a promising teaching approach to increase students' learning effectiveness in physiology course, and the long-term effects of FC facilitate the learning of the follow-up medical courses. Furthermore, this study also demonstrates that although the time investment on physiology is increased by FC teaching, it does not weaken students' learning of other courses conducted in the same period of time.","Purpose: This study aims to find out whether the use of MOODLE in English lessons as a tool for blended instruction makes a significant difference to the students’ language journey Research Methods: This is quasi-experimental research by nature, utilizing a mixed-method approach as the most appropriate tradition In this study, 44 students ranging in age from 16 to 18 selected on the basis of a convenience sampling technique participated After a fifteen-week treatment of MOODLE with the experimental group, paired samples T-test was applied to see if there was any difference between the two groups A questionnaire and semi-structured interviews were also conducted to gain a deeper insight into students’ experience with MOODLE Findings: Quantitative data revealed that there was statistically significant difference between the experimental group and the control group, suggesting potential contribution of MOODLE to learners’ language achievement in blended EFL lessons In the same vein, the qualitative data affirmed that most of the students were satisfied with using MOODLE to support English lessons Implications for Research and Practice: Since there is a statistically significant difference between the 1st and 2nd English exam scores of the students in the experimental group (t=-3 085 sig=0 005), MOODLE proves to be an effective online learning tool supporting blended learning The findings of the study also provide empirical evidence for integrating blended-instruction with MOODLE in foreign EFL lessons and valuable information to the Ministry of National Education (MONE) about employing blended-instruction with MOODLE in EFL classes © 2020 Ani Publishing Ltd All rights reserved","Abstract Objective: To evaluate whether computer-based learning (CBL) improves newly acquired knowledge and is an effective strategy for teaching prenatal ultrasound diagnostic skills to third-year medical students when compared with instruction by traditional paper-based methods (PBM). Study Design: We conducted a randomized, prospective study involving volunteer junior (3rd year) medical students consecutively rotating through the Obstetrics and Gynecology clerkship during six months of the 2005-2006 academic year. The students were randomly assigned to permuted blocks and divided into two groups. Half of the participants received instruction in prenatal ultrasound diagnostics using an interactive CBL program; the other half received instruction using equivalent material by the traditional PBM. Outcomes were evaluated by comparing changes in pre-tutorial and post instruction examination scores. Results: All 36 potential participants (100%) completed the study curriculum. Students were divided equally between the CBL (n=18) and PBM (n=18) groups. Pre-tutorial exam scores (mean ± s.d.) were 44% ± 11.1% for the CBL group and 44% ± 10.8% for the PBL cohort, indicating no statistically significant differences (p > 0.05) between the two groups. After instruction, post-tutorial exam scores (mean ± s.d.) were increased from the pre-tutorial scores, 74% ± 11% and 67% ± 12%, for students in the CBL and the PBM groups, respectively. The improvement in post-tutorial exam scores from the pre-test scores was considered significant (p < 0.05). When post-test scores for the tutorial groups were compared, the CBL subjects achieved a score that was, on average, 7 percentage points higher than their PBM counterparts, a statistically significant difference (p < 0.05). Conclusion: Instruction by either CBL or PBM strategies is associated with improvements in newly acquired knowledge as reflected by increased post-tutorial examination scores. Students that received CBL had significantlyhigher post-tutorial exam scores than those in the PBM group, indicating that CBL is an effective instruction strategy in this setting.","Introduction: Student-generated questions can be a very helpful tool in medical education. The use of this activity can allow the students to feel more involved in the subjects covered and may improve their knowledge and learning. The aim of this study was to identify the effect of question-writing activity as a stimulus factor on learning in midwifery students and determine their perception about this activity. Methods: This quasi-experimental study with two groups of pre- and post-tests was conducted on two groups of midwifery students who had taken the immunology course. Two classes of midwifery students (N=62) participated and were randomly assigned to two different groups. One class was selected as the experimental group (n=32) and the other class was considered as the control group (n=30). The experimental group’s students were asked to write questions covering different topics of the syllabus components taught during 15 weeks from February 2016 to May 2016. They were asked to write, answer and explain their multiple-choice questions (MCQs). The students’ performance in immunology course was compared between the two groups at the end of the semester. After their final exam, we asked them to fill in a questionnaire on their views about this activity. The data were analyzed by independent t- test using SPSS software, version 18. Results: The differences between pre- and post-test mean scores of the experimental and control groups were 24.53±5.74 and 20.63±5.58, respectively. The results of independent t-test showed that these differences in the two groups were significant (p=0.009). Nevertheless, most of the students stated that question-writing activity as a learning tool is an unfamiliar exercise and unpopular learning strategy. Conclusion: Results showed that question writing by students has been found to promote learning when it is implemented as a part of the teaching curriculum in immunology course; therefore, this activity could be effective in improving the students’ learning.","Introduction Medical educators in recent years have been using social media for more penetrance to technologically-savvy learners. The utility of using Twitter for curriculum content delivery has not been studied. We sought to determine if participation in a social media-based educational supplement would improve student performance on a test of clinical images at the end of the semester. Methods 116 second-year medical students were enrolled in a lecture-based clinical medicine course, in which images of common clinical exam findings were presented. An additional, optional assessment was performed on Twitter. Each week, a clinical presentation and physical exam image (not covered in course lectures) were distributed via Twitter, and students were invited to guess the exam finding or diagnosis. After the completion of the course, students were asked to participate in a slideshow “quiz” with 24 clinical images, half from lecture and half from Twitter. Results We conducted a one-way analysis of variance to determine the effect Twitter participation had on total, Twitter-only, and lecture-only scores. Twitter participation data was collected from the end-of-course survey and was defined as submitting answers to the Twitter-only questions “all or most of the time”, “about half of the time”, and “little or none of the time.” We found a significant difference in overall scores (p<0.001) and in Twitter-only scores (p<0.001). There was not enough evidence to conclude a significant difference in lecture-only scores (p=0.124). Students who submitted answers to Twitter “all or most of the time” or “about half the time” had significantly higher overall scores and Twitter-only scores (p<0.001 and p<0.001, respectively) than those students who only submitted answers “little or none of the time.” Conclusion While students retained less information from Twitter than from traditional classroom lecture, some retention was noted. Future research on social media in medical education would benefit from clear control and experimental groups in settings where quantitative use of social media could be measured. Ultimately, it is unlikely for social media to replace lecture in medical curriculum; however, there is a reasonable role for social media as an adjunct to traditional medical education.","Introduction: Instruction in teacher-centered formats may lead to early learning fatigue, which in turn, decelerates students’ knowledge retrieval. Presently, teachers try to increase students' participation and their active attention to course content by incorporating effective, applicable, low-cost, and enjoyable teaching apparatuses. Methods: The participants of this quasi-experimental study were the students of speech therapy in 4th semester (n=83) at Ahvaz Jundishapur University of Medical Sciences. They were simple-randomly divided into two groups of experimental (who received the crossword puzzle accompanied by lecture or the hybrid method as Group A) and control (who received the traditional method as Group B). The students' knowledge level and students' satisfaction with their received instruction methods were assessed as outcome measures throughout the experiment for both groups. The test score of students' initial knowledge of the concepts in Speech Therapy, the score from the semester final exam of the courses in forms of multiple choice questions, and the retained learning score were calculated as the pre-test, post-test and a follow-up measurement, respectively. Independent-samples T-test for comparative analyses of students' satisfaction between the pre-test and post-test, and multivariate repeated measures ANOVA test were used to analyze the students' knowledge level at three time-points (before, immediately after, and one month after the trainings). The data were analyzed using SPSS ver. 18.0 software, and at the level of statistical significance of P≤0.05. Results: Both educational methods significantly improved the students' knowledge level after the trainings (P=0.030); however, the mean score of knowledge and learning of Group A (mean=17.14) were significantly higher than that of Group B (mean=16.02) immediately after (P=0.036) and one month after the trainings (mean=18.26 vs. 16.10) (P=0.001). The mean score of students' satisfaction in Group A was also significantly higher than that in Group B (P=0.010). Conclusion: Utilizing the crossword puzzle as an enjoyable and participatory teaching tool accompanied by lecture could improve management quality in Speech Therapy sessions.","Introduction: In traditional medical education systems much interest is placed on the cramming of basic and clinical facts without considering their applicability in the future professional career. The aim of this study is to evaluate a novice medical training method (problem-based learning) as compared to the contemporary teacher-based medical education or traditional methods. Methods: Selection of the study subjects was done through simple sampling and according to the division of medical students introduced from Medical Faculty to the Pediatrics Department with no personal involvement. 120 medical students were assigned to 8 groups of 15 students each. For four months, 4 groups were trained with traditional method and 4 other groups underwent problem-based learning method on selected subject materials. In each method, a pre-course test at the beginning and a post-course test at the end of each course were given to each group. The questionnaire used in this study as the instrument was composed of 39 questions, 37 multiple choice questions and two short answer questions. Three professors of pediatric gastroenterologist took part in the training. Two of these professors were responsible for solving task training method. The third professor used traditional teacher-centered methodology to eliminate any possible bias. Scores obtained from these tests were analyzed using paired t-test and independent t-test. P-values of less than 0.05 were considered as significant. Results: The scores of the students undergoing the traditional method were 14.70±3.03 and 21.20±4.07 in the first and second test, respectively. In problem-based learning, the scores were 15.82±3.29 in the first and 27.52±4.72 in the second test. There was a significant difference between the mean scores of post-course exams of the two groups (p=0.001), while no significant difference was observed between the mean scores of pre-course exams of the groups (p=0.550). Conclusion: It may be concluded that problem-based learning method leads to a significant increase in learning and recalling output compared to the traditional method. Given the evolving medical education in the country's medical schools toward problem-based learning, it is suggested that the grounds be laid so that this change will take place based on thought, principles and problem solving.","Background Medical student ultrasound education is sparse. In 2002, we began the first medical student rotation in emergency ultrasound. Objective To evaluate if medical students can learn and retain sonographic skills during a two- or four-week elective. Methods We gave students an exam on the first and last days of the rotation. Six months later, students took the exam a third time. A control group was used for comparison. Results Over a 19-month period, we enrolled 45 students (25 on the two-week and 20 on the four-week elective). The four-week student post-test score was significantly better than the two- week post-test score (81% vs 72%, p=0.003). On the six-month exam, the four-week student post-test score was significantly better than the two-week post-test score (77% vs 69%, p=0.008). The control group did not statistically improve. Conclusion Medical students can learn bedside ultrasound interpretation with clinical integration and retain the knowledge six months later.",22.6464284778091,1,"method, group, effect"
5,student; use; educ; learn; exam; test; question; can; evalu; medic; teacher; assess; studi; score; result,"Over the past decades many teaching strategies have been proposed by various educators to improve education of all students including students with special needs. No single one of these proposed teaching strategies meets the needs of all students. The new Every Student Succeeds Act, successor to No Child Left behind Law, which transfers oversight from federal level back to states, could be a benefactor for constructivism and special education. Educators are also optimistic that the new Every Student Succeeds Act will be better for vulnerable students in special education because it will introduce more flexibility in how individual states carry out evaluation of students and teachers. In addition, it will provide more flexibility on testing and adapt the curriculum to student’s needs. It would further reduce time and energy for students preparing for standardized tests or statewide exams. It will also end “Adequate Yearly Progress”-a measure that required schools to show test score gains. Constructivist teaching philosophy is all about accepting student autonomy where student thinking drives the lessons, where dialogue, inquiry, and puzzlement are valued and assessing student learning is in the context of teaching. It helps teachers to draw on new ideas as they make decisions about which teaching techniques are most appropriate for all students to learn. Now is the time to revisit the great debate of constructivism versus teacher-centered instruction and special education. Time has come to effectively explore our educational system and examine the core unit of the whole enterprise, the textbook, the classroom, a setting that is often dominated by teacher talk and students listen.","Background Shortage of human resources, increasing educational costs, and the need to keep social distances in response to the COVID-19 worldwide outbreak have prompted the necessity of clinical training methods designed for distance learning. Virtual patient simulators (VPSs) may partially meet these needs. Natural language processing (NLP) and intelligent tutoring systems (ITSs) may further enhance the educational impact of these simulators. Objective The goal of this study was to develop a VPS for clinical diagnostic reasoning that integrates interaction in natural language and an ITS. We also aimed to provide preliminary results of a short-term learning test administered on undergraduate students after use of the simulator. Methods We trained a Siamese long short-term memory network for anamnesis and NLP algorithms combined with Systematized Nomenclature of Medicine (SNOMED) ontology for diagnostic hypothesis generation. The ITS was structured on the concepts of knowledge, assessment, and learner models. To assess short-term learning changes, 15 undergraduate medical students underwent two identical tests, composed of multiple-choice questions, before and after performing a simulation by the virtual simulator. The test was made up of 22 questions; 11 of these were core questions that were specifically designed to evaluate clinical knowledge related to the simulated case. Results We developed a VPS called Hepius that allows students to gather clinical information from the patient’s medical history, physical exam, and investigations and allows them to formulate a differential diagnosis by using natural language. Hepius is also an ITS that provides real-time step-by-step feedback to the student and suggests specific topics the student has to review to fill in potential knowledge gaps. Results from the short-term learning test showed an increase in both mean test score (P<.001) and mean score for core questions (P<.001) when comparing presimulation and postsimulation performance. Conclusions By combining ITS and NLP technologies, Hepius may provide medical undergraduate students with a learning tool for training them in diagnostic reasoning. This may be particularly useful in a setting where students have restricted access to clinical wards, as is happening during the COVID-19 pandemic in many countries worldwide.","Background Musculoskeletal (MSK) complaints comprise a large proportion of outpatient visits. However, multiple studies show that medical school curriculum often fails to adequately prepare graduates to diagnose and manage common MSK problems. Current standardised exams inadequately assess trainees’ MSK knowledge and other MSK-specific exams such as Freedman and Bernstein’s (1998) exam have limitations in implementation. We propose a new 30-question multiple choice exam for graduating medical students and primary care residents. Results highlight individual deficiencies and identify areas for curriculum improvement. Methods/Results We developed a bank of multiple choice questions based on 10 critical topics in MSK medicine. The questions were validated with subject-matter experts (SMEs) using a modified Delphi method to obtain consensus on the importance of each question. Based on the SME input, we compiled 30 questions in the assessment. Results of the large-scale pilot test (167 post-clerkship medical students) were an average score of 74 % (range 53% – 90 %, SD 7.8%). In addition, the tool contains detailed explanations and references were created for each question to allow an individual or group to review and enhance learning. Summary The proposed MSK30 exam evaluates clinically important topics and offers an assessment tool for clinical MSK knowledge of medical students and residents. It fills a gap in current curriculum and improves on previous MSK-specific assessments through better clinical relevance and consistent grading. Educators can use the results of the exam to guide curriculum development and individual education.","The visual aids used in teaching and lecturing to students have clearly evolved over the last several decades. Illustrations on paper were replaced by carousels full of photographic slides, which in turn have been supplanted by Powerpoint™ presentations. At an arguably much slower pace, the method of teaching microscopic anatomy to students of the healthcare professions is also changing. For the majority of medical students graduating before 2000, the microscope and accompanying boxes of glass slides were the standard tools for learning both histology and pathology. Studying for exams also included reviewing kodachromes showing static fields-of-view at predetermined magnifications. Both of these methods of learning required the student to be physically present on campus. Pathology residents, when not learning at the microscope with the attending pathologist, must rely on teaching sets of glass slides that cannot leave the department. Group learning must either be done at a multiheaded microscope (which many times has fewer heads than people present) or by use of video technology attached to the microscope. With the advent of digital whole slide imaging (WSI) over the past several years, there is an opportunity to revolutionize the way teaching and learning are done for all students of medicine including doctors, nurses, medical technicians, histology technicians, cytology technicians, and others. Comparison of Digital Whole Slide Images with Glass Slides There are many advantages to using WSI when compared with traditional glass slides [Table 1]. Digital images can be standardized; all students will study the exact same tissue section. Sections on glass slides are inherently variable in quality and content.[1] Although admittedly subtle in some cases, these variabilities can be eliminated with digital imaging. The quality of the image can also be indefinitely maintained compared to glass slides that are vulnerable to fading, breaking, and vanishing.[2] One very helpful aspect of digital images is the use of a thumbnail image. As students are examining the image at higher magnification, they can always refer to the thumbnail for orientation.[3] This obviously is impossible with glass slides. Glass slides cannot be easily annotated with any precision, relying on relatively crude “dotting” for the purposes of highlighting a certain area of the slide. Digital images can have multiple annotations including arrows, circles, text, etc. placed exactly where needed. Portability is another benefit of using digital images. The use of microscopes obligates a student to remain on campus in order to study, review, etc. With WSI loaded onto a web-based server, study can occur wherever and whenever the student wishes.[2] WSI also makes simultaneous viewing of a particular field-of-view possible; a major advantage over glass slides. Viewing the image on a common computer monitor encourages discussion and collaboration between classmates.[1] Finally, storage of WSI becomes a matter of having enough server memory. As server space becomes less and less expensive, the cost and effort of storing and maintaining both the microscopes and glass slide sets will become comparatively more burdensome.[3] Some disadvantages that have become apparent with WSI include the dependence of the image quality on monitor resolution and the challenge of scanning tissue sections that have artifacts such as folds, etc.[3] Judicious choice of an acceptable non-cost prohibitive monitor is essential for an accurate image. As digital scanners become “smarter”, the flaws in a slide will likely become less of an issue. Table 1 Benefits of digital slide imaging Educational Applications of Digital Whole Slide Imaging The educational applications for this technology are growing. Histology and pathology laboratories and small group study sessions are the early opportunities for medical student use either in a formal computer laboratory or via personal laptops. For those students choosing a pathology residency, WSI can be used for didactic lectures and unknown conferences. Independent study can be encouraged and facilitated with the use of organ-system-based teaching sets, of both neoplastic and non-neoplastic diseases. Diagnostic skills can also be assessed with WSI exams. One academic center looked at the reliability of WSI for measuring resident competency. Using a set of 20 questions based upon 20 whole slide images, junior and senior residents were tested. They determined that the correlation between exam score and months of training was high, the correlation with the resident in-service examination (RISE) was not quite as high, and that the exam could reliably discriminate between junior and senior residents.[4] WSI can also be used for teaching residents or fellows in clinical fields. For pathologists in either academic or non-academic medical centers, WSI can be implemented into both teaching and working interdepartmental conferences such as tumor boards and biopsy conferences (renal, liver, transplant, etc.). For the established pathologist, WSI has become a convenient method of acquiring continuing medical education credits offered through national pathology organization websites. Additional uses for WSI including the creation of electronic books will certainly evolve over time.","Introduction Emergency care of older adults requires specialized knowledge of their unique physiology, atypical presentations, and care transitions. Older adults often require distinctive assessment, treatment and disposition. Emergency medicine (EM) residents should develop expertise and efficiency in geriatric care. Older adults represent over 25% of most emergency department (ED) volumes. Yet many EM residencies lack curricula or assessment tools for competent geriatric care. Fully educating residents in emergency geriatric care can demand large amounts of limited conference time. The Geriatric Emergency Medicine Competencies (GEMC) are high-impact geriatric topics developed to help residencies efficiently and effectively meet this training demand. This study examines if a 2-hour didactic intervention can significantly improve resident knowledge in 7 key domains as identified by the GEMC across multiple programs. Methods A validated 29-question didactic test was administered at six EM residencies before and after a GEMC-focused lecture delivered in summer and fall of 2009. We analyzed scores as individual questions and in defined topic domains using a paired student t test. Results A total of 301 exams were administered; 86 to PGY1, 88 to PGY2, 86 to PGY3, and 41 to PGY4 residents. The testing of didactic knowledge before and after the GEMC educational intervention had high internal reliability (87.9%). The intervention significantly improved scores in all 7 GEMC domains (improvement 13.5% to 34.6%; p<0.001). For all questions, the improvement was 23% (37.8% pre, 60.8% post; P<0.001) Graded increase in geriatric knowledge occurred by PGY year with the greatest improvement post intervention seen at the PGY 3 level (PGY1 19.1% versus PGY3 27.1%). Conclusion A brief GEMC intervention had a significant impact on EM resident knowledge of critical geriatric topics. Lectures based on the GEMC can be a high-yield tool to enhance resident knowledge of geriatric emergency care. Formal GEMC curriculum should be considered in training EM residents for the demands of an aging population.","This study aims to develop an Android app to support learning activities consisting of mobile applications and web server applications. Mobile applications have two applications: teacher apps and student applications, while teachers and administrators use web server applications. Mobile apps run on Android smartphones, while web server applications are in Chrome web browsers. In mobile applications, students can view material with pictures and videos, do online tests, perform tasks, view simulations, view announcements in the form of updates made by teachers, and see recap test scores, assignments, exams, and final score in a chapter. In a mobile application, the teacher can see how many times students access the material, view the student's time notice in performing tests and tasks, view the test scores, duties, exams and the final grade of each student who is registered on the web server. Administrator applications on the web server focus more on managing the data that will changes. This application can run on Android operating system Jelly Bean and above. The development used refers to the ADDIE model with the following stages: 1) Analysis, 2) Design (design), 3) Development (development), and 4) Evaluation (evaluation/feedback). The developed media has been validated by subject experts, media experts and high school physics teachers with average percentage of all aspects of subject experts is 85.50%, media experts 85.20% and physics teachers 90%, based on these results show that mobile learning android platform based on web service proper to use as a media of physics learning.","Background: Undergraduate medical examination is undergoing extensive re evaluation with new core educational objectives being defined. Consequently, new exam systems have also been designed to test the objectives. Objective structured practical examination (OSPE) is one of them. Objectives: To introduce OSPE as a method of assessment of practical skills and learning and to determine student satisfaction regarding the OSPE. Furthermore, to explore the faculty perception of OSPE as a learning and assessment tool. Materials and Methods: The first M.B.B.S students of 2011 12 batch of Medical College, Kolkata, were the subjects for the study. OSPE was organized and conducted on “Identification of Unknown Abnormal Constituents in Urine.” Coefficient of reliability of questions administered was done by calculating Cronbach's alpha. A questionnaire on various components of the OSPE was administered to get the feedback. Results: 16 students failed to achieve an average of 50% or above in the assessment. However, 49 students on an average achieved >75%, 52 students achieved between 65% and 75%, and 29 students scored between 50% and 65%. Cronbach's alpha of the questions administered showed to be having high internal consistency with a score of 0.80. Ninety nine percent of students believed that OSPE helps them to improve and 81% felt that this type of assessment fits in as both learning and evaluation tools. Faculty feedback reflected that such assessment tested objectivity, measured practical skills better, and eliminated examiner bias to a greater extent. Conclusion: OSPE tests different desired components of competence better and eliminated examiner bias. Student feedback reflects that such assessment helps them to improve as it is effective both as teaching and evaluation tools.","Undergraduate students struggle to read the scientific literature and educators have suggested that this may reflect deficiencies in their science literacy skills. In this two-year study we develop and test a strategy for using the scientific literature to teach science literacy skills to novice life science majors. The first year of the project served as a preliminary investigation in which we evaluated student science literacy skills, created a set of science literacy learning objectives aligned with Bloom’s taxonomy, and developed a set of homework assignments that used peer-reviewed articles to teach science literacy. In the second year of the project the effectiveness of the assignments and the learning objectives were evaluated. Summative student learning was evaluated in the second year on a final exam. The mean score was 83.5% (±20.3%) and there were significant learning gains (p < 0.05) in seven of nine of science literacy skills. Project data indicated that even though students achieved course-targeted lower-order science literacy objectives, many were deficient in higher-order literacy skills. Results of this project suggest that building scientific literacy is a continuing process which begins in first-year science courses with a set of fundamental skills that can serve the progressive development of literacy skills throughout the undergraduate curriculum.","Background Large language models (LLMs) have revolutionized natural language processing with their ability to generate human-like text through extensive training on large data sets. These models, including Generative Pre-trained Transformers (GPT)-3.5 (OpenAI), GPT-4 (OpenAI), and Bard (Google LLC), find applications beyond natural language processing, attracting interest from academia and industry. Students are actively leveraging LLMs to enhance learning experiences and prepare for high-stakes exams, such as the National Eligibility cum Entrance Test (NEET) in India. Objective This comparative analysis aims to evaluate the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. Methods In this paper, we evaluated the performance of the 3 mainstream LLMs, namely GPT-3.5, GPT-4, and Google Bard, in answering questions related to the NEET-2023 exam. The questions of the NEET were provided to these artificial intelligence models, and the responses were recorded and compared against the correct answers from the official answer key. Consensus was used to evaluate the performance of all 3 models. Results It was evident that GPT-4 passed the entrance test with flying colors (300/700, 42.9%), showcasing exceptional performance. On the other hand, GPT-3.5 managed to meet the qualifying criteria, but with a substantially lower score (145/700, 20.7%). However, Bard (115/700, 16.4%) failed to meet the qualifying criteria and did not pass the test. GPT-4 demonstrated consistent superiority over Bard and GPT-3.5 in all 3 subjects. Specifically, GPT-4 achieved accuracy rates of 73% (29/40) in physics, 44% (16/36) in chemistry, and 51% (50/99) in biology. Conversely, GPT-3.5 attained an accuracy rate of 45% (18/40) in physics, 33% (13/26) in chemistry, and 34% (34/99) in biology. The accuracy consensus metric showed that the matching responses between GPT-4 and Bard, as well as GPT-4 and GPT-3.5, had higher incidences of being correct, at 0.56 and 0.57, respectively, compared to the matching responses between Bard and GPT-3.5, which stood at 0.42. When all 3 models were considered together, their matching responses reached the highest accuracy consensus of 0.59. Conclusions The study’s findings provide valuable insights into the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. GPT-4 emerged as the most accurate model, highlighting its potential for educational applications. Cross-checking responses across models may result in confusion as the compared models (as duos or a trio) tend to agree on only a little over half of the correct responses. Using GPT-4 as one of the compared models will result in higher accuracy consensus. The results underscore the suitability of LLMs for high-stakes exams and their positive impact on education. Additionally, the study establishes a benchmark for evaluating and enhancing LLMs’ performance in educational tasks, promoting responsible and informed use of these models in diverse learning environments.","Assessment Test is one of the routine agenda that is carried out every semester change. This test is conducted to see the development of students in learning activities. Currently SMK 5 Kota Tangerang already uses a mobile application using the PENTAS application in answering the exam questions. But this application needs to be done to understand applications that can be used properly, or vice versa. This study uses the System Usability Scale (SUS) method to measure the use of this application for use. This SUS method has 10 questions that will be answered by respondents who are directly involved in using the PENTAS application. The average score obtained by the System Use Scale method is 46.00. These results fall into the Unacceptable category, so this PENTAS application is not good for use.",23.6080655848847,3,"teacher, educ, evalu"
