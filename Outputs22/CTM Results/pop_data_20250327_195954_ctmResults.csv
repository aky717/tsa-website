Topic_Number,Keywords,Abstract_1,Abstract_2,Abstract_3,Abstract_4,Abstract_5,Abstract_6,Abstract_7,Abstract_8,Abstract_9,Abstract_10,Perc_of_Corpus,Topic Cluster,Summary topic
1,new; space; field; gravit; world; energi; earth; physic; develop; system; time; soil; theori; paper; scienc,"In 2000, the author published a new discovery about the same-sex charge produced by friction of the same substance at the ninth electrostatic academic conference of Chinese physical society. For this important new experimental discovery, the author puts forward a new understanding of “positive and negative charges” and finds a new theory to explain all electrostatic effects. Based on the subversive new understanding of “matter”, “entity” and “heat energy”, a new understanding of “particle charge dynamic atomic model” is initiated. It is clarified that the relationship between “entity” and “heat energy” is the root of the existence of gravitation and repulsion between matter, The law of equilibrium distance between gravity and repulsion is put forward. This paper reveals the causes of the formation of the earth’s gravity and many phenomena of attraction and repulsion force in the universe and so on. In the fields of gravitational field, magnetic field, electric field and so on, a series of important scientific problems have been revealed! The establishment of the new theoretical system provides a new vision for solving “all physical problems”! The new theoretical system consists of six parts: the first part introduces the reasons for the establishment of the “new theoretical system”, the second part proposes a new basic epistemology of the material world, the third part is a new epistemology of the gravitational repulsion field, the fourth part is a new epistemology of the magnetic field, and the fifth part is a new epistemology of the electric field, and the sixth part expounds the scientific significance of the new theoretical system. Starting from a new perspective of the basic composition of “entity” and “heat energy” in the material world, this paper makes a new understanding of matter, entity, heat energy, atom, element, gravity, repulsion, magnetic field and electric field, Established 21st century physics new theoretical system, Material world: “entity” and “heat energy” constitute “unified field theory”. Scientific research needs a new vision to expand the subjective human thought’s understanding of the objective nature. The establishment of this new theoretical system may lead to a new physics revolution in the 21st century.","This issue is published as the Proceedings of the 6th Edoardo Amaldi Conference on Gravitational Waves, held on 20–24 June 2005 at Bankoku Shinryoukan in Okinawa, Japan. Since the first Amaldi conference was held in Frascati in 1994, eleven years have passed and the scale of the conference has grown with the increasing activity in the field of gravitational waves. As the centenary celebration of Einstein's `miracle year', 2005 was called `World Year of Physics'. Among his breakthroughs published in 1905, the special theory of relativity is recognized as the most significant revolution in physics, completely changing our views concerning time and space. Ten years later, Einstein proposed the general theory of relativity, by which he predicted the existence of gravitational waves (GWs). At that time, it was only a dream to observe a GW because its effect was so small. Efforts to detect GWs, pioneered by Weber, have continued for almost 40 years, yet their detection remained a dream. However, the presentations at this conference have convinced us that it is no longer a dream. The GW detector projects have made extraordinary advances; in particular, the significant sensitivity improvement of LIGO and the completion of the VIRGO detector mark the beginning of the new era of GW physics. Firm developments in theories and source estimations were also reported. In particular, the data analysis session was very active and various discussions were held. Elaborate experimental techniques were presented, some of them already achieving the requirements for the next generation of detectors, such as Advanced LIGO and LCGT. In addition to the earth-based detectors, many presentations concerning space detectors were contributed; they indicated that space would become the new stage for GW physics and astronomy. This issue brings together the papers which were presented at this exciting conference. The proceedings comprise two volumes; the largest part is published as a volume of Journal of Physics: Conference Series and the other is a special issue of Classical and Quantum Gravity (CQG), presenting the highlights of the conference. This is the first time this format has been used and selecting the highlights for CQG was a difficult task as the quality of the papers submitted was so high. The issue has been published thanks to the excellent work of the reviewers who gave precise and appropriate comments to the Editors. We strongly believe this issue to be a milestone in the inception of GW astronomy. The conference organizers would like to acknowledge the financial support of IUPAP, Okinawa prefecture, Inoue Foundation for Science, The Foundation for Promotion of Astronomy and a Grant-in-Aid for Scientific Research on Priority Areas (415) of the Ministry of Education, Culture, Sports, Science and Technology. The conference scientific programme was organized with the help of the session conveners. Their collaboration was indispensable for the success of the conference. We also appreciate the members of the international advisory committee and the local organizing committee; in particular, we thank Dr Akiteru Takamori for designing the fascinating poster of the conference and the image for the CD of this issue. The miscellaneous duties that were necessary for the conference were carried out with the help of ICS Convention Design Inc. with special thanks due to Ms Makiko Uwato and Mr Hiroyuki Suzuki. The proceedings are published by Institute of Physics Publishing; we would like to express our deep appreciation to Ms Judith Adams for her efficient management of the proceedings. Finally, we thank all of the excellent participants who made the conference so successful.","This issue is published as the Proceedings of the 6th Edoardo Amaldi Conference on Gravitational Waves, held on 20–24 June 2005 at Bankoku Shinryoukan in Okinawa, Japan. Since the first Amaldi conference was held in Frascati in 1994, eleven years have passed and the scale of the conference has grown with the increasing activity in the field of gravitational waves. As the centenary celebration of Einstein's `miracle year', 2005 was called `World Year of Physics'. Among his breakthroughs published in 1905, the special theory of relativity is recognized as the most significant revolution in physics, completely changing our views concerning time and space. Ten years later, Einstein proposed the general theory of relativity, by which he predicted the existence of gravitational waves (GWs). At that time, it was only a dream to observe a GW because its effect was so small. Efforts to detect GWs, pioneered by Weber, have continued for almost 40 years, yet their detection remained a dream. However, the presentations at this conference have convinced us that it is no longer a dream. The GW detector projects have made extraordinary advances; in particular, the significant sensitivity improvement of LIGO and the completion of the VIRGO detector mark the beginning of the new era of GW physics. Firm developments in theories and source estimations were also reported. In particular, the data analysis session was very active and various discussions were held. Elaborate experimental techniques were presented, some of them already achieving the requirements for the next generation of detectors, such as Advanced LIGO and LCGT. In addition to the earth-based detectors, many presentations concerning space detectors were contributed; they indicated that space would become the new stage for GW physics and astronomy. This issue brings together the papers which were presented at this exciting conference. The proceedings comprise two volumes; the largest part is published as a volume of Journal of Physics: Conference Series and the other is a special issue of Classical and Quantum Gravity (CQG), presenting the highlights of the conference. This is the first time this format has been used and selecting the highlights for CQG was a difficult task as the quality of the papers submitted was so high. The issue has been published thanks to the excellent work of the reviewers who gave precise and appropriate comments to the Editors. We strongly believe this issue to be a milestone in the inception of GW astronomy. The conference organizers would like to acknowledge the financial support of IUPAP, Okinawa prefecture, Inoue Foundation for Science, The Foundation for Promotion of Astronomy and a Grant-in-Aid for Scientific Research on Priority Areas (415) of the Ministry of Education, Culture, Sports, Science and Technology. The conference scientific programme was organized with the help of the session conveners. Their collaboration was indispensable for the success of the conference. We also appreciate the members of the international advisory committee and the local organizing committee; in particular, we thank Dr Akiteru Takamori for designing the fascinating poster of the conference and the image for the CD of this issue. The miscellaneous duties that were necessary for the conference were carried out with the help of ICS Convention Design Inc. with special thanks due to Ms Makiko Uwato and Mr Hiroyuki Suzuki. The proceedings are published by Institute of Physics Publishing; we would like to express our deep appreciation to Ms Judith Adams for her efficient management of the proceedings. Finally, we thank all of the excellent participants who made the conference so successful.","The issue of the journal begins with an article on French sinology. French sinology takes a special place in the history of the sinological studies development. It was France that became the first country where the transformation of missionary sinology, which was common among a limited circle of researchers (mainly in a religious sphere), into the academic scientific discipline, which had already been taught and studied at a professional level in academic institutions, occurred. The Parisian type of sinology used to dominate the entire world for a long time, including such powerful centers of Chinese studies as Germany, Great Britain, the USA, and China itself. In order to form a complete picture of sinology development in France, the authors singled out and analyzed three historical periods covering the entire history of Chinese studies development, starting from its birth and flourishment to the process of stagnation. Modern scientific communication traditionally uses visual narratives, such as comics, for education, presentation of scientific achievements to a mass audience, and as an object of research. In the article by Oksana Hudoshnyk and Oleksandr P. Krupskyi, offers a three-level characterization of the interaction of comic culture and science in a diachronic aspect. Attention is focused not only on the chronological stages of these intersections, the expression of the specifics of the interaction is offered against the background of scientific and public discussions that accompany the comics–science dialogue to this day. Emphasis is placed on the unique phenomenon of the simultaneous concordance of various stages of the dialogue between comics and science, on the prolonged replication of successful inventions into modern experience, and the active testing of known narratives at new levels of a scientific presentation. The next paper assesses the topicality of Vernadsky's concept of the noosphere, coined over almost twenty years starting in the early 20th century. Emphasizing the uniqueness of Vernadsky's concept of the noosphere as the transformation of the biosphere by a man using reason, we concentrate on the assessment of the utopian or realistic nature of his vision of the future of humanity. Based on the philosophical case-studies analysis, it identifies the ideological roots of the noosphere concept, the development of views on the concept in time, the role of reason and scientific thinking, the opinions of its supporters and critics, and Moiseev's related concept of co-evolution. Lectures de Potentia Restitutiva or Of Spring: Explaining the Power of Springing Bodies (1678) is an important book for the history of science. This book is better known for Hooke’s presentation of the law that bears his name. In the article by Isadora Monteiro, seeks to study the Lectures de Potentia Restitutiva once again to better understand Hooke’s thoughts about the rule which bears his name and his conception of gravity, which the author considered a force. Here Hooke’s definitions of body and motion will be presented, as well as his actual objective when he formulated the so-called Hooke’s Law. As we will see, Hooke intended to create a “philosophical scale” to measure the gravitational attraction between bodies. By considering his previous publications, such as An attempt to prove the motion of the Earth from Observations or Micrographia: or some Physiological Descriptions of Minute Bodies, or even unpublished works such as On the inflection of a direct motion into a curve by supervening Attractive principle, it becomes clear that Hooke was already opening a path toward an understanding of gravity before Newton’s Principia (1687) were published. By taking into account the controversy between Isaac Newton and Robert Hooke, we also intend to strengthen the idea that Hooke was an indispensable contributor to the elaboration of a law of universal gravitation. In 1915, the first occupational therapy school was founded by Jane Addams at Hull House (Chicago, USA). In that process, Addams inspired the first generation of occupational therapists, especially Eleanor Clarke Slagle. Thus, in the article by Rodolfo Morrisonseeks to highlight the contribution of Jane Addams to the development of Occupational Therapy through an in-depth bibliographic review, from primary sources. The next article presents the results of a study of the features of biographical and prosopographic materials about famous mathematicians and natural scientists, published in one of the most authoritative journals “Bulletin of Experimental Physics and Elementary Mathematics”, which was published in Kyiv and Odesa during 1886–1917. In fact, the journal was an unofficial periodical printed branch of the Mathematical Department of the Novorossiysk Society of Naturalists. The aim of the next research is to study the policy efforts conducted by the Indonesian government since the beginning of independence in 1945 to present, in advancing science and technology and innovation. A content analysis approach is employed to identify each stipulated regulation in Indonesia in the form of Laws, Government Regulations, Presidential Regulations, Presidential Decrees, and Presidential Instructions. There are 78 regulations in the field of science and technology and innovation that are analyzed. The results of the analysis are described based on the emergence of regulations and institutional implications generated as part of the ecosystem. In the article by Ihor Annienkov, based on the problem-chronological, comparative-historical, historiographical, and source-research methods, as well as the method of actualization, identifies the extent of borrowing foreign design and technological solutions in the Ukrainian Soviet Socialist Republic for projecting electrical machines in the second half of the 1930s, as well as the reasons for the absence of unambiguous information in historiography regarding the existence of this phenomenon in the republic at this chronological stage. The publication provides a general assessment of the quality of scientific support for the processes of creating electrical machines, establishes the ways of fulfilling the scientific-technical borrowings that were studiedand the dynamics of their development, analyzes their role in the growth of the technical level of products of the Ukrainian electrical machine-building branch. In the article by Mykola Ruban and Andrii Fomin, attempts to investigate the historical circumstances of the mastering and development of the industrial production of rolling stock in Ukraine from 1991 to 2021. In the course of the scientific development of the proposed research, materials from mass-circulation newspapers, industry publications of railway transport, as well as technical studies of employees of manufacturing plants were used. The next discusses the conditions and prerequisites for choosing the location of the plant; considers the stage of the establishment (foundation) of the plant; examines the stage of plant construction and equipping it with technological facilities in detail; analyzes the development and establishment of the plant between 1897 and 1914. A brief analysis of locomotive designs produced by the Kharkiv Locomotive Plant from 1897 to 1914 has been made. The article shows the significance of Consultative Congresses of Traction Engineers for the development of railway machinery both at Kharkiv Locomotive Plant and for the entire railway industry. The purpose of next study is to highlight the peculiarities of the development of the Russian aviation industry during the First World War. The focus is on analyzing production programs and matching their quantitative and qualitative parameters to war requirements. Production plans of leading Russian aviation factories as well as qualitative and quantitative parameters of products have been analyzed in the article.","The purpose of this research discussion paper is to understand the Islamic issues involved in Space Travel, which is a novel field. Hitherto, only limited research has been undertaken on how Muslim astronauts can maintain their Islam for a prolonged period away from the Earth. This paper will commence with an introduction to Islamic law (which includes the distinct term fiqh), before discussing the obligations of Muslims in space. Also discussed in this paper will be the Maqasid, or higher objectives, which provides an avenue for Muslim space travelers to maintain their Islam within the framework of the religion. The methodology used in this paper is based on research of existing literature, comments from previous Muslim astronauts as well as a review of Muslim law that pertains to travel. The finding of this paper sets out the application of Islamic Law for interstellar Space Travel and off-world colonisation. It discusses the relevant ibadah rulings (literally meaning religious rituals such as prayer, fasting, ablution, keeping halal, and death rites inter alia) and how these can be practically applied in the context of space travel. This paper also outlines the moral, legal and practical challenges faced by a Muslim undertaking Space Travel and discusses the relevant Islamic ‘knowledge’ that may assist in reconciling these issues. The term interstellar Space Travel and colonisation is used to refer to those activities that are performed away from the Earth, such as in the micro-gravity of space or on an off world colony i.e., Mars. This paper is unique from other published papers in the field as it contemplates off world habitation and not just a short-term sojourn into space. The research finding is that Islamic Law is able to adapt to the challenges of space by incorporating how early Muslims maintained their Islam while traveling long distances outside their home countries. This is an emerging area of study, so there is a dearth and scarcity of literature about Muslims in space written from a scholarly perspective. This paper intends to rectify this situation by providing a marker for other scholars and researchers to follow","Imagine you could choose a new set of eyes that would help you see things you have never been able to see before. Maybe you would choose Superman’s X-ray vision, or maybe you would prefer to zoom into tiny things and see the wonders of the microscopic world. Science has recently gained a new set of eyes—a new way to look into the mysteries of the universe—using gravitational waves, which are waves produced by gravity itself. In this article, I will take you on a journey that begins with an explanation of gravity—from the classical perspective of Isaac Newton to the modern and more complex view of Albert Einstein. I will then explain how movements of massive objects create gravitational waves, which are ripples in space and time, and how they might be used to explain some mysteries of the universe, and even help us to understand the origins of our planet Earth.","IN 1990, THE GERMAN ASTRONOMERS Freimut Borngen and Lutz Schmadel named an asteroid after one of the foremost political philosophers of the twentieth century, the German Jewish emigre Hannah Arendt.1 Whether Arendt would have appreciated the gesture is uncertain.2 After all, she opened her philosophical masterpiece The Human Condition (1958) by voicing grave concerns about a second satellite— Sputnik. In 1957, man had for the first time propelled his artifacts into the beyond, and he was likely to follow by propelling himself as well. But to desire to depart from the scene of the world, she felt, meant also to think of the world as something worth leaving. To emancipate ourselves from its physical limits—gravity—meant also to emancipate ourselves from the gravity of its existential claims upon us. Sputnik therefore embodied an impulse already much in evidence on Earth—to create an artificial planet. In Sputnik the ambitions of modern man lay revealed.3 These ambitions were ominous. They had also in part been realized. The Human Condition appeared not long after Arendt’s famous study The Origins of Totalitarianism (1951), and she advanced through Sputnik some of the themes broached in that earlier effort. Totalitarianism, it turns out, shared something important with the Russian satellite. Sputnik embodied a desire to fabricate an artificial substitute for the living Earth. Totalitarianism, in turn, distinguished itself from every other form of rule in its ambition to create a new world fit to compete with this one, the nontotalitarian world, and its success was to be measured in the consistency of its artful fiction. Totalitarian regimes create an “artificially fabricated insanity,” and “their art consists in using and at the same time transcending the elements of reality.”4 To-","The work relates to the field of research of gravitational fields, in particular, their wave, energy and force parameters for planetary level objects. Based on the analysis of the problems of their determination for the Earth, it is shown that the relationship of these parameters does not have an explicit form, which complicates the task of their determination. The solution of this problem is the main goal of the work performed, and its scientific novelty is a new principle of substantiation of the action of gravitational forces. The research methods used in the work are based on deduction and induction, the general principles of the theory of knowledge and the application of reliable laws of physics. Work results. A fundamentally new approach is proposed, on the basis of which new calculated dependences and their numerical values were found for the first time to determine the action of the forces of gravity of planetary systems. They are confirmed by comparative calculations of the new gravitational parameters of the Earth, which agree well with its known parameters. Conclusions. For the first time, new scientific data have been obtained, which significantly expand the range of parameters of the gravitational field of the planets and the level of knowledge of the fundamentals of the material world.","Unmanned aerial vehicles (UAVs) are increasingly attracting investment and development attention from many countries all over the world due to their great advantages. However, one of the biggest challenges for researchers is the problem of supplying energy to UAVs to ensure they can operate for a longer time. Especially in the case of rotary wings, they consume more energy than other UAV types as the motors need to spend a lot of energy to operate in order to overcome the gravity of the earth. The article aims to research power supply, energy consumption on UAVs, and a method of taking advantage of external energy sources to provide power for the operation of UAVs and discuss UAVs’ structure, categories, and control. Two experiments were conducted separately to evaluate the energy consumption of UAVs and the energy conversion from external energy sources to electrical energy. A test bench was designed to evaluate and determine the maximum efficiency using regenerative braking mode. The measuring device was manufactured to measure the necessary parameters to calculate the energy consumption and performance of the system. Experimental numerical results show that energy conversion from external sources is one of methods that can help increase the flight time of the UAV.","Gravitation is one of the basic phenomena of the world. Tremendous number of theoretical works on origin, nature, essentials, consequences, etc. of the gravitation and related phenomena were published so far. The most prominent ones are based on the Albert Einstein's general theory of relativity. The author of this communication based his approach to the gravitation on Isaac Newton's law of the universal gravitation and related quantities, i.e. gravitational forces of matter objects, distance and motion. Namely on the fact, that the gravitation force is - as well as the inertia, mass, space ""occupied"" and other properties are - principal features/attributes/properties of matter objects. Gravitation is an additive property of matter objects. Taking into account other positivistic quantities like mass of the Earth, standard acceleration of gravity, and the value of the atomic unit of mass, the author defined a gravitational force of atomic unit (or ""the Gravitational Force Quantum"") as a gravitational force which exerts one atomic unit of Earth's mass on 1 kilogram of a mass on Earths surface, and he calculated its value: GFO = 1.4958 × 10 -54 N. This quantity can be useful for further development of the ""quantum mechanical"" approach to the description and general notion about the world.",24.8543605522539,2,space
2,earth; space; graviti; system; et_al; effect; increas; ocean; human; flow; can; use; world; chang; climat,"Two-phase gas-liquid systems have wide applications both on Earth and in space. On Earth, they occur in a variety of process equipment, such as petroleum production facilities, condensers and re-boilers, power systems and core cooling of nuclear power plants during emergency operation. The potential space applications include active thermal control system, power cycle, storage and transfer of cryogenic fluids, and so on. Reliable design of such systems requires a thorough understanding of the mechanism of two-phase flow, such as the phase distributions (flow patterns), pressure drops and heat transfer coefficients at different gas and liquid flow rates. Among them, flow patterns will play an important role because of strong influence of the phase distributions on pressure drops and heat transfer coefficients and thus attract more attentions of the academic and technical communities all over the world. With the aid of numerous meticulous experiments, our present knowledge on two-phase gas-liquid systems has been built. It is, however, far from complete due to the complicate influence of gravity which is a dominant factor in normal gravity. Gravity strongly affects many phenomena of two-phase gas-liquid systems by creating forces in the systems that drive motions, shape boundaries, and compress fluids. Furthermore, the presence of gravity can mask effects that ever present but comparatively small. Depending on the flow orientation and the phase velocities, gravity can significantly alter the flow patterns, and hence the pressure drops and heat transfer rates associated the flow. Advances in the understanding of two-phase flow have been greatly hindered by masking effect of gravity on the flow. Therefore, the microgravity researches will be conductive to revealing of the mechanism underlying the phenomena, and then developing of more mechanistic models for the two-phase flow and heat transfer both on Earth and in space. Research on two-phase gas-liquid flow in microgravity has a history of more than 50 years with a short pause in the 1970s and has been advanced with the development of various microgravity facilities and with increased experimental opportunities, especially in the last two decades. Due to much strict restriction on flight chance, weight and size of the test facility, power supply, and so on, studies on two-phase gas-liquid flow in microgravity are","Nucleate pool boiling is a daily phenomenon transferring effectively high heat flux. It is, however, a very complex and illusive process because of the interrelation of numerous factors and effects as the nucleate process, the growth of the bubbles, the interaction between the heater’s surface with liquid and vapor, the evaporation process at the liquidvapor interface, and the transport process of vapour and hot liquid away from the heater’s surface. Among many sub-processes in boiling phenomenon, gravity can be involved and play much important roles, even enshroud the real mechanism underlying the phenomenon. Our present knowledge on nucleate pool boiling phenomenon has been built with the aid of numerous meticulous experiments in normal gravity environment on the ground where gravity is a dominant factor. Gravity strongly affects boiling phenomenon by creating forces in the systems that drive motions, shape boundaries, and compress fluids. Furthermore, the presence of gravity can mask effects that ever present but comparatively small. Advances in the understanding of boiling phenomenon have been greatly hindered by masking effect of gravity. Microgravity experiments offer a unique opportunity to study the complex interactions without external forces, such as buoyancy, which can affect the bubble dynamics and the related heat transfer. Furthermore, they can also provide a means to study the actual influence of gravity on the boiling. On the other hand, since many potential applications exist in space and in planetary neighbours due to its high efficiency in heat transfer, pool boiling in microgravity has become an increasing significant subject for investigation. Therefore, the microgravity researches will be conductive to revealing of the mechanism underlying the phenomenon, and then developing of more mechanistic models for the related applications both on Earth and in space. Research on boiling heat transfer in microgravity has a history of more than 50 years with a short pause in the 1970s and has been advanced with the development of various microgravity facilities and with increased experimental opportunities, especially in the last two decades. On the progress in this field, many comprehensive reviews and monographs are available now. Among many others, Straub (2001), Di Marco (2003), Kim (2003), and Ohta (2003a, b) summarized the experimental and theoretical works all over the world, which provided the status of this field at the beginning of our research. In the past decade, two research projects on nucleate pool boiling in microgravity have been conducted aboard the Chinese recoverable satellites by our group in the National","Scarce and expensive housing and consumer waste disposal are global challenges in today’s world. This study investigated the engineering properties of a clay stabilized with three waste glass sizes (less than 75 μm, greater than 150 μm but less than 75 μm, and less than 300 μm but greater than 150 μm) for the production of burnt clay bricks for earth building construction. Laboratory tests (sieve analysis, Atterberg limits, specific gravity, and compaction tests) were conducted on the clay soil sample, while firing shrinkage, water absorption, unit weight and compressive strength tests were conducted on the fired clay bricks. The unit weight, firing shrinkage and compressive strength decreased with an increasing particle size of the waste glass in the fired clay bricks, while the fired clay bricks absorbed more water as the particle size of its waste glass content decreased. The use of waste glass with particle sizes less than 75 μm for stabilizing the clay was found to produce fired clay bricks with the highest compressive strength. The compressive strength of the fired clay bricks containing less than 75 μm particle sizes of waste glass was increased by 43.9% when compared with the compressive strength of the fired clay bricks having no waste glass. Consequently, waste glass with particle sizes of less than 75 μm is recommended for use in the production of fired clay bricks. The use of waste glass, which could have been a nuisance to the environment, is a potential way of improving the strength of bricks and making them more affordable bricks and consequently, making housing more affordable.","In 1998 over 75% of the world’s population lived within 500 vertical meters above sea level (Cohen and Small, 1998; Peacock, 1998). This variation is generally inconsequential to physiological systems and inhabitants traveling within these elevations rapidly acclimate. Only about 0.004% of the world’s population lives above 5000 m (0.53 atm or 0.537 bar), where the fall in atmospheric pressure reduces the oxygen molecules present, now at nearly one-half (~11.2%) that at sea level, and thus reduces the driving pressure for gas exchange in the lungs (Tremblay and Ainslie, 2021). Extending further in elevation physiological responses and adaptation, say to high altitude flight and space travel, can only be achieved using specialized life support systems. Another extreme occurs below sea level. Due to ambient pressure and CO2 buildup a human subject on average can breathe air through a tube at a depth of less than 1 m underwater. Air can still be used to a depth of about 60 m in recreational diving using specialized equipment to regulate the pressured air from a tank. Below that level non-recreational open-sea dives to a record depth 534 m (“Hydra 8” program) have been performed using exotic heliox (helium and O2) and hydrox (hydrogen and O2) mixtures or even deeper, e.g. ~700 m, using an atmospheric diving suit. Going a step further one diver, Theo Mavrostomos, spent 2 hours under 71.1 atm of pressure in an onshore hyperbaric chamber in a simulated dive to 701 m using hydreliox (exotic breathing gas mixture of helium, oxygen and hydrogen). Challenges to human habitation are mounting even at our “sweet” zone of sea level. These are such snapshots of what physiologists face in the laboratory and in the field to better query the physiological adaptations of life on Earth and in its extremes including underwater and in space. The present Research Topic, “Insights into Environmental, Aviation, and Space Physiology”, presents five original studies focusing on decompression sickness (Karimpour et al.), locomotion training (Borzyhk et al.) and performance (Miyatsu et al. ), and space-related travel (Clément et al. and Mu et al.); two reviews on pulmonary edema (Tetzlaff et al.) and space-related travel (Barkaszi et al.); and a perspective on gravity’s effect on biology (Narayanan). This volume starts of a more comprehensive examination targeting environmental, aviation, and space physiology. Later volumes will be directed to understand how climate extremes, among them especially temperature, are radically changing and adversely affecting once habitable zones on Earth and the physiological adaptation of OPEN ACCESS","It would be an overstatement to suggest that the science of Earth’s climate system has led a sheltered life. For one thing, it has grown out of a long history of public service (e.g., weather forecasting for the public and private sectors; oceanography and marine meteorology for naval applications). For another, public interest in climatic events — ice ages, nuclear winter, El Nino, sea-level change — is sufficiently high that climate is nearly continuously in the news and has been for years. However, compared to many other branches of science — biomedicine and nuclear physics come to mind — the community of scientists who investigate the workings of Earth’s climate has tended to avoid the spotlight. They did this with fair success until recently, when global warming came along. Now, they are thrust into the glare of public scrutiny due to the controversy over projections of the rise of global temperatures associated with increases of carbon dioxide and other greenhouse gases in the atmosphere. Earth’s climate is an extraordinarily complicated physical, chemical, and biological system. Simulating its behavior is both challenging and fraught with uncertainty due to chaotic processes within the climate system itself and lack of knowledge about future atmospheric composition as well as both known and unknown deficiencies in the computer models used for the simulations. When public scrutiny becomes part of the equation, matters become even more complicated, because explaining the complexities of the climate’s behavior to the lay public is a challenge unto itself. Unfortunately, this challenge is not always met successfully. For example, there is widespread, interchangeable use of the terms “greenhouse effect” and “global warming,” an error that introduces only confusion into the ongoing discussion. It is perhaps worthwhile to emphasize the difference between the two here. What we call, with some imprecision, the greenhouse effect is a climate system process, in which gases in Earth’s atmosphere absorb and re-radiate the heat given off by Earth’s surface and by the atmosphere itself. The net effect of this is to insulate the planet and to keep the place livable. Without our atmosphere, Earth’s average temperature would be around –18oC (0oF) rather than the balmy 15oC (59oF) or so that we enjoy today. The greenhouse effect is as real as gravity and, in many respects, more well understood at the quantum level. Global warming, on the other hand, is one possible result of the net effect of all climate system processes when the system is perturbed somehow. The perturbation of concern just now,","Astrobiology asks three fundamental questions as outlined by the NASA Astrobiology Roadmap: 1. How did Life begin and evolve?; Is there Life elsewhere in the Universe?; and, What is the future of Life on Earth? As we gain perspective on how Life on Earth arose and adapted to its many niches, we too gain insight into how a planet achieves habitability. Here on Earth, microbial Life has evolved to exist in a wide range of habitats from aquatic systems to deserts, the human body, and the International Space Station (ISS). Landers, rovers, and orbiter missions support the search for signatures of Life beyond Earth, by generating data on surface and subsurface conditions of other worlds. These have provided evidence for water activity, supporting the potential for extinct or extant Life. To investigate the putative ecologies of these systems, we study extreme environments on Earth. Several locations on our planet provide analog settings to those we have detected or expect to find on neighboring and distant worlds. Whereas, the field of space biology uses the ISS and low gravity analogs to gain insight on how transplanted Earth-evolved organisms will respond to extraterrestrial environments. Modern genomics allows us to chronicle the genetic makeup of such organisms and provides an understanding of how Life adapts to various extreme environments.","Long time ago we heard that the earth is running by gravity so it has a lot of control on everything on this life. But is it really the gravity that makes everything to be stable on this plant? I am actually disagreeing with that saying, because there is something that has greater effect than the gravity itself. It might be surprising, but in my opinion this is something worth to know and study it in details in order to help our world and too safe our life. Why I am claiming that? Because in my study, I found that the plant is controlled by the pressure more than the Gravity. Now in my study I am trying to prove the life with pressure is really important and living in high altitude could be dangerous if it exceeds the normal range of the altitude. The amount of the pressure on the Earth is huge and makes everything’s stable compare to the objects that located out of the atmosphere where is it floating.","Some ocean worlds may sustain active, seafloor hydrothermal systems, but the characteristics and controls on fluid‐heat transport in these systems are not well understood. We developed three‐dimensional numerical simulations, using a ridge‐flank hydrothermal system on Earth as a reference, to test the influence of ocean world gravity on fluid and heat transport. Simulations represented the upper ∼4–5 km below the seafloor and explored ranges of: heat input at the base, aquifer thickness, depth, and permeability, and gravity values appropriate for Earth, Europa, and Enceladus. We tested when a hydrothermal siphon could be sustained and quantified consequent circulation temperatures, flow rates, and advective heat output. Calculations illustrate a trade‐off in energy between the reduction of buoyancy at lower gravity, which tends to reduce the primary forces driving fluid circulation, and the concomitant reduction in secondary convection, which consumes available energy. When a siphon was sustained under lower gravity, circulation temperatures tended to increase modestly (which should lead to more extensive geochemical reactions), whereas mass flow rates and advective heat output tended to be reduced. Deeper subseafloor circulation resulted in higher temperatures and flow rates, with a deeper, thin aquifer being more efficient in removing heat from the rocky interior. Water‐rock ratios were lower when gravity was lower, as was the efficiency of heat extraction, whereas the time required to circulate the volume of an ocean‐world's ocean through the seafloor increased. This may help to explain how small ocean worlds could sustain hydrothermal circulation for a long time despite limited heat sources.","The 2007 Mid-winter meeting of the British Society of Rheology (BSR) was held at the Department of Earth Science & Engineering, in the Royal School of Mines, Imperial College London on the 10th and 11th of December. The subject of the meeting was the rheology of foams and emulsions, with two aims: to provide a forum for the discussion of new results in the field and to introduce the subject to rheologists used to working with rather more “traditional” materials. The programme attracted over 50 delegates from a range of academic disciplines and industries. Although the number of people who study the rheology of these highly structured fluids is perhaps small compared to those working with materials of a polymeric nature, it is clear that foams and emulsions are of interest to mathematicians, physicists, chemical engineers and food and materials scientists, among many others, and industries such as mining, petroleum and personal care. A foam is a complex fluid with a rather precise internal structure: Plateau’s rules indicate that soap films always meet three-fold in Plateau borders, the liquid-carrying channels that run between the bubbles. In turn, these borders meet tetrahedrally. The material, although disordered, is not disorganized. Before proceeding, we should also point out that concentrated emulsions have the same structure and behave in much the same way as foams, and for many purposes may even be preferable. This cellular structure gives an elastic response at low strain, and as strain, or strain-rate, increases, there is plastic yielding and then viscous flow. With the addition of surface chemistry, this is indeed a rich field for research. The first lecture, given by Jan Cilliers (Imperial) on “How bubbles float the world economy”, emphasized the importance of foams for ore-separation, and thus the effect that foam research can have on wealth creation. Cilliers described model experiments and simulations of the combined liquid, solid and gas motion in a flotation froth as the gangue flows up and over a weir to collect and purify the mineral particles. Although it is difficult to persuade mining companies to implement even the small changes to processes suggested by research, slight increases in efficiency have a remarkable effect on profit. Such improvements are even more worthwhile in the current climate, where the cost of minerals such as copper is becoming ever higher. The following talk was partly motivated by another industrial application in which foam plays an important role: the use of foams for enhanced oil recovery. Sylvie Cohen-Addad (Paris Est) described the viscoelastic response of aqueous foams containing a proportion of solid particles. Even in the linear regime, the particles increase the shear modulus of the foam, and she described this in terms of a rigidity percolation model. The effect is confirmed by Surface Evolver (SE) simulations on ordered dry foams with solid inclusions. A related presentation by Tudur Davies (Aberystwyth) described SE simulations of the interaction of circular particles descending through a foam under gravity. As well as stimulating discussion about what","Abstract Anthropogenic activities such as uncontrolled deforestation and increasing greenhouse gas emissions are responsible for triggering a series of environmental imbalances that affect the Earth's complex climate dynamics. As a consequence of these changes, several climate models forecast an intensification of extreme weather events over the upcoming decades, including heat waves and increasingly severe drought and flood episodes. The occurrence of such extreme weather will prompt profound changes in several plant communities, resulting in massive forest dieback events that can trigger a massive loss of biodiversity in several biomes worldwide. Despite the gravity of the situation, our knowledge regarding how extreme weather events can undermine the performance, survival, and distribution of forest species remains very fragmented. Therefore, the present review aimed to provide a broad and integrated perspective of the main biochemical, physiological, and morpho‐anatomical disorders that may compromise the performance and survival of forest species exposed to climate change factors, particularly drought, flooding, and global warming. In addition, we also discuss the controversial effects of high CO2 concentrations in enhancing plant growth and reducing the deleterious effects of some extreme climatic events. We conclude with a discussion about the possible effects that the factors associated with the climate change might have on species distribution and forest composition.",20.9401829375408,0,earth
3,dam; graviti; use; model; data; height; concret; geoid; studi; area; comput; system; field; construct; earth,"GNSS observations are a common solution for outdoor positioning around the world for coarse and precise applications. However, GNSS produces geodetic heights, which are not physically meaningful, limiting their functionality in many engineering applications. In Costa Rica, there is no regional model of the geoid, so geodetic heights (h) cannot be converted to physically meaningful orthometric heights (H). This paper describes the computation of a geoid model using the Stokes-Helmert approach developed by the University of New Brunswick. We combined available land, marine and satellite gravity data to accurately represent Earth's high frequency gravity field over Costa Rica. We chose the GOCO05s satellite-only global geopotential model as a reference field for our computation. With this combination of input data, we computed the 2020 Regional Stokes-Helmert Costa Rican Geoid (GCR-RSH-2020). To validate this model, we compared it with 4 global combined geopotential models (GCGM): EGM2008, Eigen6C-4, GECO and SGG-UM-1 finding an average difference of 5 cm. GECO and SGG-UM-1 are more similar to the GCR-RSH-2020 based on the statistics of the difference between models and the shape of the histogram of differences. The computed geoid also showed a shift of 7 cm when compared to the old Costa Rican height system but presented a slightly better fit with that system than the other models when looking at the residuals. In conclusion, GCR-RSH-2020 presents a consistent behaviour with the global models and the Costa Rican height systems. Also, the lowest variance suggests a more accurate determination when the bias is removed.","Interest in the study of global gravitational models has increased recently all over the world because it is necessary for height datum transformations. Today the International Center for Global Earth Models (ICGEM) provides the largest collection in the world produced through gravitational data from the gravitational satellite’s missions CHAMP, GRACE, and GOCE … Etc. To allow easy access through the internet with its more intelligent technologies, it is one of the International Gravity Organization’s services. While the Global Positioning System (GPS) has become one of the most preferred technologies in engineering surveying, a major dilemma in GPS survey lies in oval-based elevations. At the same time, orthometric heights are commonly used in the engineering field. Therefore, it is necessary to convert the measured heights by satellites assigned to the elliptical surface into orthometric heights and supported to the geoid surface (mean sea level) through an accurate geodetic model. The differences between orthometric measurement heights from DGPS/leveling data (obtained from 57 points in the study area) are increasingly used by professionals geographical information systems(GIS). However, the local determination of Geoid is necessary for better accuracy of the orthometric height from DGPS. This paper aims to introduce a modern technique for determining elevation, avoiding cumbersome and time-consuming spirit leveling operations. Fast vertical positioning can be obtained using DGPS with geoid models. The Root Mean Square Error (RMSE) is ± 0.19 m with high precision of DGPS derived with EGM08; thus, the more it describes the Earth’s gravitational field in more detail.","Prospects of application of roller compacted concrete in hydro schemes of Ukraine are considered. The number of dams erected with application of roller compacted concrete is growing year after year in the world. Roller compacted concrete is an especially dry concrete mixture with decreased content of cement and increased content of pozzolana (fly ash). The broad physico-mechanical peculiarities of roller compacted concrete depend not only on its composition but also on technology of its laying and compacting in dam. Rapid construction of gravity dams with use of equipment for earth-moving works enables the more economic construction of protective embankments. Prospects of application of roller compacted concrete during erection and restoration of existing protective embankments in regions with increased flood hazard in the west of Ukraine are considered. The use of roller compacted concrete allows reducing construction deadlines by a factor of 2–3, and, in so doing, reducing the labor content by a factor of 4–5 at the expense of full mechanization of works. Decrease in content of binder in composition of roller compacted concrete by 30–80 kg/m3 favors decrease in heat release and, correspondingly, the occurrence of temperature contraction cracks, which in its turn favors economy during construction of hydro-technical structures of hydro schemes.","In this study, a new geoid model for the northern region of Peninsular Malaysia (NGM17) was computed using an alternative method known as the Least Squares Modification of Stokes formula (LSMS) with Additive Corrections (AC) or commonly called the KTH method. The NGM17 geoid was derived from the recent terrestrial gravity data provided by Department of Surveying and Mapping Malaysia (DSMM), the most recent global digital elevation model ALOS World 3D (AW3D-30) GDEM, global geopotential model (GGM) derived from three satellite gravity missions, marine gravity anomalies extracted from DTU 10 Global Gravity Field and WGM2012 Earth’s gravity anomalies. The gravimetric geoid model derived in this study (NGM17) as well as the geoid obtained from DSMM were then evaluated against the GNSS-levelling data. The statistical analysis obtained shows that NGM17 gives slightly better accuracy with the mean error of NGM17 and DSMM geoid model were 0.2568m and 1.1648m respectively, and the RMSE of ±0.2686m and ±1.1656m respectively.","The geoid-to-quasigeoid correction has been traditionally computed approximately as a function of the planar Bouguer gravity anomaly and the topographic height. Recent numerical studies based on newly developed theoretical models, however, indicate that the computation of this correction using the approximate formula yields large errors especially in mountainous regions with computation points at high elevations. In this study we investigate these approximation errors at the study area which comprises Himalayas and Tibet where this correction reaches global maxima. Since the GPS-leveling and terrestrial gravity datasets in this part of the world are not (freely) available, global gravitational models (GGMs) are used to compute this correction utilizing the expressions for a spherical harmonic analysis of the gravity field. The computation of this correction can be done using the GGM coefficients taken from the Earth Gravitational Model 2008 (EGM08) complete to degree 2160 of spherical harmonics. The recent studies based on a regional accuracy assessment of GGMs have shown that the combined GRACE/GOCE solutions provide a substantial improvement of the Earth’s gravity field at medium wavelengths of spherical harmonics compared to EGM08. We address this aspect in numerical analysis by comparing the gravity field quantities computed using the satellite-only combined GRACE/GOCE model GOCO02S against the EGM08 results. The numerical results reveal that errors in the geoid-to-quasigeoid correction computed using the approximate formula can reach as much as ~1.5 m. We also demonstrate that the expected improvement of the GOCO02S gravity field quantities at medium wavelengths (within the frequency band approximately between 100 and 250) compared to EGM08 is as much as ±60 mGal and ±0.2 m in terms of gravity anomalies and geoid/quasigeoid heights respectively.","Gravity data gaps in mountainous areas are nowadays often filled in with the data from airborne gravity surveys. Because of the errors caused by the airborne gravimeter sensors, and because of rough flight conditions, such errors cannot be completely eliminated. The precision of the gravity disturbances generated by the airborne gravimetry is around 3–5 mgal. A major obstacle in using airborne gravimetry are the errors caused by the downward continuation. In order to improve the results the external high-accuracy gravity information e.g., from the surface data can be used for high frequency correction, while satellite information can be applying for low frequency correction. Surface data may be used to reduce the systematic errors, while regularization methods can reduce the random errors in downward continuation. Airborne gravity surveys are sometimes conducted in mountainous areas and the most extreme area of the world for this type of survey is the Tibetan Plateau. Since there are no high-accuracy surface gravity data available for this area, the above error minimization method involving the external gravity data cannot be used. We propose a semi-parametric downward continuation method in combination with regularization to suppress the systematic error effect and the random error effect in the Tibetan Plateau; i.e., without the use of the external high-accuracy gravity data. We use a Louisiana airborne gravity dataset from the USA National Oceanic and Atmospheric Administration (NOAA) to demonstrate that the new method works effectively. Furthermore, and for the Tibetan Plateau we show that the numerical experiment is also successfully conducted using the synthetic Earth Gravitational Model 2008 (EGM08)-derived gravity data contaminated with the synthetic errors. The estimated systematic errors generated by the method are close to the simulated values. In addition, we study the relationship between the downward continuation altitudes and the error effect. The analysis results show that the proposed semi-parametric method combined with regularization is efficient to address such modelling problems.","In local quasi-geoid modeling, the residual terrain modeling (RTM) method is often used to remove short-wavelength gravity field signals from the measured gravity on the ground in order to obtain a regularized and smooth gravity field that is suited for field interpolation and modeling. Accurate computation of RTM corrections plays a crucial role in computing an accurate local quasi-geoid, and it requires a set of fine-tuned parameters, including the combination of DEMs with different resolutions for suitably representing the real topography, the choice of integration radius for properly defining the extent of the computation zone, and the determination of reference topography to properly describe the RTM-reduced Earth’s surface. To our knowledge, this has not been systematically documented, despite its obvious importance. This study aims to systematically investigate the impact of these factors on RTM correction computation and, consequently, on local quasi-geoid modeling to provide practical guidelines for real-world applications. The tesseroid-based gravity forward modeling technique is employed to investigate the following issues existing in the practical use of the RTM method: ① Can the combination of a high-resolution DEM and a DEM with a lower resolution replace the single use of the high-resolution DEM for RTM correction computation while maintaining accuracy and improving efficiency? If it does, how do I properly choose the resolution of this coarse DEM as well as the integration radius r1 for the inner zone and r2 for the outer zone? ② How large would the differences between the RTM corrections computed by three types of reference topographies, which are obtained from the direct averaging (DA) approach, the moving averaging (MA) approach, and the spherical harmonic (SH) approach, be, and how large would their impact on quasi-geoid modeling be? To obtain objective findings, two research regions were selected for this investigation. One is the Colorado test area (USA) with rugged terrain, and the other is the Auvergne test area (France) with moderate terrain. The main numerical findings are: (1) the combination of the 3” resolution DEM (inner zone) and the 30″ resolution DEM (outer zone) is sufficient for accurate and efficient RTM correction computation; (2) if the resolution of the reference topography is 5′ or slightly lower, all three types of reference topographies are able to obtain local quasi-geoid models at a similar accuracy level, while the values of r1 and r2 are preferred to be at least 20 km and 111 km, respectively; (3) if the reference topography has a resolution of 30′ or lower, the MA or SH reference topography is recommended, especially for the latter one, and the values of r1 and r2 are suggested to be at least 20 km and 222 km, respectively. The above numerical findings can be taken as a reference for local quasi-geoid determination in areas with different topographic regimes than the two selected test areas.","The regions around the world need to perform their results based on the local geoid. However, each region has different ground topography based on the amount of gravity in this region. Nowadays, the recent global Earth's gravity model of 2008 is successfully used for different purposes in geosciences research. This research presents an overview of the preliminary evaluation results of the new Earth Gravitation Model (EGM08) in the middle of Iraq. For completeness, the evaluation tests were also performed for EGM96 by examining 31 stations distributed over four Iraqi provinces. The national orthometric heights were compared with the GPS /leveling data obtained from these stations. This study illustrated that the GPS /leveling based on EGM08 data was better than that based on EGM96 data in terms of reducing the root mean square error (RMSE) of the differences between the orthometric heights and GPS/leveling data. The standard deviation (SD) values for the national orthometric heights and GPS heights were about 4 and 26cm, respectively. The results also show that there is a small difference in hight ranged (0.0013 0.1333 m) in Karbala, (0.0023 – 0.0062 m), in Najaf and (0.0173 – 0.0703 m), in Babylon. Due to the flat area, better results were obtained in Karbala and Najaf than Babylon. The EGM08 geoid method has shown to yield very close results to reality for various projects, thus its accuracy is acceptable.","A study has been made of the gravity field of the earth using a combined solution from free air anomalies and satellite data. Spherical harmonics up to order 8.8 have been computed in a joint solution. Satellite data from Doppler tracking (NWL) and optical observations (SAO) were added in a combined solution with full consideration of the complete covariance matrix.—This study was based on the most complete set of gravity data so far presented (approximately 500,000). DOI: 10.1111/j.2153-3490.1969.tb00461.x","This paper deals with the geopotential approach to investigate the present Brazilian Height System (BHS). Geopotential numbers are derived from Global Positioning System (GPS) satellite surveying and disturbing potential on selected benchmarks. A model for the disturbing potential can be obtained by an existing set of spherical harmonic coefficients such as the Earth Gravity Model 2008 (EGM08). The approach provides absolute evaluation of local normal geopotential numbers (aka spheropotential numbers) related to a so-called World Height System (WHS). To test the validity of the proposed methodology, a numerical experiment was carried out related to a test region in Southern Brazil. The accuracy of the derived geopotential numbers was tested versus local normal geopotential numbers based on 262 GPS/leveling points. The root mean square error (RMSE) value for metric offset of BHS derived from geopotential numbers and the disturbing potential modeling in the test area was estimated to be near 0.224 meters in the absolute view. Therefore, since these spheropotential numbers are referred to a local datum, these results of comparisons may be an indicator of the mean bias of local network due to the effect of local Sea Surface Topography (SSTop) and possible offset between the unknown reference for the BHS and the quasigeoid model in the region.",14.6205476872654,4,dam
4,water; chang; observ; data; model; surfac; use; land; grace; graviti; earth; climat; result; mass; contribut,"In line with the United Nations Sustainable Development Goal (SDG) 6, the main goal of the Special Issue on “Remote sensing for water resources and environmental management” was to solicit papers from a diverse range of scientists around the world on the use of cutting-edge remote sensing technologies to assess and monitor freshwater quality, quantity, availability, and management to ensure water security. Special consideration was given to scientific manuscripts that covered, but were not limited to, the development of geospatial techniques and remote sensing applications for detecting, quantifying, and monitoring freshwater water resources, identifying potential threats to water resources and agriculture, as well as other themes related to water resources and environmental management at various spatial scales. The Special Issue attracted over thirteen peer-reviewed scientific articles, with the majority of manuscripts originating from China. Most of the studies made use of satellite datasets, ranging from coarse spatial resolution data, such as the Gravity Recovery and Climate Experiment (GRACE) and GRACE Follow-On (GRACE-FO), to medium spatial resolution data, such as the Landsat series, ERA5, Modern-Era Retrospective Analysis for Research and Application Land version 2 reanalysis product (MERRA2), CLSM and NOAH ET, and MODIS (Moderate Resolution Imaging Spectroradiometer). Google Earth Engine (GEE) data, together with big data processing techniques, such as the remote sensing-based energy balance model (ALEXI/DisALEXI approach) and the STARFM data fusion technique, were used for analyzing geospatial datasets. Overall, this Special Issue demonstrated significant knowledge gaps in various big data image processing techniques and improved computing processes in assessing and monitoring water resources and the environment at various spatial and temporal scales.","Abstract. Drought frequently occurs in North China and is the most damaging disaster in this region owing to its large-scale impact on hydrology and ecosystems. This is the main reason that China implemented the world-famous South-to-North Water Diversion (SNWD) project. However, quantifying the drought-induced water deficit at a regional scale is still a significant challenge. Gravity Recovery and Climate Experiment (GRACE) satellites monitor temporal variations in the Earth’s gravitational potential and provide quality data sets for water storage analysis. In this study, we quantify the water deficit over North China in the context of the implementation of the SNWD project by focusing on a recent drought event, the 2009/10 drought, and identifying its onset, persistence, and recovery. As confirmed with ground-measured and land surface modelling data sets, GRACE can successfully capture temporal variations in total water storage. Total water storage shows a declining trend, reaching a low point during the 2009/10 drought with a water storage deficit of up to 25 km3 (~ 22 mm). Groundwater storage shows a similar pattern, with a trend of −6.97 mm yr−1. Together with the water deficit, vegetation growth is substantially restricted, as indicated by a reduction in the leaf area index. The amount of water transfer by the SNWD project can roughly meet the water deficit in North China but the effectiveness of the SNWD will depends on specific water configuration strategies.","Groundwater depletion occurs when the extraction exceeds its recharge and further impacts water resource management around the world, especially in developing countries. In India, most groundwater level observations are only available on a seasonal scale, i.e., January (late post-monsoon), May (pre-monsoon), August (monsoon), and November (early post-monsoon). The Gravity Recovery and Climate Experiment (GRACE) data are available to estimate the monthly variation in groundwater storage (GWS) by subtracting precipitation runoff, canopy water, soil moisture, and solid water (snow and ice) from the GLDAS model. Considering GRACE-based GWS data, the data fusion is further used to estimate monthly spatial maps of groundwater levels using time-varying spatial regression. Seasonal groundwater monitoring data are used in the training stage to identify spatial relations between groundwater level and GWS changes. Estimation of unknown groundwater levels through data fusion is accomplished by utilizing spatial coefficients that remain consistent with the nearest observed months. Monthly groundwater level maps show that the lowest groundwater level is 50 to 55 m below the earth’s surface in the state of Rajasthan. The accuracy of the estimated groundwater level is validated against observations, yielding an average RMSE of 2.37 m. The use of the GWS information enables identification of monthly spatial patterns of groundwater levels. The results will be employed to identify hotspots of groundwater depletion in India, facilitating efforts to mitigate the adverse effects of excessive groundwater extraction.","Abstract. The availability of data is a major challenge for hydrological modelling in large parts of the world. Remote sensing data can be exploited to improve models of ungauged or poorly gauged catchments. In this study we combine three datasets for calibration of a rainfall-runoff model of the poorly gauged Okavango catchment in Southern Africa: (i) surface soil moisture (SSM) estimates derived from radar measurements onboard the Envisat satellite; (ii) radar altimetry measurements by Envisat providing river stages in the tributaries of the Okavango catchment, down to a minimum river width of about one hundred meters; and (iii) temporal changes of the Earth's gravity field recorded by the Gravity Recovery and Climate Experiment (GRACE) caused by total water storage changes in the catchment. The SSM data are shown to be helpful in identifying periods with over-respectively underestimation of the precipitation input. The accuracy of the radar altimetry data is validated on gauged subbasins of the catchment and altimetry data of an ungauged subbasin is used for model calibration. The radar altimetry data are important to condition model parameters related to channel morphology such as Manning's roughness. GRACE data are used to validate the model and to condition model parameters related to various storage compartments in the hydrological model (e.g. soil, groundwater, bank storage etc.). As precipitation input the FEWS-Net RFE, TRMM 3B42 and ECMWF ERA-Interim datasets are considered and compared.","In 2007 the Programme for Monitoring the Greenland Ice Sheet (PROMICE) was initiated to observe and gain insight into the mass budget of Greenland ice masses. By means of in situ observations and remote sensing, PROMICE assesses how much mass is gained as snow accumulation on the surface versus how much is lost by iceberg calving and surface ablation (Ahlstrom et al. 2008). A key element of PROMICE is a network of automatic weather stations (AWSs) designed to quantify components of the surface mass balance, including the energy exchanges contributing to surface ablation (Van As et al. 2013).The use of these AWS observations is not limited to studies of ice-sheet mass balance. PROMICE contributes to CryoNet (www.globalcryospherewatch.org/cryonet), the core network of surface measurement sites of the World Meteorological Organization (WMO) Global Cryosphere Watch. By real-time delivery through WMO, PROMICE observations contribute to improve both operational forecasting and climate analysis in the data-sparse Arctic. The Greenlandic population, highly dependent on accurate forecasting of weather conditions, benefits directly from these real-time observations. For instance, extreme surface wind speeds are a high-risk element in Greenland. The third-highest wind speed observed at the surface of the Earth (93 m/s or 333 km/h), was recorded in a 8–9 March 1972 storm at Thule in North-West Greenland (Stansfield 1972).In this paper, we discuss the extent to which the Greenland ice sheet generates its own near-surface wind field. We use PROMICE data to gain insight into the interaction between air temperature, radiation and gravity-driven katabatic winds. We focus on a particularly powerful spring storm in 2013 that contributed to a fatality on an ice-sheet ski traverse attempt (Linden 2013).",". The availability of data is a major challenge for hydrological modelling in large parts of the world. Remote sensing data can be exploited to improve models of ungauged or poorly gauged catchments. In this study we combine three datasets for calibration of a rainfall-runoff model of the poorly gauged Okavango catchment in Southern Africa: (i) surface soil moisture (SSM) estimates derived from radar measurements onboard the Envisat satellite; (ii) radar altimetry measurements by Envisat providing river stages in the tributaries of the Okavango catchment, down to a minimum river width of about one hundred meters; and (iii) temporal changes of the Earth’s gravity ﬁeld recorded by the Gravity Recovery and Climate Experiment (GRACE) caused by total water storage changes in the catchment. The SSM data are shown to be helpful in identifying periods with over-respectively underestimation of the precipitation input. The accuracy of the radar altimetry data is validated on gauged subbasins of the catchment and altimetry data of an ungauged subbasin is used for model calibration. The radar altimetry data are important to condition model parameters related to channel morphology such as Manning’s roughness. GRACE data are used to validate","The Three Gorges Reservoir (TGR) in China, with the largest dam in the world, stores a large volume of water and may influence the Earth’s gravity field on sub-seasonal to interannual timescales. Significant changes of the total water storage (TWS) might be detectable by satellite-based data provided by the Gravity Recovery and Climate Experiment (GRACE) mission. To detect these store water changes, effects of other factors are to be removed first from these data due to band-limited representation of near-surface mass changes from GRACE. Here, we evaluated three current popular land surface models (LSMs) basing on in situ measurements and found that the WaterGAP Global Hydrology Model (WGHM) demonstrates higher correlation than other analyzed models with the in-situ rainfall measurement. Then we used the WGHM outputs to remove climate-induced TWS changes, such as surface water storage, soil, canopy, snow, and groundwater storage. The residual results (GRACE minus WGHM) indicated a strong trend (3.85 ± 2 km3/yr) that is significantly higher than the TGR analysis and hindcast experiments (2.29 ± 1 km3/yr) based on in-situ water level measurements. We also estimated the seepage response to the TGR filling, contributions from other anthropogenic dams, and used in-situ gravity and GPS observations to evaluate dominant factors responsible for the GRACE-based overestimate of the TGR volume change. We found that the modeled seepage variability through coarse-grained materials explained most of the difference between the GRACE based estimate of TGR volume changes and in situ measurements, but the agreement with in-situ gravity observations is considerably lower. In contrast, the leakage contribution from 13 adjacent reservoirs explained ~74% of the TGR volume change derived from GRACE and WGHM. Our results demonstrate that GRACE-based overestimate TGR mass change mainly from the contribution of surrounding artificial reservoirs and underestimated TWS variations in WGHM simulations due to the large uncertainty of WGHM in groundwater component. In additional, this study also indicates that reservoir or lake volume changes can be reliably derived from GRACE data when they are used in combination with relevant complementary observations.","Glaciers outside of the ice sheets are known to be important contributors to sea level rise. In this work, we provide an overview of changes in the mass of the world's glaciers, excluding those in Greenland and Antarctica, between 2002 and 2016, based on satellite gravimetry observations of the Gravity Recovery and Climate Experiment (GRACE). Glaciers lost mass at a rate of 199 ± 32 Gt yr −1 during this 14-yr period, equivalent to a cumulative sea level contribution of 8 mm. We present annual mass balances for 17 glacier regions, that show a qualitatively good agreement with published estimates from in situ observations. We find that annual mass balance varies considerably from year to year, which can in part be attributed to changes in the large-scale circulation of the atmosphere. These variations, combined with the relatively short observational record, hamper the detection of acceleration of glacier mass loss. Our study highlights the need for continued observations of the Earth's glacierized regions.","Abstract. Groundwater is the largest store of freshwater on Earth after the cryosphere and provides a substantial proportion of the water used for domestic, irrigation and industrial purposes. Knowledge of this essential resource remains incomplete, in part, because of observational challenges of scale and accessibility. Here we examine a 14-year period (2002–2016) of Gravity Recovery and Climate Experiment (GRACE) observations to investigate climate–groundwater dynamics of 14 tropical and sub-tropical aquifers selected from WHYMAP's (Worldwide Hydrogeological Mapping and Assessment Programme) 37 large aquifer systems of the world. GRACE-derived changes in groundwater storage resolved using GRACE Jet Propulsion Laboratory (JPL) mascons and the Community Land Model's land surface model are related to precipitation time series and regional-scale hydrogeology. We show that aquifers in dryland environments exhibit long-term hydraulic memory through a strong correlation between groundwater storage changes and annual precipitation anomalies integrated over the time series; aquifers in humid environments show short-term memory through strong correlation with monthly precipitation. This classification is consistent with estimates of groundwater response times calculated from the hydrogeological properties of each system, with long (short) hydraulic memory associated with slow (rapid) response times. The results suggest that groundwater systems in dryland environments may be less sensitive to seasonal climate variability but vulnerable to long-term trends from which they will be slow to recover. In contrast, aquifers in humid regions may be more sensitive to climate disturbances such as drought related to the El Niño–Southern Oscillation but may also be relatively quick to recover. Exceptions to this general pattern are traced to human interventions through groundwater abstraction. Hydraulic memory is an important factor in the management of groundwater resources, particularly under climate change.","Abstract Potatoes are one of the most important vegetable crops which play an important role in improving household income and nutrition thereby contributing to food security in smallholder farmers. However, yield and productivity of the crop have been far below the world average. The present study was, therefore, undertaken to improve the productivity and quality of potato through proper planting depth and time of earthing up under supplemental irrigation using Jalane variety. The result revealed that days to flowering, days to physiological maturity, plant height, leaf number per plant, number of main stem per plant, unmarketable tuber number, marketable tuber yield, unmarketable tuber yield, total tuber yield, dry matter content, size category and specific gravity were significantly different due to the main effects of planting depth and time of earthing up. Interaction effect of planting depth and time of earthing up significantly affected the yield and quality of potato plants. The highest marketable and total tuber yield was recorded from the earthing up at 25 days after emergence using 12 cm depth of planting. The result may give firsthand information for potato producers to maximize their productivity. The production of potato is improved through the combination of 12 cm planting depth and earthing up at 25 days after emergence.",17.943139421699,3,water
5,graviti; model; earth; structur; result; differ; data; studi; world; use; seismic; densiti; area; valu; zone,"The continuous DOBREfraction’99/DOBRE-2 WARR and CDP profile of 775 km length with about 100 km overlap was acquired by an international team from Ukraine, Poland, Denmark, USA, Netherlands, Germany, Great Britain and Norway in 1996 and 2007 respectively. It crosses southeastern East European Craton (the southern slope of the Voronezh Massif, Donbas, the Priazov Megablock), the North Azov Trough, the Middle Azov High, the Indolo-Kuban Depression, the Crimea-Caucasus inversion zone, the Sorokin Trough, the Shatsky and Andrusov Ridges in the Eastern Black Sea Basin. In terms of the number of tectonic structures of different ages and origin, the profile has no analogues in world practice. Along the profile there has first been carried out an interdisciplinary geological and geophysical study of the entire lithospheric cross-section with the use of seismic data, magnetic, gravity and thermal fields, information on seismic tomography and spontaneous electric emission of the Earth. Fundamentally new information has been obtained for the structure of the lithosphere and a number of controversial problems have been convincingly solved. Tectonically, the lithosphere is a complex collage of structures arised in different geodynamic conditions from the Archean to the Neogene as a result of successive stages of its formation. The regional regularities in the structure of the lithosphere are the decrease in the thickness of the crust from north to south, from ancient structures to young ones with simultaneous elevation of the top of asthenosphere from 210 km under the Voronezh Massif to 90 km under the East Black Sea Basin. The standard continental crystalline crust has been mapped on the southern slope of the Voronezh Massif and in the Priazov Megablock. It has been reworked by the Paleozoic rifting in Donbas. The analysis of the heterogeneity of the crystalline crust and mantle has first been used to assess the position of the actual boundary of the East European Platform and the transition zone to the Scythian Plate, which corresponds to the deepest position of the asthenosphere top and the division between domains of different seismic velocities in the lithospheric mantle. The changes in the crystalline crust type under the Main Azov Thrust fixes the buried boundary of the East European Platform. The relationship has been established between large sedimentary structures and the areas of change in the composition of the crystalline crust along suture zones. The main faults of the sedimentary cover as the sutures of different ages have been traced in the cross-section of the crystalline crust and in the upper mantle. The subcrustal decomposition of the mantle and the crust—mantle mixture at the base of the crust of the maximum thickness between the South Crimean and Mesozoic sutures and in Donbas have resulted from the lithosphere reworking during its development. Different types of crystalline crust and gentle inclined intracrustal disturbances sometimes causing doubling different layers of the crystalline crust provide evidence of repeated subduction of the oceanic crust of the Paleo-, Mezo- and Neotethys. The low-velocity mantle layer between the South Crimean and Mesozoic sutures indicates a present-day manifestation of the total effect of post-Paleozoic subductions. A set of possible rocks has been determined for the crystalline crust within the southern slope of the Voronezh Massif, Donbas and the Azov Mega block. In the Crimea-Caucasus inversion zone at a depth of 30 km a complex of rocks has been documented to be inherent in the standard continental crust which is an alternative to the speculation about the local elevation of the upper mantle due to the serpentinization of mafic rocks.","During the last two decades, space geodesy allowed mapping accurately rupture areas, slip distribution, and seismic coupling by obtaining refined inversion models and greatly improving the study of great megathrust earthquakes. A better understanding of these phenomena involving large areas of hundreds of square kilometers came from the last gravity satellite mission that allowed detecting mass transfer through the Earth interior. In this work, we performed direct modeling of satellite GOCE (Gravity Field and Steady-State Ocean Circulation Explorer) derived gravity gradients up to degree/order N = 200 of the harmonic expansion and then corrected this by the effect of topography. Cutting off the model up to this degree/order allows inferring mass heterogeneities located at an approximate depth of 31 km, just along the plate interface where most (but not all) significant slip occurs. Then, we compared the vertical gravity gradient to well-constrained coseismic slip models for three of the last major earthquakes along the Sunda interface. We analyzed seismic rupture behavior for recent and for historical earthquakes along this subduction margin and the relationship of the degree of interseismic coupling using the gravity signal. From this, we found that strong slip patches occurred along minima gravity gradient lobes and that the maximum vertical displacements were related quantitatively to the gravity-derived signal. The degree of interseismic coupling also presents a good correspondence to the vertical gravity gradient, showing an inverse relationship, with low degrees of coupling over regions of relatively higher density. This along-strike segmentation of the gravity signal agrees with the along-strike seismic segmentation observed from recent and historical earthquakes. The thermally controlled down-dip ending of the locked fault zone along central Sumatra also presented an inverse relationship with the density structure along the forearc inferred using our modeling. From this work, we inferred different mass heterogeneities related to persistent tectonic features along the megathrust and along the marine forearc, which may control strain accumulation and release along the megathrust. Combining these data with geodetical and seismological data could possibly delimit and monitor areas with a higher potential seismic hazard around the world.","The Afar and Ethiopian plateaus are in a dynamic uplift due to the mantle plume, therefore, considering the plume effect is necessary for any geophysical investigation including the estimation of lithospheric stress in this area. The Earth gravity models of the Gravity Field and Steady-State Ocean Circulation Explorer (GOCE) and lithospheric structure models can be applied to estimate the stress tensor inside the Ethiopian lithosphere. To do so, the boundary-value problem of elasticity is solved to derive a general solution for the displacement field in a thin elastic spherical shell representing the lithosphere. After that, general solutions for the elements of the strain tensor are derived from the displacement field, and finally the stress tensor from the strain tensor. The horizontal shear stresses due to mantle convection and the vertical stress due to the mantle plume are taken as the lower boundary value at the base of the lithosphere, and no stress at the upper boundary value of the lithospheric shell. The stress tensor and maximum stress directions are computed at the Moho boundary in three scenarios: considering horizontal shear stresses due to mantle convection, vertical stresses due to mantle plume, and their combination. The estimated maximum horizontal shear stresses’ locations are consistent with tectonics and seismic activities in the study area. In addition, the maximum shear stress directions are highly correlated with the World Stress Map 2016, especially when the effect of the mantle plume is solely considered, indicating the stress in the study area mainly comes from the plume.","This investigation establishes an integrated method for rare earth elements (REE) exploration through a very promising and advanced exploration prospect in the Alces Lake area (SK, Canada) by assessing the integrated analysis of several multisource geophysical datasets. The resulting outcome provides important lithostructural information to the well-exposed, mineralized middle-to-lower crust at Alces Lake, comprising deep-seated poly-phase folds, ductile shear zones, and brittle faults. Geophysical–geological models of the Alces Lake property were constructed at different scales. The area of interest is located within the Beaverlodge Domain, about 28 km north of the Athabasca Basin’s northern margin. It contains some of the highest-grade rare earth elements (REE) in the world with the REE hosted predominantly in monazites within quartzo-feldspathic granitic to biotite–garnet–monazite–zircon-rich restite-bearing/cumulate mush melt pegmatites of anatectic origin (abyssal). Geophysical magnetic, gravity, and radiometric data were used together with Shuttle Radar Topography Mission (SRTM) images to facilitate the processing, modeling, and interpretation. Consequently, major structures were identified at different scales; however, the emphasis was given to studying those at the district/camp scale. The REE zones discovered to date occur within a large district-scale refolded synformal anticline. The eastern limb of this folded structure comprises a 30–40 km long, NW-trending shear zone/fault corridor with deep-seated structural crustal roots that may have served as the major pathway for ascending fluids/melts and facilitated the emplacement of mineralization. Thus, shear zones, faults, and folds in combination with lithological contacts/rheological contrasts appear to control residual/cumulate pegmatite emplacement and monazite deposition. Anomalies obtained from the airborne equivalent thorium survey data prove to be the most useful for REE pegmatite exploration. The results herein provide new interpretation and modeling perspectives leading to a better understanding of the distribution and lithostructural controls of REE on the property, and to new guidelines for future exploration programs at Alces Lake and elsewhere in northern Saskatchewan.","Abstract. The new paradigm of plate tectonics began in 1960 with Harry H. Hess's 1960 realization that new ocean floor was being created today and is not everywhere of Precambrian age as previously thought. In the following decades an unprecedented coming together of bathymetric, topographic, magnetic, gravity, seismicity, seismic profiling data occurred, all supporting and building upon the concept of plate tectonics. Most investigators accepted the premise that there was no net torque amongst the plates. Bowin (2010) demonstrated that plates accelerated and decelerated at rates 10−8 times smaller than plate velocities, and that globally angular momentum is conserved by plate tectonic motions, but few appeared to note its existence. Here we first summarize how we separate where different mass sources may lie within the Earth and how we can estimate their mass. The Earth's greatest mass anomalies arise from topography of the boundary between the metallic nickel–iron core and the silicate mantle that dominate the Earth's spherical harmonic degree 2 and 3 potential field coefficients, and overwhelm all other internal mass anomalies. The mass anomalies due to phase changes in olivine and pyroxene in subducted lithosphere are hidden within the spherical harmonic degree 4–10 packet, and are an order of magnitude smaller than those from the core–mantle boundary. Then we explore the geometry of the Emperor and Hawaiian seamount chains and the 60° bend between them that aids in documenting the slow acceleration during both the Pacific Plate's northward motion that formed the Emperor seamount chain and its westward motion that formed the Hawaiian seamount chain, but it decelerated at the time of the bend (46 Myr). Although the 60° change in direction of the Pacific Plate at of the bend, there appears to have been nary a pause in a passive spreading history for the North Atlantic Plate, for example. This, too, supports phase change being the single driver for plate tectonics and conservation of angular momentum. Since mountain building we now know results from changes in momentum, we have calculated an experimental deformation index value (1–1000) based on a world topographic grid at 5 arcmin spacing and displayed those results for viewing.","Seismic data are primarily used in studies of the Earth’s inner structure. Since large parts of the world are not yet sufficiently covered by seismic surveys, products from the Earth’s satellite observation systems have more often been used for this purpose in recent years. In this study we use the gravity-gradient data derived from the Gravity field and steady-state Ocean Circulation Explorer (GOCE), the elevation data from the Shuttle Radar Topography Mission (SRTM) and other global datasets to determine the Moho density contrast at the study area which comprises most of the Eurasian plate (including parts of surrounding continental and oceanic tectonic plates). A regional Moho recovery is realized by solving the Vening Meinesz-Moritz’s (VMM) inverse problem of isostasy and a seismic crustal model is applied to constrain the gravimetric solution. Our results reveal that the Moho density contrast reaches minima along the mid-oceanic rift zones and maxima under the continental crust. This spatial pattern closely agrees with that seen in the CRUST1.0 seismic crustal model as well as in the KTH1.0 gravimetric-seismic Moho model. However, these results differ considerably from some previously published gravimetric studies. In particular, we demonstrate that there is no significant spatial correlation between the Moho density contrast and Moho deepening under major orogens of Himalaya and Tibet. In fact, the Moho density contrast under most of the continental crustal structure is typically much more uniform.","Head movements are primarily sensed in a reference frame tied to the head, yet they are used to calculate self-orientation relative to the world. This requires to re-encode head kinematic signals into a reference frame anchored to earth-centered landmarks such as gravity, through computations whose neuronal substrate remains to be determined. Here, we studied the encoding of self-generated head movements in the caudal cerebellar vermis, an area essential for graviceptive functions. We found that, contrarily to peripheral vestibular inputs, most Purkinje cells exhibited a mixed sensitivity to head rotational and gravitational information and were differentially modulated by active and passive movements. In a subpopulation of cells, this mixed sensitivity underlay a tuning to rotations about an axis defined relative to gravity. Therefore, we show that the caudal vermis hosts a re-encoded, gravitationally-polarized representation of self-generated head kinematics.","The Sulphide Queen carbonatite deposit at Mountain Pass in southeast California is a world class rare earth element (REE) resource. This study images electrical resistivity structure of the REE deposit and surrounding area to characterize resources under cover. An east‐west elongated grid (35 × 15 km) of 65 wideband magnetotelluric stations spanning from eastern Shadow Valley to eastern Ivanpah Valley were collected and modeled in three‐dimensions (3‐D). Gravity, aeromagnetic, and geologic data are used to inform interpretation of structures in the resistivity model, including the following observations. Shadow Valley is filled with conductive sediment that locally dips southward to a depth of 1 km. The Kingston Range‐Halloran Hills detachment fault dips westward at ∼15 degrees. The REE deposit is a moderate low resistivity zone dipping southwest to a possible depth of ∼1 km, and is bounded by the North and South faults and bisected by the Middle fault. Ivanpah Dry Lake is underlain by a north striking southward dipping sedimentary basin. Two possible zones of mineralization are observed in Ivanpah Valley, one along the western edge of Ivanpah Dry Lake and one on the western edge of valley along a new inferred fault. The brittle‐ductile transition is imaged at ∼10 km below mean sea level. No deep electrically conductive structures are imaged to be related to the REE deposit likely due to the complex geologic history of the Mojave terrane. Future studies should regional target Proterozoic rocks and search within for geophysical signatures similar to Mountain Pass.","The long‐wavelength gravity and topography of Venus are dominated by mantle convective flows, and are hence sensitive to the planet's viscosity structure and mantle density anomalies. By modeling the dynamic gravity and topography signatures and by making use of a Bayesian inference approach, we investigate the viscosity structure of the Venusian mantle by constraining radial viscosity variations. We performed inversions under a wide range of model assumptions that consistently predicted the existence of a thin low‐viscosity zone in the uppermost mantle. The zone is about 235 km thick and has a viscosity reduction of 5–15 times with respect to the underlying mantle. Drawing a parallel with the Earth, the reduced viscosity could be a result of partial melting as suggested for the origin of the asthenosphere. These results support the interpretation that Venus is a geologically active world predominantly governed by ongoing magmatic processes.","Sensory systems encode the environment in egocentric (e.g., eye, head, or body) reference frames, creating inherently unstable representations that shift and rotate as we move. However, it is widely speculated that the brain transforms these signals into an allocentric, gravity-centered representation of the world that is stable and independent of the observer's spatial pose. Where and how this representation may be achieved is currently unknown. Here we demonstrate that a subpopulation of neurons in the macaque caudal intraparietal area (CIP) visually encodes object tilt in nonegocentric coordinates defined relative to the gravitational vector. Neuronal responses to the tilt of a visually presented planar surface were measured with the monkey in different spatial orientations (upright and rolled left/right ear down) and then compared. This revealed a continuum of representations in which planar tilt was encoded in a gravity-centered reference frame in approximately one-tenth of the comparisons, intermediate reference frames ranging between gravity-centered and egocentric in approximately two-tenths of the comparisons, and in an egocentric reference frame in less than half of the comparisons. Altogether, almost half of the comparisons revealed a shift in the preferred tilt and/or a gain change consistent with encoding object orientation in nonegocentric coordinates. Through neural network modeling, we further show that a purely gravity-centered representation of object tilt can be achieved directly from the population activity of CIP-like units. These results suggest that area CIP may play a key role in creating a stable, allocentric representation of the environment defined relative to an “earth-vertical” direction.",21.6417694012408,1,graviti
