Topic_Number,Keywords,Abstract_1,Abstract_2,Abstract_3,Abstract_4,Abstract_5,Abstract_6,Abstract_7,Abstract_8,Abstract_9,Abstract_10,Perc_of_Corpus,Topic Cluster,Summary topic
1,learn; student; cours; use; studi; method; score; assess; result; exam; signific; examin; evalu; final; question,"Background: Educational reform, especially methods of teaching, has been a focus among nursing educators. This study explored the impact of blended versus offline case-centered learning on academic performance of Medical Nursing and critical thinking ability among undergraduate nursing students.Methods: A cluster randomized controlled study design was used, with assessments immediately before and one school year after the intervention. All the second-year undergraduate nursing students in two class were enrolled in this study by cluster sampling. The two classes of Medical Nursing were randomly allocated to either the experimental class, which undertook blended case-centered learning, or the control class, which undertook offline case-centered learning. The primary outcomes were academic performance consisting of final exam and process assessment, as well as the critical thinking ability assessed with the Critical Thinking Disposition Inventory-Chinese Version (CTDI-CV). The Mann-Whitney U test and the unpaired t test was subsequently used. ANCOVA analyses were also performed to examine the two teaching methods’ effect on academic performance and critical thinking.Results: Students in the experimental class showed a significantly higher improvement in academic performance of Medical Nursing than the control class. In addition, compared with the control class, the pre-post difference in competency in critical thinking self-confidence in the experimental class was significantly greater (p=0.037). In the experimental class, there was significant improvement compared with baseline in dimension of critical thinking self-confidence (p=0.022). In the control class, there was significant improvement compared with baseline in the total score (p=0.029) and two of the seven dimensions: truth-seeking (p=0.016) and systematicity (p=0.005).Conclusions: Use of the blended case-centered learning showed the promising results in promoting students’ academic performance. Both the blended and offline case-centered learning in this study were a suitable educational approach to improve the critical thinking ability of undergraduate nursing students. In the future, blended and offline case-centered learning could be implemented in other nursing subjects. Moreover, further efforts to improve teaching are warranted.","This study aims to determine whether there is a positive and significant relationship and there is an influence between learning interest on Integrated Science learning outcomes. The type of research used in this research is quantitative research with correlational methods. The population in this study were all 65 students of class VII at SMP Negeri 4 Maniamolo. The sampling technique uses a total sampling technique, meaning that the entire population is used as a sample. The instrument in this study used a closed questionnaire and students' science learning outcomes were in the form of odd semester final exam scores. Data analysis techniques were carried out by describing the data, correlational analysis, coefficient of determination and hypothesis testing. The test results in this study indicate that there is a positive and significant relationship between learning interest on science learning outcomes, and there is also an influence between learning interest on Integrated Science learning outcomes. So it was concluded that 1) because students have a sense of pleasure, interest, and a high desire for learning which is seen as giving them benefits and satisfaction, 2) students have a sense of comfort, are aware of the benefits of learning, and know the learning goals that make them interested so that learning occurs. improvement in learning outcomes.","This study aims to determine a positive and significant relationship as well as an influence between students' interest in learning and their mathematics learning outcomes. The research method used in this study is quantitative research with a correlational approach. The population in this study consists of all eighth-grade students at SMP Negeri 1 Toma, totaling 65 students. The sampling technique used is total sampling, meaning the entire population is used as the sample. The instruments in this study include closed-ended questionnaires and students' mathematics learning outcomes in the form of even semester final exam scores (UKK). Data analysis techniques involve describing the data, correlational analysis, coefficient of determination, and hypothesis testing. The results of this study show that there is a positive and significant relationship between students' interest in learning and their mathematics learning outcomes, and there is also an influence of students' interest in learning on their mathematics learning outcomes. It can be concluded that 1) because students have a sense of enjoyment, interest, and a high desire to learn that they perceive as beneficial and satisfying, and 2) students feel comfortable, are aware of the benefits of learning, and understand the learning objectives, which makes them interested and leads to an improvement in learning outcomes.","Sir, Assessment of learning has always been a difficult, yet an essential component of an educational program. In the undergraduate medical education system in India, curricular guidelines of Medical Council of India lay emphasis on methods of assessment of knowledge and skills in pharmacology.[1] Although continuous formative assessment constitutes an integral part in the curriculum, the ‘pass’ and the ‘fail’ certificates are based to a great extent on students’ performance in the final summative examination. The final examination consists of written papers, viva-voce sessions and practical exercises. Written examination consists of two papers. Each paper has the maximum marks of 40 and contains structured essay type questions and short notes. In viva-voce examination, each student is assessed by five examiners; two of them external examiners and the others internal examiners. In order to pass, a candidate must obtain 50% marks in aggregate with a minimum of 50% marks in written and viva together and a minimum of 50% marks in practical examination.[1] The written examination is a useful evaluation format that not only tests students’ ability to recall facts, but also can assess higher-order cognitive functions, such as interpretation of data and problem solving skills. The viva-voce examination on the other hand is a general encounter between a candidate and one or more examiners.[2] Viva-voce examinations are less reliable as they are essentially subjective in nature, afflicted with ‘halo effects’, errors of central tendency, a general tendency toward leniency, and errors of contrast.[2] Examiners mostly indulge in over-marking in viva-voce examinations in order to make an otherwise undeserving candidate ‘pass’. We explored this recently in a small questionnaire-based interview among examiners of pharmacology in one university and the examiners admitted showing such ‘leniency’. Against this backdrop, we planned the present study to compare students’ performance in written and viva-voce components of the final summative pharmacology examination in MBBS curriculum in order to have a critical insight into the two modes of evaluation, the way they are practiced. This was a record-based observational study done in a medical college in India that also served as an examination centre for second professional MBBS examination in pharmacology for four consecutive years, from 2008 to 2011. The performance of students was assessed. Permission for access to the students’ score sheets was obtained from appropriate authority and confidentiality of individual student’s score was maintained. Percentage of marks obtained by four batches of students (n=589), in consecutive years (2008-11), in written and viva-voce components of the final summative examination in pharmacology were reviewed: Batch 1 (Jan 2011 Exam, n=159), Batch 2 (Jan 2010 Exam, n=139), Batch 3 (Jan 2009 Exam, n=148), Batch 4 (Jan 2008 Exam, n=143). Based on their performance in terms of percentage of marks in aggregate, all students in a batch were classified into four categories viz., ‘failed’(F) – <50%, ‘borderline passed’ (BP) – 50-57%, ‘passed’ (P) – >57% to <75% and ‘passed with distinction’ (PD) – ≥75%. Correlation was assessed between the percentage of marks obtained by students in these categories in written vis-a-vis viva-voce examination. Highly significant association was observed in marks obtained by students in P and PD categories in all four batches in viva-voce and written examination (P<0.001). However, no significant association was observed in marks obtained by students in F and BP categories in all four batches in viva-voce and written examination (P>0.05). The results are shown in Table 1. Interestingly, no student in F category got 50% marks in written examination, but most of them scored satisfactorily in the viva-voce. Among all the students in F category, three students in 2008, five in 2009, four in 2010 and none in 2011 failed in practical examination. The number of students in each category (e.g., F, BP, P and PD) when compared among the 4 years (2008-11) did not show any significant difference [Figure 1]. Our study showed that there was highly significant association between written and viva-voce marks of students in the PD and P categories (P<0.001). We interpret this as the ‘true’ reflection of knowledge and competence of the students in this category. Our study also revealed that there was a lack of significant association in performance in written and viva-voce examination among students in F and BP categories (P>0.05). Marks obtained by students in viva-voce were higher with respect to those in written examination in these two categories. Rather, the poorer the performance in written examination, the higher the marks obtained in the viva-voce. Such trend is most prominent in the F category of students Access this article online","Background In recent years, pharmacists have been involved in expanded patient care responsibilities, for example patient counseling in self-medication, medication review and pharmaceutical care, which require graduates to develop the necessary competences. Consequently, reorientation of pharmacy education has become necessary. As such, active learning strategies have been introduced into classrooms to increase problem-solving and critical thinking skills of students. The objective of this study was to evaluate the performance and perceptions of competency of students in a new pharmaceutical care course that uses active learning methodologies. Methods This pharmaceutical care course was conducted in the first semester of 2014, in the Federal University of Sergipe. In the pharmaceutical care course, active learning methods were used, consisting of dialogic classroom expository, simulation and case studies. Student learning was evaluated using classroom tests and instruments that evaluated the perception of competency in pharmaceutical care practice. Furthermore, students' satisfaction with the course was evaluated. Results Thirty-three students completed the four evaluations used in the course (i.e., a discursive written exam, seminars, OSCE, and virtual patient); 25 were female (75.75%), and the median age was 23.43 (SD 2.82) years. The overall mean of student scores, in all evaluation methods was 7.97 (SD 0.59) on a scale of 0 to 10 points, and student performance on the virtual patient method was statistically superior to other methods. With respect to the perception of competency in pharmaceutical care practice, a comparison of pre- and post-test scores revealed statistically significant improvement for all evaluated competences. At the end of the semester, the students presented positive opinions of the pharmaceutical care course. Conclusions The results suggest that an active learning course can enhance the learning of pharmaceutical care competences. In future studies it will be necessary to compare active learning to traditional methods.","Introduction: Online formative assessments (OFA’s) have been increasingly recognised in medical education as resources that promote self-directed learning. Formative assessments are used to support the self-directed learning of students. Online formative assessments have been identified to be less time consuming with automated feedback. This pilot study aimed to determine whether participation and performance in online formative assessments (OFA’s) had measurable effects on learning and evaluate the students’ experience of using the OFA’s in the department of Obstetrics and Gynaecology. Methods: This is a cross-sectional study conducted among fourth year medical students (n=92) during their seven week postings in Obstetrics and Gynaecology. Five sets of online formative assessments in the format of one best answers (OBA), Objective structured practical examination (OSPE) and Short answer question (SAQ) with feedback were delivered over five weeks through the online portal. The mean scores of the end of posting summative exam (EOP) of those who participated in the assessments (OFA users) and of those who did not (non-OFA users) were compared, using Students t test. The frequency of tool usage was analysed and satisfaction surveys were utilized at the end of the course by survey questionnaire using the five point Likert scale. Results: The mean scores of the students in end of posting summative examination marks for students who had participated in the online formative assessment (OFA users) and for those who had not (non OFA users) showed no significant difference in all the three components OBA, SAQ and OSPE (p=0.902, 0.633, 0.248). Majority of the students perceived that OFAs fulfilled the stated aims and objectives and so they would persuade their peers to participate in the OFAs. Conclusions: Online formative assessments are perceived as tools that promote self-directed learning, improved knowledge and tailor learning for individual learning needs and style.","Introduction Self-directed learning (SDL) and problem-based learning (PBL) are fundamental tools to achieve lifelong learning in an integrated medical curriculum. However, the efficacy of SDL in some clinical courses is debated. Aim The aim of the study was to measure the effectiveness of SDL for an ophthalmology course in comparison with PBL. Methods A cross-sectional study was conducted with fifth-year medical students enrolled in an ophthalmology course. SDL comprised four case-based scenarios guided by several questions. PBL comprised three sessions. An ear, nose, and throat (ENT) course was selected for comparison as a control. At the end of the course, 30 multiple-choice questions (MCQs) for both SDL and PBL were assessed and analyzed against their counterparts in the ENT course by an independent t-test. Results For the SDL component of the ophthalmology course, the number and percentages of students attaining high (n = 6/60, 10%) and moderate (n = 15/60, 28.3%) scores on an MCQs written exam were evaluated. For the PBL component, high scores were seen for 23.3% (n = 14/60), and moderate scores for 33.3% (n = 20/60) of the participants. For the SDL component of the ENT course, the number and percentages of students attaining high (n = 14/60, 23.3%) and moderate (n = 17/60, 28.3%) scores were recorded. For the PBL component, high (16/60, 26.6%) and moderate (17/60, 28%) scores were recorded. Significant p-values were obtained between the results for SDL and PBL in the ophthalmology course (p = 0.009), as well as between SDL results for both courses (p = 0.0308). Moreover, differences between the SDL results of ophthalmology and the PBL results of ENT (p = 0.0372) were significant. Conclusion SDL appears to be less valuable for promotion of self-readiness. Periodic discussions in small groups or by panel discussion are strongly recommended for students to enhance readiness with SDL.","Background: Undergraduate medical examination is undergoing extensive re evaluation with new core educational objectives being defined. Consequently, new exam systems have also been designed to test the objectives. Objective structured practical examination (OSPE) is one of them. Objectives: To introduce OSPE as a method of assessment of practical skills and learning and to determine student satisfaction regarding the OSPE. Furthermore, to explore the faculty perception of OSPE as a learning and assessment tool. Materials and Methods: The first M.B.B.S students of 2011 12 batch of Medical College, Kolkata, were the subjects for the study. OSPE was organized and conducted on “Identification of Unknown Abnormal Constituents in Urine.” Coefficient of reliability of questions administered was done by calculating Cronbach's alpha. A questionnaire on various components of the OSPE was administered to get the feedback. Results: 16 students failed to achieve an average of 50% or above in the assessment. However, 49 students on an average achieved >75%, 52 students achieved between 65% and 75%, and 29 students scored between 50% and 65%. Cronbach's alpha of the questions administered showed to be having high internal consistency with a score of 0.80. Ninety nine percent of students believed that OSPE helps them to improve and 81% felt that this type of assessment fits in as both learning and evaluation tools. Faculty feedback reflected that such assessment tested objectivity, measured practical skills better, and eliminated examiner bias to a greater extent. Conclusion: OSPE tests different desired components of competence better and eliminated examiner bias. Student feedback reflects that such assessment helps them to improve as it is effective both as teaching and evaluation tools.","Objective: The aim of the study was to determine the efficacy of Team-based Learning (TBL) in an undergraduate nursing course with regard to the outcomes of academic performance (Health Education Systems Incorporated [HESI ® ] Management exam) and self-reported measures of critical thinking, leadership and management skills, overall course ratings, accountability to learning, preference for lecture or TBL, and learner satisfaction with TBL. Methods: In a quantitative, quasi-experimental post-test study, 221 undergraduate senior nursing students participated in the TBL course or a traditional instructor-led control course.  In both courses, academic performance was measured by the HESI ® Management scores; critical thinking, leadership and management skills, and overall course experience were measured using an online survey. In the TBL course, accountability to learning, preference for lecture or TBL, and learner satisfaction was measured with the Team-Based Learning Student Assessment Instrument. Results: When compared to lecture, TBL learners scored significantly higher on the HESI ® Management exam and reported significantly higher critical thinking, leadership and management skills and better overall course experience ratings ( p ≤ .01). TBL learners reported moderate to high levels of accountability, higher preference for TBL than lecture, and satisfaction with TBL. Total scores indicated moderate to high levels of favorable experiences with TBL. Conclusions: Results indicate TBL is an acceptable and efficacious instructional strategy in undergraduate nursing students. To control for extraneous factors and limit confounding, future research should evaluate the impact of TBL via a randomized control trial.","The aim of this study is to determine the effect of Learning Modeling System (LMS) Moodle in learning. The population is taken from all students of Mathematics Education, University of PGRI Semarang. The sample was randomly selected from five different course groups. The initial score is taken from the semester test, and the final score is taken through the semester test after the five groups are taught using Moodle. The results of both test results are compared to find out the increase in learning outcomes. Meanwhile, the student's attitude toward learning is taken through his mathematical disposition through questionnaire. The results show that there was a significant increase in exam results on the final exam of the semester. This result is supported by student learning interest which increases on average after using LMS Moodle taken from disposition data.",21.5027551138757,2,Unlabeled
2,student; physic; test; perform; school; score; use; exam; question; assess; differ; cours; model; data; educ,"Introduction Emergency care of older adults requires specialized knowledge of their unique physiology, atypical presentations, and care transitions. Older adults often require distinctive assessment, treatment and disposition. Emergency medicine (EM) residents should develop expertise and efficiency in geriatric care. Older adults represent over 25% of most emergency department (ED) volumes. Yet many EM residencies lack curricula or assessment tools for competent geriatric care. Fully educating residents in emergency geriatric care can demand large amounts of limited conference time. The Geriatric Emergency Medicine Competencies (GEMC) are high-impact geriatric topics developed to help residencies efficiently and effectively meet this training demand. This study examines if a 2-hour didactic intervention can significantly improve resident knowledge in 7 key domains as identified by the GEMC across multiple programs. Methods A validated 29-question didactic test was administered at six EM residencies before and after a GEMC-focused lecture delivered in summer and fall of 2009. We analyzed scores as individual questions and in defined topic domains using a paired student t test. Results A total of 301 exams were administered; 86 to PGY1, 88 to PGY2, 86 to PGY3, and 41 to PGY4 residents. The testing of didactic knowledge before and after the GEMC educational intervention had high internal reliability (87.9%). The intervention significantly improved scores in all 7 GEMC domains (improvement 13.5% to 34.6%; p<0.001). For all questions, the improvement was 23% (37.8% pre, 60.8% post; P<0.001) Graded increase in geriatric knowledge occurred by PGY year with the greatest improvement post intervention seen at the PGY 3 level (PGY1 19.1% versus PGY3 27.1%). Conclusion A brief GEMC intervention had a significant impact on EM resident knowledge of critical geriatric topics. Lectures based on the GEMC can be a high-yield tool to enhance resident knowledge of geriatric emergency care. Formal GEMC curriculum should be considered in training EM residents for the demands of an aging population.","Our previous research Kost et al., Phys. Rev. ST Phys. Educ. Res. 5, 010101 2009 examined gender differences in the first-semester, introductory physics class at the University of Colorado at Boulder. We found that: 1 there were gender differences in several aspects of the course, including conceptual survey performance, 2 these differences persisted despite the use of interactive engagement techniques, and 3 the post-test gender differences could largely be attributed to differences in males’ and females’ prior physics and math performance and their incoming attitudes and beliefs. In the current study, we continue to characterize gender differences in our physics courses by examining the second-semester, electricity and magnetism course. We analyze three factors: student retention from Physics 1 to Physics 2, student performance, and students’ attitudes and beliefs about physics, and find gender differences in all three of these areas. Specifically, females are less likely to stay in the physics major than males. Despite males and females performing about equally on the conceptual pretest, we find that females score about 6 percentage points lower than males on the conceptual post-test. In most semesters, females outperform males on homework and participation, and males outperform females on exams, resulting in course grades of males and females that are not significantly different. In terms of students’ attitudes and beliefs, we find that both males and females shift toward less expertlike beliefs over the course of Physics 2. Shifts are statistically equal for all categories except for the Personal Interest category, where females have more negative shifts than males. A large fraction of the conceptual post-test gender gap up to 60% can be accounted for by differences in males’ and females’ prior physics and math performance and their pre-Physics 2 attitudes and beliefs. Taken together, the results of this study suggest that it is an accumulation of small gender differences over time that may be responsible for the large differences that we observe in physics participation of males and females.","Background Large language models, such as ChatGPT by OpenAI, have demonstrated potential in various applications, including medical education. Previous studies have assessed ChatGPT’s performance in university or professional settings. However, the model’s potential in the context of standardized admission tests remains unexplored. Objective This study evaluated ChatGPT’s performance on standardized admission tests in the United Kingdom, including the BioMedical Admissions Test (BMAT), Test of Mathematics for University Admission (TMUA), Law National Aptitude Test (LNAT), and Thinking Skills Assessment (TSA), to understand its potential as an innovative tool for education and test preparation. Methods Recent public resources (2019-2022) were used to compile a data set of 509 questions from the BMAT, TMUA, LNAT, and TSA covering diverse topics in aptitude, scientific knowledge and applications, mathematical thinking and reasoning, critical thinking, problem-solving, reading comprehension, and logical reasoning. This evaluation assessed ChatGPT’s performance using the legacy GPT-3.5 model, focusing on multiple-choice questions for consistency. The model’s performance was analyzed based on question difficulty, the proportion of correct responses when aggregating exams from all years, and a comparison of test scores between papers of the same exam using binomial distribution and paired-sample (2-tailed) t tests. Results The proportion of correct responses was significantly lower than incorrect ones in BMAT section 2 (P<.001) and TMUA paper 1 (P<.001) and paper 2 (P<.001). No significant differences were observed in BMAT section 1 (P=.2), TSA section 1 (P=.7), or LNAT papers 1 and 2, section A (P=.3). ChatGPT performed better in BMAT section 1 than section 2 (P=.047), with a maximum candidate ranking of 73% compared to a minimum of 1%. In the TMUA, it engaged with questions but had limited accuracy and no performance difference between papers (P=.6), with candidate rankings below 10%. In the LNAT, it demonstrated moderate success, especially in paper 2’s questions; however, student performance data were unavailable. TSA performance varied across years with generally moderate results and fluctuating candidate rankings. Similar trends were observed for easy to moderate difficulty questions (BMAT section 1, P=.3; BMAT section 2, P=.04; TMUA paper 1, P<.001; TMUA paper 2, P=.003; TSA section 1, P=.8; and LNAT papers 1 and 2, section A, P>.99) and hard to challenging ones (BMAT section 1, P=.7; BMAT section 2, P<.001; TMUA paper 1, P=.007; TMUA paper 2, P<.001; TSA section 1, P=.3; and LNAT papers 1 and 2, section A, P=.2). Conclusions ChatGPT shows promise as a supplementary tool for subject areas and test formats that assess aptitude, problem-solving and critical thinking, and reading comprehension. However, its limitations in areas such as scientific and mathematical knowledge and applications highlight the need for continuous development and integration with conventional learning strategies in order to fully harness its potential.","Background Large language models (LLMs) have revolutionized natural language processing with their ability to generate human-like text through extensive training on large data sets. These models, including Generative Pre-trained Transformers (GPT)-3.5 (OpenAI), GPT-4 (OpenAI), and Bard (Google LLC), find applications beyond natural language processing, attracting interest from academia and industry. Students are actively leveraging LLMs to enhance learning experiences and prepare for high-stakes exams, such as the National Eligibility cum Entrance Test (NEET) in India. Objective This comparative analysis aims to evaluate the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. Methods In this paper, we evaluated the performance of the 3 mainstream LLMs, namely GPT-3.5, GPT-4, and Google Bard, in answering questions related to the NEET-2023 exam. The questions of the NEET were provided to these artificial intelligence models, and the responses were recorded and compared against the correct answers from the official answer key. Consensus was used to evaluate the performance of all 3 models. Results It was evident that GPT-4 passed the entrance test with flying colors (300/700, 42.9%), showcasing exceptional performance. On the other hand, GPT-3.5 managed to meet the qualifying criteria, but with a substantially lower score (145/700, 20.7%). However, Bard (115/700, 16.4%) failed to meet the qualifying criteria and did not pass the test. GPT-4 demonstrated consistent superiority over Bard and GPT-3.5 in all 3 subjects. Specifically, GPT-4 achieved accuracy rates of 73% (29/40) in physics, 44% (16/36) in chemistry, and 51% (50/99) in biology. Conversely, GPT-3.5 attained an accuracy rate of 45% (18/40) in physics, 33% (13/26) in chemistry, and 34% (34/99) in biology. The accuracy consensus metric showed that the matching responses between GPT-4 and Bard, as well as GPT-4 and GPT-3.5, had higher incidences of being correct, at 0.56 and 0.57, respectively, compared to the matching responses between Bard and GPT-3.5, which stood at 0.42. When all 3 models were considered together, their matching responses reached the highest accuracy consensus of 0.59. Conclusions The study’s findings provide valuable insights into the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. GPT-4 emerged as the most accurate model, highlighting its potential for educational applications. Cross-checking responses across models may result in confusion as the compared models (as duos or a trio) tend to agree on only a little over half of the correct responses. Using GPT-4 as one of the compared models will result in higher accuracy consensus. The results underscore the suitability of LLMs for high-stakes exams and their positive impact on education. Additionally, the study establishes a benchmark for evaluating and enhancing LLMs’ performance in educational tasks, promoting responsible and informed use of these models in diverse learning environments.","Information about score obtained from a test is often interpreted as an indicator of the student's ability level. This is one of the weaknesses of classical analysis that are unable to provide meaningful and fair information. The acquisition of the same score if it comes from a test item with a different level of difficulty, must show different abilities. Analysis of the Rasch model will overcome this weakness. The purpose of this study was to analyze the quality of the items by validating the national chemistry exam instrument using the Rasch model. The research sample was 212 new students of the Department of Chemistry at the State University of Medan. The data collected was in the form of respondent's answer data to the 2013 chemistry UN questions, which amounted to 40 items multiple choice and uses the documentation method. Data analysis technique used the Rasch Model with Ministep software. The results of the analysis show the quality of the Chemistry National Exam (UN) questions is categorized as very good based on the following aspects: unidimension, item fit test, person map item, difficulty test level, person and item reliability. There is one item found to be gender bias, in which men benefit more than women. The average chemistry ability of respondents is above the average level of difficulty of the test items","Pass rates by Texas tenth-graders on the high school exit exam improved from 52 percent in 1994 to 72 percent in 1998. In his article ""The Myth of the Texas Miracle in Education"" (EPAA, August 2000) Professor Walt Haney argued that some part of this increased pass rate was, as he put it, an illusion. Haney contended that the combined effects of students dropping out of school prior to taking the 10th grade TAAS and special education exemptions accounted for much of the increase in TAAS pass rates. Relying on the same methodology and data that Haney used, we demonstrate that his conclusion is incorrect. None of the 20 percent improvement in the TAAS exit test pass rate between 1994 and 1998 is explained by combined increases in dropout rates or special education exemptions.","The “ gender gap ” on various physics conceptual evaluations has been extensively studied. Men ’ s average pretest scores on the Force Concept Inventory and Force and Motion Conceptual Evaluation are 13% higher than women ’ s, and post-test scores are on average 12% higher than women ’ s. This study analyzed the gender differences within the Conceptual Survey of Electricity and Magnetism (CSEM) in which the gender gap has been less well studied and is less consistent. In the current study, data collected from 1407 students (77% men, 23% women) in a calculus-based physics course over ten semesters showed that male students outperformed female students on the CSEM pretest (5%) and post-test (6%). Separate analyses were conducted for qualitative and quantitative problems on lab quizzes and course exams and showed that male students outperformed female students by 3% on qualitative quiz and exam problems. Male and female students performed equally on the quantitative course exam problems. The gender gaps within CSEM post-test scores, qualitative lab quiz scores, and qualitative exam scores were insignificant for students with a CSEM pretest score of 25% or less but grew as pretest scores increased. Structural equation modeling demonstrated that a latent variable, called Conceptual Physics Performance/Non-Quantitative (CPP/NonQnt), orthogonal to quantitative test performance was useful in explaining the differences observed in qualitative performance; this variable was most strongly related to CSEM post-test scores. The CPP/NonQnt of male students was 0.44 standard deviations higher than female students. The CSEM pretest measured CPP/NonQnt much less accurately for women ( R 2 ¼ 4% ) than for men ( R 2 ¼ 17% ). The failure to detect a gender gap for students scoring 25% or less on the pretest suggests that the CSEM instrument itself is not gender biased. The failure to find a performance difference in quantitative test performance while detecting a gap in qualitative performance suggests the qualitative differences do not result from psychological factors such as science anxiety or stereotype threat. DOI: 10.1103/PhysRevPhysEducRes.13.020114","With the rapid evolution of artificial intelligence (AI), its potential implications for higher education have become a focal point of interest. This study delves into the capabilities of AI in physics education and offers actionable AI policy recommendations. Using openAI’s flagship gpt-3.5-turbo large language model (LLM), we assessed its ability to answer 1337 physics exam questions spanning general certificate of secondary education (GCSE), A-Level, and introductory university curricula. We employed various AI prompting techniques: Zero Shot, in context learning, and confirmatory checking, which merges chain of thought reasoning with reflection. The proficiency of gpt-3.5-turbo varied across academic levels: it scored an average of 83.4% on GCSE, 63.8% on A-Level, and 37.4% on university-level questions, with an overall average of 59.9% using the most effective prompting technique. In a separate test, the LLM’s accuracy on 5000 mathematical operations was found to be 45.2%. When evaluated as a marking tool, the LLM’s concordance with human markers averaged at 50.8%, with notable inaccuracies in marking straightforward questions, like multiple-choice. Given these results, our recommendations underscore caution: while current LLMs can consistently perform well on physics questions at earlier educational stages, their efficacy diminishes with advanced content and complex calculations. LLM outputs often showcase novel methods not in the syllabus, excessive verbosity, and miscalculations in basic arithmetic. This suggests that at university, there’s no substantial threat from LLMs for non-invigilated physics questions. However, given the LLMs’ considerable proficiency in writing physics essays and coding abilities, non-invigilated examinations of these skills in physics are highly vulnerable to automated completion by LLMs. This vulnerability also extends to pysics questions pitched at lower academic levels. It is thus recommended that educators be transparent about LLM capabilities with their students, while emphasizing caution against overreliance on their output due to its tendency to sound plausible but be incorrect.","This paper examines the relationship between the type of senior high school attended by Indonesian youth and their subsequent labor market outcomes. This topic is very timely, given the governments recent decision to dramatically expand vocational enrollment. The analysis controls for an unusually rich set of predetermined characteristics, and exploits longitudinal data spanning 14 years to separately identify cohort and age effects. There are four main findings. First, students are sorted into different school types largely on the basis of their entering exam score. Public schools attract the highest-scoring students, while private vocational schools serve the lowest-scoring students. Second, after controlling for a variety of characteristics, including test scores, male public school graduates earn a substantial premium over their privately schooled counterparts. Third, private vocational school graduates fare at least as well as private general graduates, despite coming from more disadvantaged socioeconomic backgrounds. Finally, the returns to public vocational education have declined sharply for the most recent cohort of men. This raises important concerns about the current expansion of public vocational education, and the relevance of the male vocational curriculum in an increasingly service-oriented economy.","Does school climate ameliorate or exacerbate the impact of neighborhood violent crime on test scores? Using administrative data from the New York City Department of Education and the New York City Police Department, we find that exposure to violence in the residential neighborhood and an unsafe climate at school lead to substantial test score losses in English language arts (ELA). Middle school students exposed to neighborhood violent crime before the ELA exam who attend schools perceived to be less safe or to have a weak sense of community score 0.06 and 0.03 standard deviations lower, respectively. We find the largest negative effects for boys and Hispanic students in the least safe schools, and no effect of neighborhood crime for students attending schools with better climates.",16.6437209534316,0,Unlabeled
3,group; student; test; score; medic; exam; studi; signific; anxieti; differ; method; two; control; use; cours,"Background: Concerning the prevalence of test anxiety among nursing students and presence of stress in nursing education years, this study was conducted to determine the effect of progressive muscle relaxation method on test anxiety among nursing students of Isfahan University of Medical Sciences in 2013. Materials and Methods: This was a quasi-experimental study conducted in three stages on 49 male and female nursing students divided into two groups (study and control). In the pre-test stage, demographic data and Sarason anxiety questionnaires were filled by 94 students (of terms 3 and 4). Then, in the intervention stage, the students having test anxiety were assigned to two groups (study and control), and the progressive muscle relaxation method was performed in the experiment group in four sessions. Then, the students did this method two times a day until final exams, immediately following which they filled the self-reported checklists. On the first day of the final exams, test anxiety questionnaire was filled by the two groups again. The collected data were analyzed by the statistical tests, i.e. χ2, paired t-test, independent sample t-test, Mann–Whitney and Wilcoxon tests, using SPSS 18. Results: Independent t-test showed a significant difference in the mean scores of test anxiety after intervention between the two groups of study and control (P = 0.00), but this difference was not significant before intervention (P = 0.76). Also, in the study group, there was a significant difference in the mean scores of test anxiety before and after intervention (P = 0.00), but this difference was not significant in the control group (P = 0.09). Mann–Whitney test showed no significant difference in categorization of test anxiety scores before intervention in the study and control groups (P = 0.60), but the difference was significant after intervention (P = 0.00). Wilcoxon test showed a significant difference in categorization of test anxiety scores in the study group before and after intervention (P = 0.00), but the difference was not significant in the control group (P = 0.083). Conclusions: Generally, the results showed that performing progressive muscle relaxation method was effective in reducing test anxiety among nursing students. It is suggested to conduct educational programs concerning this method in the faculties of nursing to decrease the test anxiety of nursing students.","Background: Test anxiety often leads to poor academic performance. This study aimed to determine the effect of computer-based tests on nursing students’ test anxiety. Methods: This quasi-experimental study was conducted in 2016 on 39 nursing student with anxiety score under 128 on Spielberger’s State-Trait Inventory (STAI). They were randomly allocated to computer-based tests (CBT) and paper-based test (PBT) group. Prior to exam, all students completed Sarason’s Test Anxiety Scale (TAS). We administered CBT for students in experimental group. Data were analyzed using independent t-test and one-way ANOVA. Results: Students mean test anxiety score was 11.94 and 11.32 in CBT and PBT groups, respectively. 47.4% of students in CBT group and 29.4% of those in PBT group experienced higher test anxiety, while the difference was not significant (p=0.56). Conclusions: Despite, there was no significant difference between anxiety score of two groups; but students’ test anxiety score was higher in CBT group. With the current increase in computer-based assessment, educational administrators must be aware of and plan for the possible unfavorable effects of computer assisted testing, such an anxiety. Future studies are needed to evaluate and compare the effect of different type of student testing such as distance testing or CBTs using new information technologies such as laptop, tablet or mobile phone on students’ test anxiety and performance.","Background Medical student ultrasound education is sparse. In 2002, we began the first medical student rotation in emergency ultrasound. Objective To evaluate if medical students can learn and retain sonographic skills during a two- or four-week elective. Methods We gave students an exam on the first and last days of the rotation. Six months later, students took the exam a third time. A control group was used for comparison. Results Over a 19-month period, we enrolled 45 students (25 on the two-week and 20 on the four-week elective). The four-week student post-test score was significantly better than the two- week post-test score (81% vs 72%, p=0.003). On the six-month exam, the four-week student post-test score was significantly better than the two-week post-test score (77% vs 69%, p=0.008). The control group did not statistically improve. Conclusion Medical students can learn bedside ultrasound interpretation with clinical integration and retain the knowledge six months later.","Introduction The curriculum in most emergency medicine (EM) clerkships includes very little formalized training in point-of-care ultrasound. Medical schools have begun to implement ultrasound training in the pre-clinical curriculum, and the EM clerkship is an appropriate place to build upon this training. The objectives are (1) to evaluate the effectiveness of implementing a focused ultrasound curriculum within an established EM clerkship and (2) to obtain feedback from medical students regarding the program. Methods We conducted a prospective cohort study of medical students during an EM clerkship year from July 1, 2011, to June 30, 2012. Participants included fourth-year medical students (n=45) enrolled in the EM clerkship at our institution. The students underwent a structured program focused on the focused assessment with sonography for trauma exam and ultrasound-guided vascular access. At the conclusion of the rotation, they took a 10-item multiple choice test assessing knowledge and image interpretation skills. A cohort of EM residents (n=20) also took the multiple choice test but did not participate in the training with the students. We used an independent samples t-test to examine differences in test scores between the groups. Results The medical students in the ultrasound training program scored significantly higher on the multiple-choice test than the EM residents, t(63)=2.3, p<0.05. The feedback from the students indicated that 82.8% were using ultrasound on their current rotations and the majority (55.2%) felt that the one-on-one scanning shift was the most valuable aspect of the curriculum. Discussion Our study demonstrates support for an ultrasound training program for medical students in the EM clerkship. After completing the training, students were able to perform similarly to EM residents on a knowledge-based exam.","Background Point-of-care ultrasonography (PoCUS) is a rapidly evolving discipline that aims to train non-cardiologists, non-radiologists clinicians in performing bedside ultrasound to guide clinical decision. Training of PoCUS is challenging, time-consuming and requires large amount of resources. The objective of our study was to evaluate if this training process can be simplified by allowing medical students self-train themselves with a web-based cardiac ultrasound software. Methods A prospective, single blinded, cohort study, comparing performance of 29 medical students in performing a six-minutes cardiac ultrasound exam. Students were divided into two groups: self-learning group, using a combination of E-learning software and self-practice using pocket ultrasound device compared to formal, frontal cardiac ultrasound course. Results All 29 students completed their designated courses and performed the six-minutes exam: 20 students participated in the frontal cardiac ultrasound course and 9 completed the self-learning course. The median (Q1,Q3) test score for the self-learning group was higher than the frontal course group score, 18 (15,19) versus 15 (12,19.5), respectively. Nevertheless, no statistically significant difference was found between the two study groups (p = 0.478). All students in the self-learning course group (9/9, 100%) and 16 (16/20, 80%) of students in the frontal ultrasound course group obtained correct alignment of the parasternal long axis view (p = 0.280). Conclusions Self-learning students combining E-learning software with self-practice cardiac ultrasound were as good as students who received a validated, bedside, frontal cardiac ultrasound course. Our findings suggest that independent cardiac ultrasound learning, combining utilization of E–learning software and self-practice, is feasible. Self-E- learning of cardiac ultrasound may serve as an important, cost-effective adjunct to heavily resource consuming traditional teaching.","Collaborative testing has been shown to improve performance but not always content retention. In this study, we investigated whether collaborative testing could improve both performance and content retention in a large, introductory biology course. Students were semirandomly divided into two groups based on their performances on exam 1. Each group contained equal numbers of students scoring in each grade category (“A”–“F”) on exam 1. All students completed each of the four exams of the semester as individuals. For exam 2, one group took the exam a second time in small groups immediately following the individually administered test. The other group followed this same format for exam 3. Individual and group exam scores were compared to determine differences in performance. All but exam 1 contained a subset of cumulative questions from the previous exam. Performances on the cumulative questions for exams 3 and 4 were compared for the two groups to determine whether there were significant differences in content retention. Even though group test scores were significantly higher than individual test scores, students who participated in collaborative testing performed no differently on cumulative questions than students who took the previous exam as individuals.","Introduction: Instruction in teacher-centered formats may lead to early learning fatigue, which in turn, decelerates students’ knowledge retrieval. Presently, teachers try to increase students' participation and their active attention to course content by incorporating effective, applicable, low-cost, and enjoyable teaching apparatuses. Methods: The participants of this quasi-experimental study were the students of speech therapy in 4th semester (n=83) at Ahvaz Jundishapur University of Medical Sciences. They were simple-randomly divided into two groups of experimental (who received the crossword puzzle accompanied by lecture or the hybrid method as Group A) and control (who received the traditional method as Group B). The students' knowledge level and students' satisfaction with their received instruction methods were assessed as outcome measures throughout the experiment for both groups. The test score of students' initial knowledge of the concepts in Speech Therapy, the score from the semester final exam of the courses in forms of multiple choice questions, and the retained learning score were calculated as the pre-test, post-test and a follow-up measurement, respectively. Independent-samples T-test for comparative analyses of students' satisfaction between the pre-test and post-test, and multivariate repeated measures ANOVA test were used to analyze the students' knowledge level at three time-points (before, immediately after, and one month after the trainings). The data were analyzed using SPSS ver. 18.0 software, and at the level of statistical significance of P≤0.05. Results: Both educational methods significantly improved the students' knowledge level after the trainings (P=0.030); however, the mean score of knowledge and learning of Group A (mean=17.14) were significantly higher than that of Group B (mean=16.02) immediately after (P=0.036) and one month after the trainings (mean=18.26 vs. 16.10) (P=0.001). The mean score of students' satisfaction in Group A was also significantly higher than that in Group B (P=0.010). Conclusion: Utilizing the crossword puzzle as an enjoyable and participatory teaching tool accompanied by lecture could improve management quality in Speech Therapy sessions.","By taking notes students could save time for reading all textbooks for their exams or for their representations. Taking notes increases attention of students to read or heard materials, and this increases their comprehension. Thus, the present study is important because note-taking could help them to remember what they learnt, absolutely important information. The method used in this research was survey. The 40 Persian EFL learners were selected from a language institute in Karaj to participate in the present study. These learners were divided into two groups; one of them is experimental group (N=20) and the other one is control group (N=20). Pretest and post test were two instruments that were used to carry out this study, a pretest about skill of note-taking of passages of the lessons was used for both experimental and control group. This test consisted of 4 passages. The same test was administrated again as the post test for both groups by the end of the course to see the different conclusion between taking note of experimental group and control group. Reliability between 4 texts is in oscillation from 0.6 to 0.81 (from 0.6 upwards). Therefore this reliability was an acceptable one. To analyze data descriptive statistics (that was contained percentage, frequency and mean score) and also inferential statistics (that was contained ANOVA, Pearson correlation, independent sample t-test, multivariate’s test, regression) were carried out by using SPSS16 soft ware. The findings confirmed that note taking is effective in reading comprehension.","Abstract Objective: To evaluate whether computer-based learning (CBL) improves newly acquired knowledge and is an effective strategy for teaching prenatal ultrasound diagnostic skills to third-year medical students when compared with instruction by traditional paper-based methods (PBM). Study Design: We conducted a randomized, prospective study involving volunteer junior (3rd year) medical students consecutively rotating through the Obstetrics and Gynecology clerkship during six months of the 2005-2006 academic year. The students were randomly assigned to permuted blocks and divided into two groups. Half of the participants received instruction in prenatal ultrasound diagnostics using an interactive CBL program; the other half received instruction using equivalent material by the traditional PBM. Outcomes were evaluated by comparing changes in pre-tutorial and post instruction examination scores. Results: All 36 potential participants (100%) completed the study curriculum. Students were divided equally between the CBL (n=18) and PBM (n=18) groups. Pre-tutorial exam scores (mean ± s.d.) were 44% ± 11.1% for the CBL group and 44% ± 10.8% for the PBL cohort, indicating no statistically significant differences (p > 0.05) between the two groups. After instruction, post-tutorial exam scores (mean ± s.d.) were increased from the pre-tutorial scores, 74% ± 11% and 67% ± 12%, for students in the CBL and the PBM groups, respectively. The improvement in post-tutorial exam scores from the pre-test scores was considered significant (p < 0.05). When post-test scores for the tutorial groups were compared, the CBL subjects achieved a score that was, on average, 7 percentage points higher than their PBM counterparts, a statistically significant difference (p < 0.05). Conclusion: Instruction by either CBL or PBM strategies is associated with improvements in newly acquired knowledge as reflected by increased post-tutorial examination scores. Students that received CBL had significantlyhigher post-tutorial exam scores than those in the PBM group, indicating that CBL is an effective instruction strategy in this setting.","Objectives To assess illness script richness and maturity in preclinical students after they attended a specifically structured instructional format, i.e., a case based clinical reasoning (CBCR) course. Methods In a within-subject experimental design, medical students who had finished the CBCR course participated in an illness script experiment. In the first session, richness and maturity of students’ illness scripts for diseases discussed during the CBCR course were compared to illness script richness and maturity for similar diseases not included in the course. In the second session, diagnostic performance was tested, to test for differences between CBCR cases and non-CBCR cases. Scores on the CBCR course exam were related to both experimental outcomes. Results Thirty-two medical students participated. Illness script richness for CBCR diseases was almost 20% higher than for non-CBCR diseases, on average 14.47 (SD=3.25) versus 12.14 (SD=2.80), respectively (p<0.001). In addition, students provided more information on Enabling Conditions and less on Fault-related aspects of the disease. Diagnostic performance was better for the diseases discussed in the CBCR course, mean score 1.63 (SD=0.32) versus 1.15 (SD=0.29) for non-CBCR diseases (p<0.001). A significant correlation of exam results with recognition of CBCR cases was found (r=0.571, p<0.001), but not with illness script richness (r=–0.006, p=NS). Conclusions The CBCR-course fosters early development of clinical reasoning skills by increasing the illness script richness and diagnostic performance of pre-clinical students. However, these results are disease-specific and therefore we cannot conclude that students develop a more general clinical reasoning ability.",18.9115302993384,4,Unlabeled
4,student; score; perform; exam; studi; medic; academ; test; year; stress; use; predict; correl; signific; examin,"Background Objective Structured Clinical Examinations (OSCEs) have been used to assess the clinical competence of medical students for decades. Limited data are available on the factors that predict students’ performance on the OSCEs. The aim of our study was to evaluate the factors predicting performance on the pediatrics final OSCE, including the timing of students’ clerkship and their performance on the in-training OSCE and written examinations. Methods Grades in pediatrics for 3 consecutive academic years (2013–2016) were included. The average scores of the in-training OSCEs, written and final OSCEs and written exams were compared among the three years using the analysis of variance (ANOVA) test. The correlations between performance on the final OSCEs and the in-training OSCEs, in-training written exams and final written exams were studied using Spearman’s Rho correlation test. The effect of the timing of the clerkship on the final OSCE performance was evaluated. Results A total of 286 students’ records were included. There were 115 male students and 171 female students (M:F 1:1.5). There were strong positive correlations between students’ performance on the in-training examinations (OSCE and written) and the final OSCE (correlation coefficients of 0.508 and 0.473, respectively). The final written exam scores were positively correlated with the final OSCEs (r = 0.448). There was no significant effect of the timing of the clerkship. Conclusions Students’ performance on in-training examinations might predict their final OSCE scores. Thus, it is important to provide students with the necessary intervention at an early stage to reduce failure rates. The final OSCE performance does not seem to be affected by the timing of the clerkship.","OBJECTIVES The aim of this study was to assess the psychological health of first-year health professional students and to study sources of student stress. METHODS All first-year students (N = 125) of the Gulf Medical University (GMU) in Ajman, United Arab Emirates (UAE), were invited to participate in a voluntary, anonymous, self-administered, questionnaire-based survey in January 2011. Psychological health was assessed using the 12-item General Health Questionnaire. A 24-item questionnaire, with items related to academic, psychosocial and health domains was used to identify sources of stress. Pearson's chi-squared test and the Mann-Whitney U-test were used for testing the association between psychological morbidity and sources of stress. RESULTS A total of 112 students (89.6%) completed the survey and the overall prevalence of psychological morbidity was found to be 33.6%. The main academic-related sources of stress were 'frequency of exams', 'academic workload', and 'time management'. Major psychosocial stressors were 'worries regarding future', 'high parental expectations', 'anxiety', and 'dealing with members of the opposite sex'. Health-related issues were 'irregular eating habits', 'lack of exercise', and 'sleep-related problems'. Psychological morbidity was not significantly associated with any of the demographic factors studied. However, total stress scores and academics-related domain scores were significantly associated with psychological morbidity. CONCLUSION Psychological morbidity was seen in one in three first-year students attending GMU. While worries regarding the future and parental expectations were sources of stress for many students, psychological morbidity was found to be significantly associated with only the total stress and the academic-related domain scores.","OBJECTIVE The aim of this study was to assess the relationship between the use of neuroenhancing substances, exam anxiety and academic performance among first-year Bosnian-Herzegovinian (BH) university students. METHODS In a cross-sectional study, an ad hoc questionnaire was delivered to a sample of BH first-year university students. The following data were collected: socio-demographic features, consumption of neuroenchancing substances, the Westside Test Anxiety Scale (WTAS) and academic performance. RESULTS A total of 214 students were included. Consumption of lifestyle substances, coffee, energy drinks, nicotine, alcohol, and marijuana, for the purpose of neuroenhancement increased during the week before the exams. OTC cognitive enhancer use was reported by 31.0%, and of benzodiazepines by 1.5% of students. No psycostimulants were used. A high to extremely high exam WTAS score was reported in 38.3% students. The exam WTAS score was positively correlated with consumption of coffee (rho=0.31; P<0.001), energy drinks (rho=0.18; P=0.009), and nicotine (rho=0.22; P=0.001), and negatively correlated with last exam grade (rho=-0.33; P<0.001). The exam WTAS score was a significant independent predictor (OR=0.55; 95% CI 0.31 to 0.97, P=0.039) for self-assessed academic performance. Self-assessed academic performance was positively correlated with last exam grade (rho=0.15; P=0.043). CONCLUSIONS Although first-year BH university students do not seem to use either prescription or illicit psycostimulants, the consumption of nicotine, alcohol, and marijuana is worrying. However, the consumption of these neuroenhancing substances seems not to be related to better self-assessed academic performance. Finally, exam anxiety seems to be a significant problem among BH first-year university students.","Objectives To examine the predictive validity of pre-admission variables on students’ performance in a medical school in Saudi Arabia. Methods In this retrospective study, we collected admission and college performance data for 737 students in preclinical and clinical years. Data included high school scores and other standardized test scores, such as those of the National Achievement Test and the General Aptitude Test. Additionally, we included the scores of the Test of English as a Foreign Language (TOEFL) and the International English Language Testing System (IELTS) exams. Those datasets were then compared with college performance indicators, namely the cumulative Grade Point Average (cGPA) and progress test, using multivariate linear regression analysis. Results In preclinical years, both the National Achievement Test (p=0.04, B=0.08) and TOEFL (p=0.017, B=0.01) scores were positive predictors of cGPA, whereas the General Aptitude Test (p=0.048, B=-0.05) negatively predicted cGPA. Moreover, none of the pre-admission variables were predictive of progress test performance in the same group. On the other hand, none of the pre-admission variables were predictive of cGPA in clinical years. Overall, cGPA strongly predict-ed students’ progress test performance (p<0.001 and B=19.02). Conclusions Only the National Achievement Test and TOEFL significantly predicted performance in preclinical years. However, these variables do not predict progress test performance, meaning that they do not predict the functional knowledge reflected in the progress test. We report various strengths and deficiencies in the current medical college admission criteria, and call for employing more sensitive and valid ones that predict student performance and functional knowledge, especially in the clinical years.","Background: Identification of the potential sources of stress is important in dental education program, as it gives opportunity to take various measures to prevent stress in the dental school environment. The purpose of the present study was to address various sources of stress among dental school students and its relation with gender and year of the study. Materials and Methods: A questionnaire based cross-sectional study was conducted among 3 rd and 4 th year students of a dental school. Questionnaire used in the study comprised the modified version of the questionnaire used in Dental Environmental Stress. A four-point Likert scale was used to record the responses from the subjects. A total of 174 subjects participated in the study. Statistical analysis was done using SPSS package version 16. Results: Of the participants, 39% (68) were males and 61% (106) were females. Majority of students felt stressed about academic performance, clinic/patient related stress, and career related stress. Top stressors in academic performance related stress were exam and grade stress (95%), followed by fear of failing (90.5%), lack of time between tests/clinics, and criticism at work (94%). Mean stress scores were significantly related to year and gender of students. Conclusion: Worries about fulfilling clinical requirements, academics, exam stress, and insecurity regarding career were the major sources of stress reported by the clinical year dental students in the present study.","Objectives: To evaluate the correlation and concordance between the ‘Peruvian National Exam of Medicine’ (ENAM) and the Mean Grade Point Average (GPA) in recently graduated medical students in the period 2007 to 2009. Materials and Methods: We carried out a secondary data analysis, using the records of the physicians applying to the Rural and Urban Marginal Service in Health of Peru (SERUMS) processes for the years 2008 to 2010. We extracted from these registers, the grades obtained in the ENAM and GPA. We performed a descriptive analysis using medians and 1 st and 3 rd quartiles (q1/q3); we calculated the correlation between both scores using the Spearman correlation coefficient, additionally, we conducted a lineal regression analysis, and the concordance was measured using the Bland and Altman coefficient. Results: A total of 6 117 physicians were included, the overall median for the GPA was 13.4 (12.7/14.2) and for the ENAM was 11.6 (10.2/13.0).Of the total assessed, 36.8% failed the TEST. We observed an increase in annual median of ENAM scores, with the consequent decrease in the difference between both grades. The correlation between ENAM and PPU is direct and moderate (0.582), independent from the year, type of university management (Public or Private) and location. However, the concordance between both ratings is regular, with a global coefficient of 0.272 (CI 95%: 0.260 to 0.284). Conclusions: Independently of the year, location or type of university management, there is a moderate correlation between the ENAM and the PPU; however, there is only a regular concordance between both grades.","Background Graduate entry medicine raises new questions about the suitability of students with different backgrounds. We examine this, and the broader issue of effectiveness of selection and assessment procedures. Methods The data included background characteristics, academic record, interview score and performance in pre-clinical modular assessment for two years intake of graduate entry medical students. Exploratory factor analysis is a powerful method for reducing a large number of measures to a smaller group of underlying factors. It was used here to identify patterns within and between the selection and performance data. Principal Findings Basic background characteristics were of little importance in predicting exam success. However, easily interpreted components were detected within variables comprising the ‘selection’ and ‘assessment’ criteria. Three selection components were identified (‘Academic’, ‘GAMSAT’, ‘Interview’) and four assessment components (‘General Exam’, ‘Oncology’, ‘OSCE’, ‘Family Case Study’). There was a striking lack of relationships between most selection and performance factors. Only ‘General Exam’ and ‘Academic’ showed a correlation (Pearson's r = 0.55, p<0.001). Conclusions This study raises questions about methods of student selection and their effectiveness in predicting performance and assessing suitability for a medical career. Admissions tests and most exams only confirmed previous academic achievement, while interview scores were not correlated with any consequent assessment.","Introduction The purpose of this study was to determine the associations and predictive values of Medical College Admission Test (MCAT) component and composite scores prior to 2015 with U.S. Medical Licensure Exam (USMLE) Step 1 and Step 2 Clinical Knowledge (CK) scores, with a focus on whether students scoring low on the MCAT were particularly likely to continue to score low on the USMLE exams. Method Multiple linear regression, correlation, and chi-square analyses were performed to determine the relationship between MCAT component and composite scores and USMLE Step 1 and Step 2 CK scores from five graduating classes (2011–2015) at the University of Minnesota Medical School (N=1,065). Results The multiple linear regression analyses were both significant (p<0.001). The three MCAT component scores together explained 17.7% of the variance in Step 1 scores (p<0.001) and 12.0% of the variance in Step 2 CK scores (p<0.001). In the chi-square analyses, significant, albeit weak associations were observed between almost all MCAT component scores and USMLE scores (Cramer's V ranged from 0.05 to 0.24). Discussion Each of the MCAT component scores was significantly associated with USMLE Step 1 and Step 2 CK scores, although the effect size was small. Being in the top or bottom scoring range of the MCAT exam was predictive of being in the top or bottom scoring range of the USMLE exams, although the strengths of the associations were weak to moderate. These results indicate that MCAT scores are predictive of student performance on the USMLE exams, but, given the small effect sizes, should be considered as part of the holistic view of the student.","Introduction The purpose of this study was to determine the associations of the demographic variables of gender, state of legal residency, student age, and undergraduate major with scores on the Medical College Admissions Test (MCAT) and the United States Medical Licensing Exam (USMLE) Step 1 and Step 2 Clinical Knowledge. Methods The researchers collected and analyzed exam scores and demographic student data from participants of five graduating classes of students at the University of Minnesota Medical School (N = 1,067). Results Significant differences (p < 0.05) were found for traditional-aged (defined as < 25 years old at matriculation) versus nontraditional-aged students on USMLE Step 1 scores (t[1065] = 2.91, p = 0.004) and USMLE Step 2 scores (t[1061] = 4.39, p < 0.001), both in favor of traditional-aged students. Significant differences were found for males versus females on MCAT Composite scores (t[1063] = 6.53, p < 0.001) and USMLE Step 1 scores (t[1065] = 5.14, p < 0.001), both in favor of males. There were no significant differences between science and nonscience majors or between Minnesota legal residents and nonresidents. Conclusion Traditional age and male gender were associated with higher exam scores, although patterns differed between tests, whereas undergraduate major and state of legal residency were not associated with higher exam scores.",Purpose Examine the factors improving performance on national medical licensing board examinations. Rationale Accreditation Council for Graduate Medical Education (ACGME) accredited residency programs report the United States Medical Licensing Examination (USMLE) Step 1 and Comprehensive Osteopathic Licensing Examination-USA (COMLEX-USA) Level 1 scores as the most important criteria in selecting candidates to interview. Hypotheses (1) Certain resources are superior for exam preparation. (2) Certain practice tests better assess exam preparedness. (3) USMLE performance will correlate with the COMLEX-USA. Methods One-hundred and two (102) medical students were surveyed regarding preparation for and performance on COMLEX-USA Level 1 and USMLE Step 1. Results USMLE-specific question banks were positively correlated with performance on COMLEX-USA Level 1 and USMLE Step 1 while COMLEX-specific question banks showed no correlation. National Board of Medical Examiners (NBME) Comprehensive Basic Science Self Assessment (CBSSA) and National Board of Osteopathic Medical Examiners (NBOME) Comprehensive Osteopathic Medical Self-Assessment Examination (COMSAE) practice examinations were positively correlated with performance on the USMLE Step 1 and the COMLEX-USA Level 1. Scores on USMLE Step 1 and COMLEX-USA Level 1 were highly correlated. Students who took USMLE Step 1 performed better on COMLEX-USA Level 1 than those who did not. Conclusion COMLEX-specific resources may not adequately prepare students for COMLEX-USA Level 1. Students studying for COMLEX-USA Level 1 may benefit by preparing for USMLE Step 1.,18.852287791274,1,Unlabeled
5,student; exam; score; test; use; studi; educ; result; teacher; teach; learn; effect; statist; time; academ,"Teacher education programs are often accused of lacking intellectual rigor and failing to cultivate the competencies their graduates will need. Using data from the National Survey of Student Engagement, Mr. Carini and Mr. Kuh find that the educational experiences of future teachers compare favorably with those of other students in college. However, these positive experiences do not necessarily stem from teacher education programs. SOONER OR LATER, discussions of schooling turn to teacher quality. Both educational leaders and the general public agree that high-quality teachers are a key to boosting student achievement.1 Why might we not have the high-quality teachers we need? Two reasons dominate the debate. The first is self-selection -- the academic ability of those who choose to teach is thought to be a cut (or more) below that of peers headed to other vocations. Second, teacher preparation programs supposedly lack intellectual rigor and don't cultivate certain critical skills and competencies in their students. Though the evidence supporting these claims is far from conclusive,2 universities and policy makers seem determined to upgrade teacher quality. One popular approach is to raise the bar for entry into teacher preparation programs by requiring higher minimum college grades or higher scores on entrance exams. This strategy recalls the specious criteria used in many annual rankings of colleges and universities in which higher scores on such input measures as entrance tests and more resources for faculty salaries or in an endowment yield higher ""quality"" rankings for the university. The public remains mesmerized by such ranking schemes, despite decades of research on college-level learning that point to a very different conclusion. Indeed, studies show that what matters far more to learning and a host of other desired outcomes during college is what students do with their time and how they use the institution's educational resources, not the test scores they bring to college or the resources a school has. Equally important, scores on college entrance tests and even such outcome measures as the Praxis I and II exams don't tell us what we should focus on to enhance teacher preparation, because it isn't clear which institutional policies or practices affect the outcomes of interest. Looking Behind Test Scores and Outcomes The best predictor of learning and personal development for college students is the amount of time and energy they expend on educationally fruitful activities.3 For example, the more students study or practice, the more they learn or the better they become at something. How can we find out whether students are doing these and other productive activities during college? Process indicators are one potentially instructive source of information. These are measures that represent effective educational practices -- student and institutional behaviors that theory and research show are empirically linked to desired outcomes.4 The argument goes like this: future teachers who are challenged more academically during college or who have considerable firsthand experience in educationally meaningful pursuits, such as active and collaborative learning or classes that demand the use of higher-order thinking skills, will tend to be more effective teachers after college because they will learn more during college and will be well positioned to use similar strategies in their own teaching.5 Consider service learning, which is linked to a host of desirable outcomes.6 If we think of service learning as ""a teaching strategy that connects community service with the curriculum,""7 it stands to reason that teachers who've had this experience during college will be better prepared to use this and allied instructional strategies in their own classrooms when they begin teaching. If teacher education programs had valid, reliable process indicators, then faculty members and others could diagnose in which areas prospective teachers were underperforming relative to established standards or compared with their peers in other fields. …",This study was designed to measure students’ voluntary use of retrieval practice as a review tool. Students who used test-based reviews scored higher on exams than students who used reading-based reviews. Showing students exam performance associated with test- vs. reading-based reviews coincided with a significant increase in use of test-based reviews.,"Over the past decades many teaching strategies have been proposed by various educators to improve education of all students including students with special needs. No single one of these proposed teaching strategies meets the needs of all students. The new Every Student Succeeds Act, successor to No Child Left behind Law, which transfers oversight from federal level back to states, could be a benefactor for constructivism and special education. Educators are also optimistic that the new Every Student Succeeds Act will be better for vulnerable students in special education because it will introduce more flexibility in how individual states carry out evaluation of students and teachers. In addition, it will provide more flexibility on testing and adapt the curriculum to student’s needs. It would further reduce time and energy for students preparing for standardized tests or statewide exams. It will also end “Adequate Yearly Progress”-a measure that required schools to show test score gains. Constructivist teaching philosophy is all about accepting student autonomy where student thinking drives the lessons, where dialogue, inquiry, and puzzlement are valued and assessing student learning is in the context of teaching. It helps teachers to draw on new ideas as they make decisions about which teaching techniques are most appropriate for all students to learn. Now is the time to revisit the great debate of constructivism versus teacher-centered instruction and special education. Time has come to effectively explore our educational system and examine the core unit of the whole enterprise, the textbook, the classroom, a setting that is often dominated by teacher talk and students listen.","Achievement test scores are used to diagnose strengths, weaknesses, and a basis for awarding prizes, scholarship, or degrees. They are also used in evaluating the influences of course of study, teachers, teaching methods, and other factors considered to be significant in educational practice. Still, sometimes there is a gap in the score of essay tests and the existing knowledge of examinees. In the present study, the relationship between writing skill and the academic achievement of Iranian EFL students was examined to find a logical connection between them. The results of four final exams as content scores were examined and scored again in term of writing ability in analytical scoring scheme according to IELTS criteria. Then the average of two sets of scores calculated by two raters was compared with content scores of the same tests. The results showed that correlation between content score of all students and their writing skills is meaningful at 0.01 level of significance. The results showed that there is a strong relationship between EFL students' degree of content score and their writing skill.","The introduction of computer-based testing in high-stakes examining in higher education is developing rather slowly due to institutional barriers (the need of extra facilities, ensuring test security) and teacher and student acceptance. From the existing literature it is unclear whether computer-based exams will result in similar results as paper-based exams and whether student acceptance can change as a result of administering computer-based exams. In this study, we compared results from a computer-based and paper-based exam in a sample of psychology students and found no differences in total scores across the two modes. Furthermore, we investigated student acceptance and change in acceptance of computer-based examining. After taking the computer-based exam, fifty percent of the students preferred paper-and-pencil exams over computer-based exams and about a quarter preferred a computer-based exam. We conclude that computer-based exam total scores are similar as paper-based exam scores, but that for the acceptance of high-stakes computer-based exams it is important that students practice and get familiar with this new mode of test administration.","To test the hypothesis that adding course structure may encourage self-regulated learning skills resulting in an increase in student exam performance in the community college setting, we added daily preclass online, open-book reading quizzes to an introductory biology course. We compared three control terms without reading quizzes and three experimental terms with online, open-book reading quizzes; the instructor of record, class size, and instructional time did not vary. Analyzing the Bloom’s taxonomy level of a random sample of exam questions indicated a similar cognitive level of high-stakes assessments across all six terms in the study. To control for possible changes in student preparation or ability over time, we calculated each student’s grade point average in courses other than biology during the term under study and included it as a predictor variable in our regression models. Our final model showed that students in the experimental terms had significantly higher exam scores than students in the control terms. This result shows that online reading quizzes can boost achievement in community college students. We also comment on the importance of discipline-based education research in community college settings and the structure of our community college/4-year institution collaboration.","Improving English language skills of learners is a strenuous task because of the variations in culture, background and learning styles. This strenuous task is further aggravated when English teachers realizes the proficiency level of students is far too low that his/her expectation. In most of the ESL and EFL context, English teachers rely on mid-term test to evaluate the proficiency level of the students. Blame game follows when there are too many failures in the classroom. Teachers blame the students for giving least importance to English language which resulted in low scores while the students blame the teacher for making the exam tough. The college/university management considers failure of students as a failure of the teachers in the classroom teaching. The information presented in this paper is an alarming wakeup call and a reminder for the teachers to be constant self-evaluators of their classroom teaching rather than waiting for the results of a test to understand the students’ progress in classroom. This paper gives insights to the struggling teachers to succeed through reflective teaching practices.","Traditional and online university courses share expectations for quality content and rigor. Student and faculty concerns about compromised academic integrity and actual instances of academic dishonesty in assessments, especially with online testing, are increasingly troublesome. Recent research suggests that in the absence of proctoring, the time taken to complete an exam increases significantly and online test results are inflated. This study uses a randomized design in seven sections of an online course to examine test scores from 97 students and time taken to complete online tests with and without proctoring software, controlling for exam difficulty, course design, instructor effects, and student majors. Results from fixed effects estimated from a fitted statistical model showed a significant advantage in quiz performance (7-9 points on a 100 point quiz) when students were not proctored, with all other variables statistically accounted for. Larger grade disparities and longer testing times were observed on the most difficult quizzes, and with factors that reflected the perception of high stakes of the quiz grades. Overall, use of proctoring software resulted in lower quiz scores, shorter quiz taking times, and less variation in quiz performance across exams, implying greater compliance with academic integrity compared with when quizzes were taken without proctoring software.","Prior research has established that students often underprepare for midterm examinations yet remain overconfident in their proficiency. Research concerning the testing effect has demonstrated that utilizing testing as a study strategy leads to higher performance and more accurate confidence compared to more common study strategies such as rereading or reviewing homework problems. We report on three experiments that explore the viability of using computer adaptive testing (CAT) for assessing students’ physics proficiency, for preparing students for midterm exams by diagnosing their weaknesses, and for predicting scores in midterm exams in an introductory calculus-based mechanics course for science and engineering majors. The first two experiments evaluated the reliability and validity of the CAT algorithm. In addition, we investigated the ability of the CAT test to predict performance on the midterm exam. The third experiment explored whether completing two CAT tests in the days before a midterm exam would facilitate performance on the midterm exam. Scores on the CAT tests and the midterm exams were significantly correlated and, on average, were not statistically different from each other. This provides evidence for moderate parallel-forms reliability and criterion-related validity of the CAT algorithm. In addition, when used as a diagnostic tool, CAT showed promise in helping students perform better on midterm exams. Finally, we found that the CAT tests predicted the average performance on the midterm exams reasonably well, however, the CAT tests were not as accurate as desired at predicting the performance of individual students. While CAT shows promise for practice testing, more research is needed to refine testing algorithms to increase reliability before implementing CAT for summative evaluations. In light of these findings, we believe that more research is needed comparing CAT to traditional paper-and-pencil practice tests in order to determine whether the effort needed to create a CAT system is worthwhile.","We draw on administrative data from the country of Colombia to assess differences in student learning in online and traditional on-campus college programs. The Colombian context is uniquely suited to study this topic, as students take a compulsory exit examination at the end of their studies. We can therefore directly compare the performance on the exit exam for students in online and on-campus programs both across and within institutions, degrees, and majors. Using inverse probability weighting methods based on a rich set of background characteristics coupled with institution–degree–major fixed effects, our results suggest that bachelor’s degree students in online programs perform worse on nearly all test score measures (including math, reading, writing, and English) relative to their counterparts in on-campus programs. Results for shorter technical certificates are more mixed. While online students perform significantly worse than on-campus students on exit exams in private institutions, they perform better in SENA—the main public vocational institution in the country.",24.0897058420802,3,Unlabeled
